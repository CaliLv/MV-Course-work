{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65629145-cb8e-40ae-8306-e04b7414869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c468349-f543-41ae-8d7d-56e7c34782c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "global logs, best_acc\n",
    "logs = []\n",
    "best_acc = 0 \n",
    "modellr = 1e-5\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "number_class = 5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07437da4-eaf7-4323-aae2-0944cec0b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(66)\n",
    "\n",
    "def moveFile(input_path, rate, output_path):\n",
    "    pathDir = os.listdir(input_path)\n",
    "    filenumber = len(pathDir)\n",
    "    picknumber = int(filenumber * rate)\n",
    "    sample = random.sample(pathDir, picknumber)\n",
    "    for file_name in sample:\n",
    "        shutil.move(input_path +'/'+ file_name, output_path + '/' + file_name)\n",
    "\n",
    "\n",
    "root = 'datasets'\n",
    "categories = os.listdir(root+'/train')\n",
    "np.savetxt(root+'/classes.txt', categories, fmt='%s')\n",
    "for m in categories:\n",
    "\n",
    "    input_path = root + '/train/' + str(m)\n",
    "    output_path1 = root + '/val/' + str(m)\n",
    "    output_path2 = root + '/test/' + str(m)\n",
    "\n",
    "    isExists = os.path.exists(output_path1)\n",
    "    if not isExists:\n",
    "        os.makedirs(output_path1)\n",
    "        moveFile(input_path, 0.3, output_path1)\n",
    "    isExists = os.path.exists(output_path2)\n",
    "    if not isExists:\n",
    "        os.makedirs(output_path2)\n",
    "        moveFile(output_path1, 0.3, output_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d377b007-b2b3-4f73-bd19-cc53f35b86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1/255, 1/255, 1/255])])\n",
    "transform_val = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1/255, 1/255, 1/255])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca2a1f6-9322-44f0-91b7-3efa16dfdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_train = datasets.ImageFolder('datasets/train', transform)\n",
    "dataset_val = datasets.ImageFolder('datasets/val', transform_val)\n",
    "dataset_test = datasets.ImageFolder('datasets/test', transform_val)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5261401f-ec6a-4460-bad2-396f33a4e3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in torchvision call resnet18 pre-train model\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "#Modify the number of categories in the last classification layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 5)\n",
    "model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=modellr)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    modellrnew = modellr * (0.1 ** (epoch // 50))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = modellrnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b1882c4-bb7d-46f0-86ff-85ffc14d36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    total_num = len(train_loader.dataset)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print_loss = loss.data.item()\n",
    "        sum_loss += print_loss\n",
    "        if (batch_idx + 1) % 5 == 0:\n",
    "            log = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                (batch_idx + 1) * len(data),\n",
    "                len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.item())\n",
    "            print(log)\n",
    "            logs.append(log)\n",
    "    ave_loss = sum_loss / len(train_loader)\n",
    "    log = 'epoch:{},loss:{}'.format(epoch, ave_loss)\n",
    "    print(log)\n",
    "    logs.append(log)\n",
    "\n",
    "def val(model, device, test_loader, phase):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_num = len(test_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += torch.sum(pred == target)\n",
    "            print_loss = loss.data.item()\n",
    "            test_loss += print_loss\n",
    "        correct = correct.data.item()\n",
    "        acc = correct / total_num\n",
    "        avgloss = test_loss / len(test_loader)\n",
    "        if phase == 'train':\n",
    "            log = 'Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                avgloss,\n",
    "                correct,\n",
    "                len(test_loader.dataset),\n",
    "                100 * acc)\n",
    "        else:\n",
    "            log = 'Val set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                avgloss,\n",
    "                correct,\n",
    "                len(test_loader.dataset),\n",
    "                100 * acc)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model, 'model_best.pth')\n",
    "        print(log)\n",
    "        logs.append(log)\n",
    "        np.savetxt('logs.txt', logs, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5425ae24-1b10-4000-8c2f-8861d2ae039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [40/2566 (2%)]\tLoss: 1.318653\n",
      "Train Epoch: 1 [80/2566 (3%)]\tLoss: 1.210933\n",
      "Train Epoch: 1 [120/2566 (5%)]\tLoss: 1.194899\n",
      "Train Epoch: 1 [160/2566 (6%)]\tLoss: 1.134004\n",
      "Train Epoch: 1 [200/2566 (8%)]\tLoss: 1.396958\n",
      "Train Epoch: 1 [240/2566 (9%)]\tLoss: 1.193944\n",
      "Train Epoch: 1 [280/2566 (11%)]\tLoss: 1.088090\n",
      "Train Epoch: 1 [320/2566 (12%)]\tLoss: 1.133645\n",
      "Train Epoch: 1 [360/2566 (14%)]\tLoss: 0.872572\n",
      "Train Epoch: 1 [400/2566 (16%)]\tLoss: 0.939282\n",
      "Train Epoch: 1 [440/2566 (17%)]\tLoss: 0.567151\n",
      "Train Epoch: 1 [480/2566 (19%)]\tLoss: 0.787190\n",
      "Train Epoch: 1 [520/2566 (20%)]\tLoss: 0.890378\n",
      "Train Epoch: 1 [560/2566 (22%)]\tLoss: 0.909335\n",
      "Train Epoch: 1 [600/2566 (23%)]\tLoss: 0.650051\n",
      "Train Epoch: 1 [640/2566 (25%)]\tLoss: 1.374645\n",
      "Train Epoch: 1 [680/2566 (26%)]\tLoss: 0.635133\n",
      "Train Epoch: 1 [720/2566 (28%)]\tLoss: 1.356131\n",
      "Train Epoch: 1 [760/2566 (30%)]\tLoss: 0.695598\n",
      "Train Epoch: 1 [800/2566 (31%)]\tLoss: 0.787204\n",
      "Train Epoch: 1 [840/2566 (33%)]\tLoss: 0.732883\n",
      "Train Epoch: 1 [880/2566 (34%)]\tLoss: 0.621632\n",
      "Train Epoch: 1 [920/2566 (36%)]\tLoss: 0.956586\n",
      "Train Epoch: 1 [960/2566 (37%)]\tLoss: 0.871340\n",
      "Train Epoch: 1 [1000/2566 (39%)]\tLoss: 1.185577\n",
      "Train Epoch: 1 [1040/2566 (40%)]\tLoss: 0.443732\n",
      "Train Epoch: 1 [1080/2566 (42%)]\tLoss: 0.641002\n",
      "Train Epoch: 1 [1120/2566 (44%)]\tLoss: 0.964455\n",
      "Train Epoch: 1 [1160/2566 (45%)]\tLoss: 0.684630\n",
      "Train Epoch: 1 [1200/2566 (47%)]\tLoss: 0.554289\n",
      "Train Epoch: 1 [1240/2566 (48%)]\tLoss: 1.016531\n",
      "Train Epoch: 1 [1280/2566 (50%)]\tLoss: 0.530313\n",
      "Train Epoch: 1 [1320/2566 (51%)]\tLoss: 0.893758\n",
      "Train Epoch: 1 [1360/2566 (53%)]\tLoss: 0.796376\n",
      "Train Epoch: 1 [1400/2566 (55%)]\tLoss: 1.642774\n",
      "Train Epoch: 1 [1440/2566 (56%)]\tLoss: 0.719232\n",
      "Train Epoch: 1 [1480/2566 (58%)]\tLoss: 0.501646\n",
      "Train Epoch: 1 [1520/2566 (59%)]\tLoss: 0.551319\n",
      "Train Epoch: 1 [1560/2566 (61%)]\tLoss: 1.002502\n",
      "Train Epoch: 1 [1600/2566 (62%)]\tLoss: 0.709336\n",
      "Train Epoch: 1 [1640/2566 (64%)]\tLoss: 0.516243\n",
      "Train Epoch: 1 [1680/2566 (65%)]\tLoss: 0.829747\n",
      "Train Epoch: 1 [1720/2566 (67%)]\tLoss: 1.075854\n",
      "Train Epoch: 1 [1760/2566 (69%)]\tLoss: 0.861542\n",
      "Train Epoch: 1 [1800/2566 (70%)]\tLoss: 1.387647\n",
      "Train Epoch: 1 [1840/2566 (72%)]\tLoss: 1.293192\n",
      "Train Epoch: 1 [1880/2566 (73%)]\tLoss: 0.751428\n",
      "Train Epoch: 1 [1920/2566 (75%)]\tLoss: 0.887378\n",
      "Train Epoch: 1 [1960/2566 (76%)]\tLoss: 0.898753\n",
      "Train Epoch: 1 [2000/2566 (78%)]\tLoss: 0.318282\n",
      "Train Epoch: 1 [2040/2566 (79%)]\tLoss: 0.455810\n",
      "Train Epoch: 1 [2080/2566 (81%)]\tLoss: 0.567743\n",
      "Train Epoch: 1 [2120/2566 (83%)]\tLoss: 0.703082\n",
      "Train Epoch: 1 [2160/2566 (84%)]\tLoss: 0.717592\n",
      "Train Epoch: 1 [2200/2566 (86%)]\tLoss: 0.722347\n",
      "Train Epoch: 1 [2240/2566 (87%)]\tLoss: 0.748011\n",
      "Train Epoch: 1 [2280/2566 (89%)]\tLoss: 0.459578\n",
      "Train Epoch: 1 [2320/2566 (90%)]\tLoss: 1.182674\n",
      "Train Epoch: 1 [2360/2566 (92%)]\tLoss: 0.471547\n",
      "Train Epoch: 1 [2400/2566 (93%)]\tLoss: 1.164701\n",
      "Train Epoch: 1 [2440/2566 (95%)]\tLoss: 0.859617\n",
      "Train Epoch: 1 [2480/2566 (97%)]\tLoss: 0.517992\n",
      "Train Epoch: 1 [2520/2566 (98%)]\tLoss: 0.559441\n",
      "Train Epoch: 1 [2560/2566 (100%)]\tLoss: 1.146456\n",
      "epoch:1,loss:0.8506069668913927\n",
      "Train set: Average loss: 0.5926, Accuracy: 2031/2566 (79%)\n",
      "Val set: Average loss: 0.5784, Accuracy: 265/327 (81%)\n",
      "Train Epoch: 2 [40/2566 (2%)]\tLoss: 0.317161\n",
      "Train Epoch: 2 [80/2566 (3%)]\tLoss: 0.611754\n",
      "Train Epoch: 2 [120/2566 (5%)]\tLoss: 0.654880\n",
      "Train Epoch: 2 [160/2566 (6%)]\tLoss: 0.658700\n",
      "Train Epoch: 2 [200/2566 (8%)]\tLoss: 0.539286\n",
      "Train Epoch: 2 [240/2566 (9%)]\tLoss: 0.521988\n",
      "Train Epoch: 2 [280/2566 (11%)]\tLoss: 0.501638\n",
      "Train Epoch: 2 [320/2566 (12%)]\tLoss: 0.678609\n",
      "Train Epoch: 2 [360/2566 (14%)]\tLoss: 1.062956\n",
      "Train Epoch: 2 [400/2566 (16%)]\tLoss: 0.402136\n",
      "Train Epoch: 2 [440/2566 (17%)]\tLoss: 1.006447\n",
      "Train Epoch: 2 [480/2566 (19%)]\tLoss: 0.392217\n",
      "Train Epoch: 2 [520/2566 (20%)]\tLoss: 0.422221\n",
      "Train Epoch: 2 [560/2566 (22%)]\tLoss: 0.570762\n",
      "Train Epoch: 2 [600/2566 (23%)]\tLoss: 0.785858\n",
      "Train Epoch: 2 [640/2566 (25%)]\tLoss: 0.943186\n",
      "Train Epoch: 2 [680/2566 (26%)]\tLoss: 0.932399\n",
      "Train Epoch: 2 [720/2566 (28%)]\tLoss: 0.734549\n",
      "Train Epoch: 2 [760/2566 (30%)]\tLoss: 0.671484\n",
      "Train Epoch: 2 [800/2566 (31%)]\tLoss: 0.968421\n",
      "Train Epoch: 2 [840/2566 (33%)]\tLoss: 0.443879\n",
      "Train Epoch: 2 [880/2566 (34%)]\tLoss: 0.657567\n",
      "Train Epoch: 2 [920/2566 (36%)]\tLoss: 0.990937\n",
      "Train Epoch: 2 [960/2566 (37%)]\tLoss: 1.784420\n",
      "Train Epoch: 2 [1000/2566 (39%)]\tLoss: 0.318059\n",
      "Train Epoch: 2 [1040/2566 (40%)]\tLoss: 1.237415\n",
      "Train Epoch: 2 [1080/2566 (42%)]\tLoss: 0.346569\n",
      "Train Epoch: 2 [1120/2566 (44%)]\tLoss: 0.590930\n",
      "Train Epoch: 2 [1160/2566 (45%)]\tLoss: 0.431230\n",
      "Train Epoch: 2 [1200/2566 (47%)]\tLoss: 0.831027\n",
      "Train Epoch: 2 [1240/2566 (48%)]\tLoss: 0.701290\n",
      "Train Epoch: 2 [1280/2566 (50%)]\tLoss: 0.629048\n",
      "Train Epoch: 2 [1320/2566 (51%)]\tLoss: 0.857511\n",
      "Train Epoch: 2 [1360/2566 (53%)]\tLoss: 0.510435\n",
      "Train Epoch: 2 [1400/2566 (55%)]\tLoss: 1.206730\n",
      "Train Epoch: 2 [1440/2566 (56%)]\tLoss: 0.720385\n",
      "Train Epoch: 2 [1480/2566 (58%)]\tLoss: 0.795568\n",
      "Train Epoch: 2 [1520/2566 (59%)]\tLoss: 0.586472\n",
      "Train Epoch: 2 [1560/2566 (61%)]\tLoss: 0.662594\n",
      "Train Epoch: 2 [1600/2566 (62%)]\tLoss: 0.522699\n",
      "Train Epoch: 2 [1640/2566 (64%)]\tLoss: 0.848041\n",
      "Train Epoch: 2 [1680/2566 (65%)]\tLoss: 0.413177\n",
      "Train Epoch: 2 [1720/2566 (67%)]\tLoss: 0.760259\n",
      "Train Epoch: 2 [1760/2566 (69%)]\tLoss: 0.774669\n",
      "Train Epoch: 2 [1800/2566 (70%)]\tLoss: 0.441379\n",
      "Train Epoch: 2 [1840/2566 (72%)]\tLoss: 0.666937\n",
      "Train Epoch: 2 [1880/2566 (73%)]\tLoss: 0.535577\n",
      "Train Epoch: 2 [1920/2566 (75%)]\tLoss: 0.601820\n",
      "Train Epoch: 2 [1960/2566 (76%)]\tLoss: 0.511138\n",
      "Train Epoch: 2 [2000/2566 (78%)]\tLoss: 0.404983\n",
      "Train Epoch: 2 [2040/2566 (79%)]\tLoss: 0.256951\n",
      "Train Epoch: 2 [2080/2566 (81%)]\tLoss: 0.481251\n",
      "Train Epoch: 2 [2120/2566 (83%)]\tLoss: 0.778845\n",
      "Train Epoch: 2 [2160/2566 (84%)]\tLoss: 0.661592\n",
      "Train Epoch: 2 [2200/2566 (86%)]\tLoss: 0.365699\n",
      "Train Epoch: 2 [2240/2566 (87%)]\tLoss: 0.873625\n",
      "Train Epoch: 2 [2280/2566 (89%)]\tLoss: 0.517636\n",
      "Train Epoch: 2 [2320/2566 (90%)]\tLoss: 0.556369\n",
      "Train Epoch: 2 [2360/2566 (92%)]\tLoss: 0.380686\n",
      "Train Epoch: 2 [2400/2566 (93%)]\tLoss: 0.925623\n",
      "Train Epoch: 2 [2440/2566 (95%)]\tLoss: 0.973967\n",
      "Train Epoch: 2 [2480/2566 (97%)]\tLoss: 1.274419\n",
      "Train Epoch: 2 [2520/2566 (98%)]\tLoss: 0.610198\n",
      "Train Epoch: 2 [2560/2566 (100%)]\tLoss: 0.667640\n",
      "epoch:2,loss:0.6554511492126085\n",
      "Train set: Average loss: 0.4727, Accuracy: 2150/2566 (84%)\n",
      "Val set: Average loss: 0.4998, Accuracy: 264/327 (81%)\n",
      "Train Epoch: 3 [40/2566 (2%)]\tLoss: 0.491974\n",
      "Train Epoch: 3 [80/2566 (3%)]\tLoss: 0.532780\n",
      "Train Epoch: 3 [120/2566 (5%)]\tLoss: 0.270677\n",
      "Train Epoch: 3 [160/2566 (6%)]\tLoss: 0.436266\n",
      "Train Epoch: 3 [200/2566 (8%)]\tLoss: 1.275310\n",
      "Train Epoch: 3 [240/2566 (9%)]\tLoss: 0.390924\n",
      "Train Epoch: 3 [280/2566 (11%)]\tLoss: 0.446431\n",
      "Train Epoch: 3 [320/2566 (12%)]\tLoss: 0.516714\n",
      "Train Epoch: 3 [360/2566 (14%)]\tLoss: 0.452725\n",
      "Train Epoch: 3 [400/2566 (16%)]\tLoss: 0.188958\n",
      "Train Epoch: 3 [440/2566 (17%)]\tLoss: 1.492104\n",
      "Train Epoch: 3 [480/2566 (19%)]\tLoss: 0.277095\n",
      "Train Epoch: 3 [520/2566 (20%)]\tLoss: 0.379392\n",
      "Train Epoch: 3 [560/2566 (22%)]\tLoss: 0.705019\n",
      "Train Epoch: 3 [600/2566 (23%)]\tLoss: 0.655674\n",
      "Train Epoch: 3 [640/2566 (25%)]\tLoss: 0.507513\n",
      "Train Epoch: 3 [680/2566 (26%)]\tLoss: 0.495683\n",
      "Train Epoch: 3 [720/2566 (28%)]\tLoss: 0.327480\n",
      "Train Epoch: 3 [760/2566 (30%)]\tLoss: 0.695188\n",
      "Train Epoch: 3 [800/2566 (31%)]\tLoss: 0.602869\n",
      "Train Epoch: 3 [840/2566 (33%)]\tLoss: 0.248267\n",
      "Train Epoch: 3 [880/2566 (34%)]\tLoss: 0.555689\n",
      "Train Epoch: 3 [920/2566 (36%)]\tLoss: 0.302040\n",
      "Train Epoch: 3 [960/2566 (37%)]\tLoss: 0.790806\n",
      "Train Epoch: 3 [1000/2566 (39%)]\tLoss: 0.566149\n",
      "Train Epoch: 3 [1040/2566 (40%)]\tLoss: 0.433954\n",
      "Train Epoch: 3 [1080/2566 (42%)]\tLoss: 0.400653\n",
      "Train Epoch: 3 [1120/2566 (44%)]\tLoss: 0.271275\n",
      "Train Epoch: 3 [1160/2566 (45%)]\tLoss: 0.419582\n",
      "Train Epoch: 3 [1200/2566 (47%)]\tLoss: 0.791476\n",
      "Train Epoch: 3 [1240/2566 (48%)]\tLoss: 0.556746\n",
      "Train Epoch: 3 [1280/2566 (50%)]\tLoss: 0.498725\n",
      "Train Epoch: 3 [1320/2566 (51%)]\tLoss: 0.691305\n",
      "Train Epoch: 3 [1360/2566 (53%)]\tLoss: 0.236559\n",
      "Train Epoch: 3 [1400/2566 (55%)]\tLoss: 0.484609\n",
      "Train Epoch: 3 [1440/2566 (56%)]\tLoss: 0.496069\n",
      "Train Epoch: 3 [1480/2566 (58%)]\tLoss: 0.793667\n",
      "Train Epoch: 3 [1520/2566 (59%)]\tLoss: 0.622589\n",
      "Train Epoch: 3 [1560/2566 (61%)]\tLoss: 0.791240\n",
      "Train Epoch: 3 [1600/2566 (62%)]\tLoss: 0.578446\n",
      "Train Epoch: 3 [1640/2566 (64%)]\tLoss: 0.551787\n",
      "Train Epoch: 3 [1680/2566 (65%)]\tLoss: 0.339274\n",
      "Train Epoch: 3 [1720/2566 (67%)]\tLoss: 0.492436\n",
      "Train Epoch: 3 [1760/2566 (69%)]\tLoss: 0.404045\n",
      "Train Epoch: 3 [1800/2566 (70%)]\tLoss: 1.242529\n",
      "Train Epoch: 3 [1840/2566 (72%)]\tLoss: 0.257583\n",
      "Train Epoch: 3 [1880/2566 (73%)]\tLoss: 0.337184\n",
      "Train Epoch: 3 [1920/2566 (75%)]\tLoss: 0.426949\n",
      "Train Epoch: 3 [1960/2566 (76%)]\tLoss: 0.341955\n",
      "Train Epoch: 3 [2000/2566 (78%)]\tLoss: 0.988928\n",
      "Train Epoch: 3 [2040/2566 (79%)]\tLoss: 0.409680\n",
      "Train Epoch: 3 [2080/2566 (81%)]\tLoss: 0.407795\n",
      "Train Epoch: 3 [2120/2566 (83%)]\tLoss: 1.026592\n",
      "Train Epoch: 3 [2160/2566 (84%)]\tLoss: 0.202774\n",
      "Train Epoch: 3 [2200/2566 (86%)]\tLoss: 1.046336\n",
      "Train Epoch: 3 [2240/2566 (87%)]\tLoss: 0.500426\n",
      "Train Epoch: 3 [2280/2566 (89%)]\tLoss: 0.817332\n",
      "Train Epoch: 3 [2320/2566 (90%)]\tLoss: 0.245975\n",
      "Train Epoch: 3 [2360/2566 (92%)]\tLoss: 0.361203\n",
      "Train Epoch: 3 [2400/2566 (93%)]\tLoss: 0.713477\n",
      "Train Epoch: 3 [2440/2566 (95%)]\tLoss: 0.759024\n",
      "Train Epoch: 3 [2480/2566 (97%)]\tLoss: 0.466560\n",
      "Train Epoch: 3 [2520/2566 (98%)]\tLoss: 0.453835\n",
      "Train Epoch: 3 [2560/2566 (100%)]\tLoss: 0.517028\n",
      "epoch:3,loss:0.549752392083685\n",
      "Train set: Average loss: 0.3978, Accuracy: 2204/2566 (86%)\n",
      "Val set: Average loss: 0.4668, Accuracy: 272/327 (83%)\n",
      "Train Epoch: 4 [40/2566 (2%)]\tLoss: 0.848669\n",
      "Train Epoch: 4 [80/2566 (3%)]\tLoss: 0.508015\n",
      "Train Epoch: 4 [120/2566 (5%)]\tLoss: 0.167842\n",
      "Train Epoch: 4 [160/2566 (6%)]\tLoss: 0.403196\n",
      "Train Epoch: 4 [200/2566 (8%)]\tLoss: 0.260650\n",
      "Train Epoch: 4 [240/2566 (9%)]\tLoss: 0.266709\n",
      "Train Epoch: 4 [280/2566 (11%)]\tLoss: 0.566186\n",
      "Train Epoch: 4 [320/2566 (12%)]\tLoss: 1.422406\n",
      "Train Epoch: 4 [360/2566 (14%)]\tLoss: 0.518595\n",
      "Train Epoch: 4 [400/2566 (16%)]\tLoss: 0.592140\n",
      "Train Epoch: 4 [440/2566 (17%)]\tLoss: 0.374433\n",
      "Train Epoch: 4 [480/2566 (19%)]\tLoss: 0.308123\n",
      "Train Epoch: 4 [520/2566 (20%)]\tLoss: 0.466368\n",
      "Train Epoch: 4 [560/2566 (22%)]\tLoss: 0.849612\n",
      "Train Epoch: 4 [600/2566 (23%)]\tLoss: 0.673422\n",
      "Train Epoch: 4 [640/2566 (25%)]\tLoss: 0.514120\n",
      "Train Epoch: 4 [680/2566 (26%)]\tLoss: 0.222863\n",
      "Train Epoch: 4 [720/2566 (28%)]\tLoss: 0.260859\n",
      "Train Epoch: 4 [760/2566 (30%)]\tLoss: 1.075601\n",
      "Train Epoch: 4 [800/2566 (31%)]\tLoss: 0.557078\n",
      "Train Epoch: 4 [840/2566 (33%)]\tLoss: 0.215761\n",
      "Train Epoch: 4 [880/2566 (34%)]\tLoss: 0.329538\n",
      "Train Epoch: 4 [920/2566 (36%)]\tLoss: 0.367080\n",
      "Train Epoch: 4 [960/2566 (37%)]\tLoss: 0.509559\n",
      "Train Epoch: 4 [1000/2566 (39%)]\tLoss: 0.504033\n",
      "Train Epoch: 4 [1040/2566 (40%)]\tLoss: 0.728570\n",
      "Train Epoch: 4 [1080/2566 (42%)]\tLoss: 0.473843\n",
      "Train Epoch: 4 [1120/2566 (44%)]\tLoss: 0.436798\n",
      "Train Epoch: 4 [1160/2566 (45%)]\tLoss: 0.247830\n",
      "Train Epoch: 4 [1200/2566 (47%)]\tLoss: 1.103028\n",
      "Train Epoch: 4 [1240/2566 (48%)]\tLoss: 0.364676\n",
      "Train Epoch: 4 [1280/2566 (50%)]\tLoss: 0.630943\n",
      "Train Epoch: 4 [1320/2566 (51%)]\tLoss: 0.144521\n",
      "Train Epoch: 4 [1360/2566 (53%)]\tLoss: 0.594971\n",
      "Train Epoch: 4 [1400/2566 (55%)]\tLoss: 0.333829\n",
      "Train Epoch: 4 [1440/2566 (56%)]\tLoss: 0.452299\n",
      "Train Epoch: 4 [1480/2566 (58%)]\tLoss: 0.807539\n",
      "Train Epoch: 4 [1520/2566 (59%)]\tLoss: 1.060103\n",
      "Train Epoch: 4 [1560/2566 (61%)]\tLoss: 0.200246\n",
      "Train Epoch: 4 [1600/2566 (62%)]\tLoss: 0.417090\n",
      "Train Epoch: 4 [1640/2566 (64%)]\tLoss: 0.517800\n",
      "Train Epoch: 4 [1680/2566 (65%)]\tLoss: 1.445831\n",
      "Train Epoch: 4 [1720/2566 (67%)]\tLoss: 1.064869\n",
      "Train Epoch: 4 [1760/2566 (69%)]\tLoss: 0.639596\n",
      "Train Epoch: 4 [1800/2566 (70%)]\tLoss: 0.476967\n",
      "Train Epoch: 4 [1840/2566 (72%)]\tLoss: 0.308055\n",
      "Train Epoch: 4 [1880/2566 (73%)]\tLoss: 0.597332\n",
      "Train Epoch: 4 [1920/2566 (75%)]\tLoss: 0.519580\n",
      "Train Epoch: 4 [1960/2566 (76%)]\tLoss: 0.618671\n",
      "Train Epoch: 4 [2000/2566 (78%)]\tLoss: 0.564707\n",
      "Train Epoch: 4 [2040/2566 (79%)]\tLoss: 0.548098\n",
      "Train Epoch: 4 [2080/2566 (81%)]\tLoss: 0.546993\n",
      "Train Epoch: 4 [2120/2566 (83%)]\tLoss: 0.237154\n",
      "Train Epoch: 4 [2160/2566 (84%)]\tLoss: 0.229715\n",
      "Train Epoch: 4 [2200/2566 (86%)]\tLoss: 0.182452\n",
      "Train Epoch: 4 [2240/2566 (87%)]\tLoss: 1.169901\n",
      "Train Epoch: 4 [2280/2566 (89%)]\tLoss: 0.382606\n",
      "Train Epoch: 4 [2320/2566 (90%)]\tLoss: 0.366785\n",
      "Train Epoch: 4 [2360/2566 (92%)]\tLoss: 0.494997\n",
      "Train Epoch: 4 [2400/2566 (93%)]\tLoss: 0.196328\n",
      "Train Epoch: 4 [2440/2566 (95%)]\tLoss: 0.768214\n",
      "Train Epoch: 4 [2480/2566 (97%)]\tLoss: 0.313567\n",
      "Train Epoch: 4 [2520/2566 (98%)]\tLoss: 0.353812\n",
      "Train Epoch: 4 [2560/2566 (100%)]\tLoss: 0.628120\n",
      "epoch:4,loss:0.49848844447518437\n",
      "Train set: Average loss: 0.3365, Accuracy: 2262/2566 (88%)\n",
      "Val set: Average loss: 0.4397, Accuracy: 273/327 (83%)\n",
      "Train Epoch: 5 [40/2566 (2%)]\tLoss: 0.149319\n",
      "Train Epoch: 5 [80/2566 (3%)]\tLoss: 0.471875\n",
      "Train Epoch: 5 [120/2566 (5%)]\tLoss: 0.249402\n",
      "Train Epoch: 5 [160/2566 (6%)]\tLoss: 0.429467\n",
      "Train Epoch: 5 [200/2566 (8%)]\tLoss: 0.344722\n",
      "Train Epoch: 5 [240/2566 (9%)]\tLoss: 0.390835\n",
      "Train Epoch: 5 [280/2566 (11%)]\tLoss: 0.601569\n",
      "Train Epoch: 5 [320/2566 (12%)]\tLoss: 0.181112\n",
      "Train Epoch: 5 [360/2566 (14%)]\tLoss: 1.310939\n",
      "Train Epoch: 5 [400/2566 (16%)]\tLoss: 0.332655\n",
      "Train Epoch: 5 [440/2566 (17%)]\tLoss: 0.389501\n",
      "Train Epoch: 5 [480/2566 (19%)]\tLoss: 0.175990\n",
      "Train Epoch: 5 [520/2566 (20%)]\tLoss: 0.275757\n",
      "Train Epoch: 5 [560/2566 (22%)]\tLoss: 0.280029\n",
      "Train Epoch: 5 [600/2566 (23%)]\tLoss: 0.303893\n",
      "Train Epoch: 5 [640/2566 (25%)]\tLoss: 0.504856\n",
      "Train Epoch: 5 [680/2566 (26%)]\tLoss: 0.612817\n",
      "Train Epoch: 5 [720/2566 (28%)]\tLoss: 0.528868\n",
      "Train Epoch: 5 [760/2566 (30%)]\tLoss: 0.521137\n",
      "Train Epoch: 5 [800/2566 (31%)]\tLoss: 0.256299\n",
      "Train Epoch: 5 [840/2566 (33%)]\tLoss: 0.478540\n",
      "Train Epoch: 5 [880/2566 (34%)]\tLoss: 0.237593\n",
      "Train Epoch: 5 [920/2566 (36%)]\tLoss: 0.529815\n",
      "Train Epoch: 5 [960/2566 (37%)]\tLoss: 0.376821\n",
      "Train Epoch: 5 [1000/2566 (39%)]\tLoss: 0.231623\n",
      "Train Epoch: 5 [1040/2566 (40%)]\tLoss: 0.811794\n",
      "Train Epoch: 5 [1080/2566 (42%)]\tLoss: 0.473630\n",
      "Train Epoch: 5 [1120/2566 (44%)]\tLoss: 0.725633\n",
      "Train Epoch: 5 [1160/2566 (45%)]\tLoss: 0.901130\n",
      "Train Epoch: 5 [1200/2566 (47%)]\tLoss: 0.447774\n",
      "Train Epoch: 5 [1240/2566 (48%)]\tLoss: 0.224316\n",
      "Train Epoch: 5 [1280/2566 (50%)]\tLoss: 0.410142\n",
      "Train Epoch: 5 [1320/2566 (51%)]\tLoss: 0.742856\n",
      "Train Epoch: 5 [1360/2566 (53%)]\tLoss: 0.522486\n",
      "Train Epoch: 5 [1400/2566 (55%)]\tLoss: 0.226954\n",
      "Train Epoch: 5 [1440/2566 (56%)]\tLoss: 0.241124\n",
      "Train Epoch: 5 [1480/2566 (58%)]\tLoss: 0.797059\n",
      "Train Epoch: 5 [1520/2566 (59%)]\tLoss: 0.369316\n",
      "Train Epoch: 5 [1560/2566 (61%)]\tLoss: 0.794941\n",
      "Train Epoch: 5 [1600/2566 (62%)]\tLoss: 0.787723\n",
      "Train Epoch: 5 [1640/2566 (64%)]\tLoss: 0.226902\n",
      "Train Epoch: 5 [1680/2566 (65%)]\tLoss: 0.269520\n",
      "Train Epoch: 5 [1720/2566 (67%)]\tLoss: 0.176693\n",
      "Train Epoch: 5 [1760/2566 (69%)]\tLoss: 0.277719\n",
      "Train Epoch: 5 [1800/2566 (70%)]\tLoss: 0.379480\n",
      "Train Epoch: 5 [1840/2566 (72%)]\tLoss: 0.640006\n",
      "Train Epoch: 5 [1880/2566 (73%)]\tLoss: 0.101840\n",
      "Train Epoch: 5 [1920/2566 (75%)]\tLoss: 0.376449\n",
      "Train Epoch: 5 [1960/2566 (76%)]\tLoss: 0.240055\n",
      "Train Epoch: 5 [2000/2566 (78%)]\tLoss: 0.665566\n",
      "Train Epoch: 5 [2040/2566 (79%)]\tLoss: 0.602544\n",
      "Train Epoch: 5 [2080/2566 (81%)]\tLoss: 0.567542\n",
      "Train Epoch: 5 [2120/2566 (83%)]\tLoss: 0.605864\n",
      "Train Epoch: 5 [2160/2566 (84%)]\tLoss: 0.131406\n",
      "Train Epoch: 5 [2200/2566 (86%)]\tLoss: 0.216431\n",
      "Train Epoch: 5 [2240/2566 (87%)]\tLoss: 0.572124\n",
      "Train Epoch: 5 [2280/2566 (89%)]\tLoss: 0.204182\n",
      "Train Epoch: 5 [2320/2566 (90%)]\tLoss: 0.360675\n",
      "Train Epoch: 5 [2360/2566 (92%)]\tLoss: 0.603336\n",
      "Train Epoch: 5 [2400/2566 (93%)]\tLoss: 0.571846\n",
      "Train Epoch: 5 [2440/2566 (95%)]\tLoss: 0.511420\n",
      "Train Epoch: 5 [2480/2566 (97%)]\tLoss: 0.531360\n",
      "Train Epoch: 5 [2520/2566 (98%)]\tLoss: 0.140664\n",
      "Train Epoch: 5 [2560/2566 (100%)]\tLoss: 0.155226\n",
      "epoch:5,loss:0.44426623511351526\n",
      "Train set: Average loss: 0.2822, Accuracy: 2331/2566 (91%)\n",
      "Val set: Average loss: 0.4220, Accuracy: 273/327 (83%)\n",
      "Train Epoch: 6 [40/2566 (2%)]\tLoss: 0.314475\n",
      "Train Epoch: 6 [80/2566 (3%)]\tLoss: 0.118604\n",
      "Train Epoch: 6 [120/2566 (5%)]\tLoss: 0.403544\n",
      "Train Epoch: 6 [160/2566 (6%)]\tLoss: 0.106606\n",
      "Train Epoch: 6 [200/2566 (8%)]\tLoss: 0.796929\n",
      "Train Epoch: 6 [240/2566 (9%)]\tLoss: 0.228904\n",
      "Train Epoch: 6 [280/2566 (11%)]\tLoss: 0.220341\n",
      "Train Epoch: 6 [320/2566 (12%)]\tLoss: 0.152352\n",
      "Train Epoch: 6 [360/2566 (14%)]\tLoss: 0.489186\n",
      "Train Epoch: 6 [400/2566 (16%)]\tLoss: 0.730110\n",
      "Train Epoch: 6 [440/2566 (17%)]\tLoss: 0.238419\n",
      "Train Epoch: 6 [480/2566 (19%)]\tLoss: 0.249513\n",
      "Train Epoch: 6 [520/2566 (20%)]\tLoss: 0.264192\n",
      "Train Epoch: 6 [560/2566 (22%)]\tLoss: 0.262763\n",
      "Train Epoch: 6 [600/2566 (23%)]\tLoss: 0.457443\n",
      "Train Epoch: 6 [640/2566 (25%)]\tLoss: 0.419044\n",
      "Train Epoch: 6 [680/2566 (26%)]\tLoss: 0.346002\n",
      "Train Epoch: 6 [720/2566 (28%)]\tLoss: 0.292138\n",
      "Train Epoch: 6 [760/2566 (30%)]\tLoss: 0.261211\n",
      "Train Epoch: 6 [800/2566 (31%)]\tLoss: 0.144206\n",
      "Train Epoch: 6 [840/2566 (33%)]\tLoss: 0.165396\n",
      "Train Epoch: 6 [880/2566 (34%)]\tLoss: 0.110043\n",
      "Train Epoch: 6 [920/2566 (36%)]\tLoss: 1.322483\n",
      "Train Epoch: 6 [960/2566 (37%)]\tLoss: 0.223350\n",
      "Train Epoch: 6 [1000/2566 (39%)]\tLoss: 0.360274\n",
      "Train Epoch: 6 [1040/2566 (40%)]\tLoss: 0.416518\n",
      "Train Epoch: 6 [1080/2566 (42%)]\tLoss: 1.036136\n",
      "Train Epoch: 6 [1120/2566 (44%)]\tLoss: 0.309829\n",
      "Train Epoch: 6 [1160/2566 (45%)]\tLoss: 0.399787\n",
      "Train Epoch: 6 [1200/2566 (47%)]\tLoss: 0.456587\n",
      "Train Epoch: 6 [1240/2566 (48%)]\tLoss: 0.190593\n",
      "Train Epoch: 6 [1280/2566 (50%)]\tLoss: 0.960699\n",
      "Train Epoch: 6 [1320/2566 (51%)]\tLoss: 0.295755\n",
      "Train Epoch: 6 [1360/2566 (53%)]\tLoss: 0.255989\n",
      "Train Epoch: 6 [1400/2566 (55%)]\tLoss: 0.401421\n",
      "Train Epoch: 6 [1440/2566 (56%)]\tLoss: 0.186275\n",
      "Train Epoch: 6 [1480/2566 (58%)]\tLoss: 0.194132\n",
      "Train Epoch: 6 [1520/2566 (59%)]\tLoss: 0.087103\n",
      "Train Epoch: 6 [1560/2566 (61%)]\tLoss: 0.157927\n",
      "Train Epoch: 6 [1600/2566 (62%)]\tLoss: 0.239945\n",
      "Train Epoch: 6 [1640/2566 (64%)]\tLoss: 1.180003\n",
      "Train Epoch: 6 [1680/2566 (65%)]\tLoss: 0.226007\n",
      "Train Epoch: 6 [1720/2566 (67%)]\tLoss: 0.213564\n",
      "Train Epoch: 6 [1760/2566 (69%)]\tLoss: 0.092120\n",
      "Train Epoch: 6 [1800/2566 (70%)]\tLoss: 0.173707\n",
      "Train Epoch: 6 [1840/2566 (72%)]\tLoss: 0.572567\n",
      "Train Epoch: 6 [1880/2566 (73%)]\tLoss: 0.150268\n",
      "Train Epoch: 6 [1920/2566 (75%)]\tLoss: 0.194537\n",
      "Train Epoch: 6 [1960/2566 (76%)]\tLoss: 0.333439\n",
      "Train Epoch: 6 [2000/2566 (78%)]\tLoss: 0.222892\n",
      "Train Epoch: 6 [2040/2566 (79%)]\tLoss: 0.683434\n",
      "Train Epoch: 6 [2080/2566 (81%)]\tLoss: 0.181479\n",
      "Train Epoch: 6 [2120/2566 (83%)]\tLoss: 0.563440\n",
      "Train Epoch: 6 [2160/2566 (84%)]\tLoss: 0.200245\n",
      "Train Epoch: 6 [2200/2566 (86%)]\tLoss: 0.387634\n",
      "Train Epoch: 6 [2240/2566 (87%)]\tLoss: 0.640689\n",
      "Train Epoch: 6 [2280/2566 (89%)]\tLoss: 0.308225\n",
      "Train Epoch: 6 [2320/2566 (90%)]\tLoss: 0.189130\n",
      "Train Epoch: 6 [2360/2566 (92%)]\tLoss: 0.616788\n",
      "Train Epoch: 6 [2400/2566 (93%)]\tLoss: 0.519248\n",
      "Train Epoch: 6 [2440/2566 (95%)]\tLoss: 0.193799\n",
      "Train Epoch: 6 [2480/2566 (97%)]\tLoss: 0.162769\n",
      "Train Epoch: 6 [2520/2566 (98%)]\tLoss: 0.260057\n",
      "Train Epoch: 6 [2560/2566 (100%)]\tLoss: 0.201329\n",
      "epoch:6,loss:0.40446301257220385\n",
      "Train set: Average loss: 0.2413, Accuracy: 2372/2566 (92%)\n",
      "Val set: Average loss: 0.4430, Accuracy: 277/327 (85%)\n",
      "Train Epoch: 7 [40/2566 (2%)]\tLoss: 0.173275\n",
      "Train Epoch: 7 [80/2566 (3%)]\tLoss: 0.622745\n",
      "Train Epoch: 7 [120/2566 (5%)]\tLoss: 0.215355\n",
      "Train Epoch: 7 [160/2566 (6%)]\tLoss: 0.412715\n",
      "Train Epoch: 7 [200/2566 (8%)]\tLoss: 0.390318\n",
      "Train Epoch: 7 [240/2566 (9%)]\tLoss: 0.382337\n",
      "Train Epoch: 7 [280/2566 (11%)]\tLoss: 0.112787\n",
      "Train Epoch: 7 [320/2566 (12%)]\tLoss: 0.164356\n",
      "Train Epoch: 7 [360/2566 (14%)]\tLoss: 0.361175\n",
      "Train Epoch: 7 [400/2566 (16%)]\tLoss: 0.951873\n",
      "Train Epoch: 7 [440/2566 (17%)]\tLoss: 0.243434\n",
      "Train Epoch: 7 [480/2566 (19%)]\tLoss: 0.220487\n",
      "Train Epoch: 7 [520/2566 (20%)]\tLoss: 0.362275\n",
      "Train Epoch: 7 [560/2566 (22%)]\tLoss: 0.680745\n",
      "Train Epoch: 7 [600/2566 (23%)]\tLoss: 0.209191\n",
      "Train Epoch: 7 [640/2566 (25%)]\tLoss: 0.501878\n",
      "Train Epoch: 7 [680/2566 (26%)]\tLoss: 0.431175\n",
      "Train Epoch: 7 [720/2566 (28%)]\tLoss: 0.190202\n",
      "Train Epoch: 7 [760/2566 (30%)]\tLoss: 0.234467\n",
      "Train Epoch: 7 [800/2566 (31%)]\tLoss: 0.719758\n",
      "Train Epoch: 7 [840/2566 (33%)]\tLoss: 0.148973\n",
      "Train Epoch: 7 [880/2566 (34%)]\tLoss: 0.436040\n",
      "Train Epoch: 7 [920/2566 (36%)]\tLoss: 0.627820\n",
      "Train Epoch: 7 [960/2566 (37%)]\tLoss: 0.144688\n",
      "Train Epoch: 7 [1000/2566 (39%)]\tLoss: 0.498942\n",
      "Train Epoch: 7 [1040/2566 (40%)]\tLoss: 0.938667\n",
      "Train Epoch: 7 [1080/2566 (42%)]\tLoss: 0.253751\n",
      "Train Epoch: 7 [1120/2566 (44%)]\tLoss: 0.360343\n",
      "Train Epoch: 7 [1160/2566 (45%)]\tLoss: 0.324785\n",
      "Train Epoch: 7 [1200/2566 (47%)]\tLoss: 0.351255\n",
      "Train Epoch: 7 [1240/2566 (48%)]\tLoss: 0.350444\n",
      "Train Epoch: 7 [1280/2566 (50%)]\tLoss: 0.203854\n",
      "Train Epoch: 7 [1320/2566 (51%)]\tLoss: 0.490614\n",
      "Train Epoch: 7 [1360/2566 (53%)]\tLoss: 0.321597\n",
      "Train Epoch: 7 [1400/2566 (55%)]\tLoss: 0.422442\n",
      "Train Epoch: 7 [1440/2566 (56%)]\tLoss: 0.385867\n",
      "Train Epoch: 7 [1480/2566 (58%)]\tLoss: 0.230226\n",
      "Train Epoch: 7 [1520/2566 (59%)]\tLoss: 0.376528\n",
      "Train Epoch: 7 [1560/2566 (61%)]\tLoss: 0.134629\n",
      "Train Epoch: 7 [1600/2566 (62%)]\tLoss: 0.396102\n",
      "Train Epoch: 7 [1640/2566 (64%)]\tLoss: 0.206647\n",
      "Train Epoch: 7 [1680/2566 (65%)]\tLoss: 0.752328\n",
      "Train Epoch: 7 [1720/2566 (67%)]\tLoss: 0.234776\n",
      "Train Epoch: 7 [1760/2566 (69%)]\tLoss: 0.096185\n",
      "Train Epoch: 7 [1800/2566 (70%)]\tLoss: 0.487341\n",
      "Train Epoch: 7 [1840/2566 (72%)]\tLoss: 0.312504\n",
      "Train Epoch: 7 [1880/2566 (73%)]\tLoss: 0.585758\n",
      "Train Epoch: 7 [1920/2566 (75%)]\tLoss: 0.610970\n",
      "Train Epoch: 7 [1960/2566 (76%)]\tLoss: 0.085957\n",
      "Train Epoch: 7 [2000/2566 (78%)]\tLoss: 0.147469\n",
      "Train Epoch: 7 [2040/2566 (79%)]\tLoss: 0.269549\n",
      "Train Epoch: 7 [2080/2566 (81%)]\tLoss: 0.572890\n",
      "Train Epoch: 7 [2120/2566 (83%)]\tLoss: 0.661804\n",
      "Train Epoch: 7 [2160/2566 (84%)]\tLoss: 0.867290\n",
      "Train Epoch: 7 [2200/2566 (86%)]\tLoss: 0.210041\n",
      "Train Epoch: 7 [2240/2566 (87%)]\tLoss: 0.305674\n",
      "Train Epoch: 7 [2280/2566 (89%)]\tLoss: 0.614706\n",
      "Train Epoch: 7 [2320/2566 (90%)]\tLoss: 0.180640\n",
      "Train Epoch: 7 [2360/2566 (92%)]\tLoss: 0.436741\n",
      "Train Epoch: 7 [2400/2566 (93%)]\tLoss: 0.360933\n",
      "Train Epoch: 7 [2440/2566 (95%)]\tLoss: 0.369808\n",
      "Train Epoch: 7 [2480/2566 (97%)]\tLoss: 0.077853\n",
      "Train Epoch: 7 [2520/2566 (98%)]\tLoss: 0.385228\n",
      "Train Epoch: 7 [2560/2566 (100%)]\tLoss: 0.396390\n",
      "epoch:7,loss:0.35948273920195867\n",
      "Train set: Average loss: 0.2125, Accuracy: 2410/2566 (94%)\n",
      "Val set: Average loss: 0.4592, Accuracy: 270/327 (83%)\n",
      "Train Epoch: 8 [40/2566 (2%)]\tLoss: 0.211308\n",
      "Train Epoch: 8 [80/2566 (3%)]\tLoss: 0.770449\n",
      "Train Epoch: 8 [120/2566 (5%)]\tLoss: 0.331728\n",
      "Train Epoch: 8 [160/2566 (6%)]\tLoss: 0.421809\n",
      "Train Epoch: 8 [200/2566 (8%)]\tLoss: 0.154122\n",
      "Train Epoch: 8 [240/2566 (9%)]\tLoss: 0.338448\n",
      "Train Epoch: 8 [280/2566 (11%)]\tLoss: 0.438482\n",
      "Train Epoch: 8 [320/2566 (12%)]\tLoss: 0.602205\n",
      "Train Epoch: 8 [360/2566 (14%)]\tLoss: 0.217262\n",
      "Train Epoch: 8 [400/2566 (16%)]\tLoss: 0.415133\n",
      "Train Epoch: 8 [440/2566 (17%)]\tLoss: 0.136283\n",
      "Train Epoch: 8 [480/2566 (19%)]\tLoss: 0.106597\n",
      "Train Epoch: 8 [520/2566 (20%)]\tLoss: 0.225971\n",
      "Train Epoch: 8 [560/2566 (22%)]\tLoss: 0.332258\n",
      "Train Epoch: 8 [600/2566 (23%)]\tLoss: 0.246695\n",
      "Train Epoch: 8 [640/2566 (25%)]\tLoss: 0.144267\n",
      "Train Epoch: 8 [680/2566 (26%)]\tLoss: 0.878282\n",
      "Train Epoch: 8 [720/2566 (28%)]\tLoss: 0.236223\n",
      "Train Epoch: 8 [760/2566 (30%)]\tLoss: 0.190352\n",
      "Train Epoch: 8 [800/2566 (31%)]\tLoss: 0.135494\n",
      "Train Epoch: 8 [840/2566 (33%)]\tLoss: 0.348917\n",
      "Train Epoch: 8 [880/2566 (34%)]\tLoss: 0.593812\n",
      "Train Epoch: 8 [920/2566 (36%)]\tLoss: 0.496555\n",
      "Train Epoch: 8 [960/2566 (37%)]\tLoss: 1.123775\n",
      "Train Epoch: 8 [1000/2566 (39%)]\tLoss: 0.345841\n",
      "Train Epoch: 8 [1040/2566 (40%)]\tLoss: 0.161655\n",
      "Train Epoch: 8 [1080/2566 (42%)]\tLoss: 0.481217\n",
      "Train Epoch: 8 [1120/2566 (44%)]\tLoss: 0.252911\n",
      "Train Epoch: 8 [1160/2566 (45%)]\tLoss: 0.244502\n",
      "Train Epoch: 8 [1200/2566 (47%)]\tLoss: 0.161035\n",
      "Train Epoch: 8 [1240/2566 (48%)]\tLoss: 0.066548\n",
      "Train Epoch: 8 [1280/2566 (50%)]\tLoss: 0.365545\n",
      "Train Epoch: 8 [1320/2566 (51%)]\tLoss: 0.107385\n",
      "Train Epoch: 8 [1360/2566 (53%)]\tLoss: 0.577340\n",
      "Train Epoch: 8 [1400/2566 (55%)]\tLoss: 0.165054\n",
      "Train Epoch: 8 [1440/2566 (56%)]\tLoss: 0.220066\n",
      "Train Epoch: 8 [1480/2566 (58%)]\tLoss: 0.219361\n",
      "Train Epoch: 8 [1520/2566 (59%)]\tLoss: 0.584652\n",
      "Train Epoch: 8 [1560/2566 (61%)]\tLoss: 0.089972\n",
      "Train Epoch: 8 [1600/2566 (62%)]\tLoss: 0.096562\n",
      "Train Epoch: 8 [1640/2566 (64%)]\tLoss: 0.142949\n",
      "Train Epoch: 8 [1680/2566 (65%)]\tLoss: 0.098022\n",
      "Train Epoch: 8 [1720/2566 (67%)]\tLoss: 0.205701\n",
      "Train Epoch: 8 [1760/2566 (69%)]\tLoss: 0.167511\n",
      "Train Epoch: 8 [1800/2566 (70%)]\tLoss: 0.147469\n",
      "Train Epoch: 8 [1840/2566 (72%)]\tLoss: 0.516503\n",
      "Train Epoch: 8 [1880/2566 (73%)]\tLoss: 0.088502\n",
      "Train Epoch: 8 [1920/2566 (75%)]\tLoss: 0.094296\n",
      "Train Epoch: 8 [1960/2566 (76%)]\tLoss: 0.103789\n",
      "Train Epoch: 8 [2000/2566 (78%)]\tLoss: 0.636369\n",
      "Train Epoch: 8 [2040/2566 (79%)]\tLoss: 0.684770\n",
      "Train Epoch: 8 [2080/2566 (81%)]\tLoss: 0.200172\n",
      "Train Epoch: 8 [2120/2566 (83%)]\tLoss: 0.154587\n",
      "Train Epoch: 8 [2160/2566 (84%)]\tLoss: 0.248657\n",
      "Train Epoch: 8 [2200/2566 (86%)]\tLoss: 0.156867\n",
      "Train Epoch: 8 [2240/2566 (87%)]\tLoss: 0.310290\n",
      "Train Epoch: 8 [2280/2566 (89%)]\tLoss: 0.266766\n",
      "Train Epoch: 8 [2320/2566 (90%)]\tLoss: 0.372941\n",
      "Train Epoch: 8 [2360/2566 (92%)]\tLoss: 0.146405\n",
      "Train Epoch: 8 [2400/2566 (93%)]\tLoss: 0.125033\n",
      "Train Epoch: 8 [2440/2566 (95%)]\tLoss: 0.103356\n",
      "Train Epoch: 8 [2480/2566 (97%)]\tLoss: 0.648828\n",
      "Train Epoch: 8 [2520/2566 (98%)]\tLoss: 0.382000\n",
      "Train Epoch: 8 [2560/2566 (100%)]\tLoss: 0.172485\n",
      "epoch:8,loss:0.3149734581719121\n",
      "Train set: Average loss: 0.1589, Accuracy: 2473/2566 (96%)\n",
      "Val set: Average loss: 0.4503, Accuracy: 273/327 (83%)\n",
      "Train Epoch: 9 [40/2566 (2%)]\tLoss: 0.144311\n",
      "Train Epoch: 9 [80/2566 (3%)]\tLoss: 0.291036\n",
      "Train Epoch: 9 [120/2566 (5%)]\tLoss: 0.148926\n",
      "Train Epoch: 9 [160/2566 (6%)]\tLoss: 0.184813\n",
      "Train Epoch: 9 [200/2566 (8%)]\tLoss: 0.228115\n",
      "Train Epoch: 9 [240/2566 (9%)]\tLoss: 0.118655\n",
      "Train Epoch: 9 [280/2566 (11%)]\tLoss: 0.346429\n",
      "Train Epoch: 9 [320/2566 (12%)]\tLoss: 0.212298\n",
      "Train Epoch: 9 [360/2566 (14%)]\tLoss: 0.185014\n",
      "Train Epoch: 9 [400/2566 (16%)]\tLoss: 0.128348\n",
      "Train Epoch: 9 [440/2566 (17%)]\tLoss: 0.576294\n",
      "Train Epoch: 9 [480/2566 (19%)]\tLoss: 0.373108\n",
      "Train Epoch: 9 [520/2566 (20%)]\tLoss: 0.182276\n",
      "Train Epoch: 9 [560/2566 (22%)]\tLoss: 0.083733\n",
      "Train Epoch: 9 [600/2566 (23%)]\tLoss: 0.148419\n",
      "Train Epoch: 9 [640/2566 (25%)]\tLoss: 0.176607\n",
      "Train Epoch: 9 [680/2566 (26%)]\tLoss: 0.154351\n",
      "Train Epoch: 9 [720/2566 (28%)]\tLoss: 0.279046\n",
      "Train Epoch: 9 [760/2566 (30%)]\tLoss: 0.171929\n",
      "Train Epoch: 9 [800/2566 (31%)]\tLoss: 0.344435\n",
      "Train Epoch: 9 [840/2566 (33%)]\tLoss: 0.260726\n",
      "Train Epoch: 9 [880/2566 (34%)]\tLoss: 0.416000\n",
      "Train Epoch: 9 [920/2566 (36%)]\tLoss: 0.334882\n",
      "Train Epoch: 9 [960/2566 (37%)]\tLoss: 0.213009\n",
      "Train Epoch: 9 [1000/2566 (39%)]\tLoss: 0.214655\n",
      "Train Epoch: 9 [1040/2566 (40%)]\tLoss: 0.384341\n",
      "Train Epoch: 9 [1080/2566 (42%)]\tLoss: 0.243685\n",
      "Train Epoch: 9 [1120/2566 (44%)]\tLoss: 0.354970\n",
      "Train Epoch: 9 [1160/2566 (45%)]\tLoss: 0.069555\n",
      "Train Epoch: 9 [1200/2566 (47%)]\tLoss: 0.155558\n",
      "Train Epoch: 9 [1240/2566 (48%)]\tLoss: 0.271533\n",
      "Train Epoch: 9 [1280/2566 (50%)]\tLoss: 0.636304\n",
      "Train Epoch: 9 [1320/2566 (51%)]\tLoss: 0.204366\n",
      "Train Epoch: 9 [1360/2566 (53%)]\tLoss: 0.106374\n",
      "Train Epoch: 9 [1400/2566 (55%)]\tLoss: 0.692700\n",
      "Train Epoch: 9 [1440/2566 (56%)]\tLoss: 0.096928\n",
      "Train Epoch: 9 [1480/2566 (58%)]\tLoss: 0.120543\n",
      "Train Epoch: 9 [1520/2566 (59%)]\tLoss: 0.118146\n",
      "Train Epoch: 9 [1560/2566 (61%)]\tLoss: 0.783016\n",
      "Train Epoch: 9 [1600/2566 (62%)]\tLoss: 0.536394\n",
      "Train Epoch: 9 [1640/2566 (64%)]\tLoss: 0.119849\n",
      "Train Epoch: 9 [1680/2566 (65%)]\tLoss: 0.104539\n",
      "Train Epoch: 9 [1720/2566 (67%)]\tLoss: 0.163234\n",
      "Train Epoch: 9 [1760/2566 (69%)]\tLoss: 0.300375\n",
      "Train Epoch: 9 [1800/2566 (70%)]\tLoss: 0.130022\n",
      "Train Epoch: 9 [1840/2566 (72%)]\tLoss: 0.385265\n",
      "Train Epoch: 9 [1880/2566 (73%)]\tLoss: 0.246844\n",
      "Train Epoch: 9 [1920/2566 (75%)]\tLoss: 0.396383\n",
      "Train Epoch: 9 [1960/2566 (76%)]\tLoss: 0.339145\n",
      "Train Epoch: 9 [2000/2566 (78%)]\tLoss: 0.240666\n",
      "Train Epoch: 9 [2040/2566 (79%)]\tLoss: 0.135747\n",
      "Train Epoch: 9 [2080/2566 (81%)]\tLoss: 0.484333\n",
      "Train Epoch: 9 [2120/2566 (83%)]\tLoss: 0.600170\n",
      "Train Epoch: 9 [2160/2566 (84%)]\tLoss: 0.155377\n",
      "Train Epoch: 9 [2200/2566 (86%)]\tLoss: 0.343521\n",
      "Train Epoch: 9 [2240/2566 (87%)]\tLoss: 0.557960\n",
      "Train Epoch: 9 [2280/2566 (89%)]\tLoss: 0.189030\n",
      "Train Epoch: 9 [2320/2566 (90%)]\tLoss: 0.089869\n",
      "Train Epoch: 9 [2360/2566 (92%)]\tLoss: 0.195627\n",
      "Train Epoch: 9 [2400/2566 (93%)]\tLoss: 0.095312\n",
      "Train Epoch: 9 [2440/2566 (95%)]\tLoss: 0.359795\n",
      "Train Epoch: 9 [2480/2566 (97%)]\tLoss: 0.160502\n",
      "Train Epoch: 9 [2520/2566 (98%)]\tLoss: 0.298159\n",
      "Train Epoch: 9 [2560/2566 (100%)]\tLoss: 0.628191\n",
      "epoch:9,loss:0.29154726475291537\n",
      "Train set: Average loss: 0.1259, Accuracy: 2481/2566 (97%)\n",
      "Val set: Average loss: 0.4452, Accuracy: 274/327 (84%)\n",
      "Train Epoch: 10 [40/2566 (2%)]\tLoss: 0.114492\n",
      "Train Epoch: 10 [80/2566 (3%)]\tLoss: 0.088287\n",
      "Train Epoch: 10 [120/2566 (5%)]\tLoss: 0.072027\n",
      "Train Epoch: 10 [160/2566 (6%)]\tLoss: 0.401892\n",
      "Train Epoch: 10 [200/2566 (8%)]\tLoss: 0.256965\n",
      "Train Epoch: 10 [240/2566 (9%)]\tLoss: 0.509840\n",
      "Train Epoch: 10 [280/2566 (11%)]\tLoss: 0.181439\n",
      "Train Epoch: 10 [320/2566 (12%)]\tLoss: 0.251155\n",
      "Train Epoch: 10 [360/2566 (14%)]\tLoss: 0.315418\n",
      "Train Epoch: 10 [400/2566 (16%)]\tLoss: 0.365131\n",
      "Train Epoch: 10 [440/2566 (17%)]\tLoss: 0.219491\n",
      "Train Epoch: 10 [480/2566 (19%)]\tLoss: 0.362139\n",
      "Train Epoch: 10 [520/2566 (20%)]\tLoss: 0.838181\n",
      "Train Epoch: 10 [560/2566 (22%)]\tLoss: 0.322301\n",
      "Train Epoch: 10 [600/2566 (23%)]\tLoss: 0.271192\n",
      "Train Epoch: 10 [640/2566 (25%)]\tLoss: 0.295953\n",
      "Train Epoch: 10 [680/2566 (26%)]\tLoss: 0.101083\n",
      "Train Epoch: 10 [720/2566 (28%)]\tLoss: 0.087841\n",
      "Train Epoch: 10 [760/2566 (30%)]\tLoss: 0.096754\n",
      "Train Epoch: 10 [800/2566 (31%)]\tLoss: 0.237936\n",
      "Train Epoch: 10 [840/2566 (33%)]\tLoss: 0.252976\n",
      "Train Epoch: 10 [880/2566 (34%)]\tLoss: 0.370979\n",
      "Train Epoch: 10 [920/2566 (36%)]\tLoss: 0.235981\n",
      "Train Epoch: 10 [960/2566 (37%)]\tLoss: 0.475278\n",
      "Train Epoch: 10 [1000/2566 (39%)]\tLoss: 0.110356\n",
      "Train Epoch: 10 [1040/2566 (40%)]\tLoss: 0.198745\n",
      "Train Epoch: 10 [1080/2566 (42%)]\tLoss: 0.082035\n",
      "Train Epoch: 10 [1120/2566 (44%)]\tLoss: 0.282179\n",
      "Train Epoch: 10 [1160/2566 (45%)]\tLoss: 0.281059\n",
      "Train Epoch: 10 [1200/2566 (47%)]\tLoss: 0.169631\n",
      "Train Epoch: 10 [1240/2566 (48%)]\tLoss: 0.174868\n",
      "Train Epoch: 10 [1280/2566 (50%)]\tLoss: 0.220434\n",
      "Train Epoch: 10 [1320/2566 (51%)]\tLoss: 0.298950\n",
      "Train Epoch: 10 [1360/2566 (53%)]\tLoss: 0.374858\n",
      "Train Epoch: 10 [1400/2566 (55%)]\tLoss: 0.145307\n",
      "Train Epoch: 10 [1440/2566 (56%)]\tLoss: 0.228501\n",
      "Train Epoch: 10 [1480/2566 (58%)]\tLoss: 0.100380\n",
      "Train Epoch: 10 [1520/2566 (59%)]\tLoss: 0.050729\n",
      "Train Epoch: 10 [1560/2566 (61%)]\tLoss: 0.115290\n",
      "Train Epoch: 10 [1600/2566 (62%)]\tLoss: 0.153699\n",
      "Train Epoch: 10 [1640/2566 (64%)]\tLoss: 0.221367\n",
      "Train Epoch: 10 [1680/2566 (65%)]\tLoss: 0.128365\n",
      "Train Epoch: 10 [1720/2566 (67%)]\tLoss: 0.056395\n",
      "Train Epoch: 10 [1760/2566 (69%)]\tLoss: 0.250674\n",
      "Train Epoch: 10 [1800/2566 (70%)]\tLoss: 0.453677\n",
      "Train Epoch: 10 [1840/2566 (72%)]\tLoss: 0.114418\n",
      "Train Epoch: 10 [1880/2566 (73%)]\tLoss: 0.051824\n",
      "Train Epoch: 10 [1920/2566 (75%)]\tLoss: 0.189176\n",
      "Train Epoch: 10 [1960/2566 (76%)]\tLoss: 0.203145\n",
      "Train Epoch: 10 [2000/2566 (78%)]\tLoss: 0.417621\n",
      "Train Epoch: 10 [2040/2566 (79%)]\tLoss: 0.124355\n",
      "Train Epoch: 10 [2080/2566 (81%)]\tLoss: 0.414442\n",
      "Train Epoch: 10 [2120/2566 (83%)]\tLoss: 0.463849\n",
      "Train Epoch: 10 [2160/2566 (84%)]\tLoss: 0.082291\n",
      "Train Epoch: 10 [2200/2566 (86%)]\tLoss: 0.050900\n",
      "Train Epoch: 10 [2240/2566 (87%)]\tLoss: 0.045509\n",
      "Train Epoch: 10 [2280/2566 (89%)]\tLoss: 0.168512\n",
      "Train Epoch: 10 [2320/2566 (90%)]\tLoss: 0.104421\n",
      "Train Epoch: 10 [2360/2566 (92%)]\tLoss: 0.112835\n",
      "Train Epoch: 10 [2400/2566 (93%)]\tLoss: 0.430206\n",
      "Train Epoch: 10 [2440/2566 (95%)]\tLoss: 0.202378\n",
      "Train Epoch: 10 [2480/2566 (97%)]\tLoss: 0.157119\n",
      "Train Epoch: 10 [2520/2566 (98%)]\tLoss: 0.488476\n",
      "Train Epoch: 10 [2560/2566 (100%)]\tLoss: 0.075316\n",
      "epoch:10,loss:0.2368553055688228\n",
      "Train set: Average loss: 0.0972, Accuracy: 2508/2566 (98%)\n",
      "Val set: Average loss: 0.4726, Accuracy: 273/327 (83%)\n",
      "Train Epoch: 11 [40/2566 (2%)]\tLoss: 0.157276\n",
      "Train Epoch: 11 [80/2566 (3%)]\tLoss: 0.075506\n",
      "Train Epoch: 11 [120/2566 (5%)]\tLoss: 0.197239\n",
      "Train Epoch: 11 [160/2566 (6%)]\tLoss: 0.282216\n",
      "Train Epoch: 11 [200/2566 (8%)]\tLoss: 0.271291\n",
      "Train Epoch: 11 [240/2566 (9%)]\tLoss: 0.098584\n",
      "Train Epoch: 11 [280/2566 (11%)]\tLoss: 0.267004\n",
      "Train Epoch: 11 [320/2566 (12%)]\tLoss: 0.497399\n",
      "Train Epoch: 11 [360/2566 (14%)]\tLoss: 0.069646\n",
      "Train Epoch: 11 [400/2566 (16%)]\tLoss: 0.062569\n",
      "Train Epoch: 11 [440/2566 (17%)]\tLoss: 0.046436\n",
      "Train Epoch: 11 [480/2566 (19%)]\tLoss: 0.462685\n",
      "Train Epoch: 11 [520/2566 (20%)]\tLoss: 0.126399\n",
      "Train Epoch: 11 [560/2566 (22%)]\tLoss: 0.222346\n",
      "Train Epoch: 11 [600/2566 (23%)]\tLoss: 0.097157\n",
      "Train Epoch: 11 [640/2566 (25%)]\tLoss: 0.067666\n",
      "Train Epoch: 11 [680/2566 (26%)]\tLoss: 0.122445\n",
      "Train Epoch: 11 [720/2566 (28%)]\tLoss: 0.083427\n",
      "Train Epoch: 11 [760/2566 (30%)]\tLoss: 0.071419\n",
      "Train Epoch: 11 [800/2566 (31%)]\tLoss: 0.127641\n",
      "Train Epoch: 11 [840/2566 (33%)]\tLoss: 0.129984\n",
      "Train Epoch: 11 [880/2566 (34%)]\tLoss: 0.083291\n",
      "Train Epoch: 11 [920/2566 (36%)]\tLoss: 0.120278\n",
      "Train Epoch: 11 [960/2566 (37%)]\tLoss: 0.326287\n",
      "Train Epoch: 11 [1000/2566 (39%)]\tLoss: 0.101747\n",
      "Train Epoch: 11 [1040/2566 (40%)]\tLoss: 0.145514\n",
      "Train Epoch: 11 [1080/2566 (42%)]\tLoss: 0.215150\n",
      "Train Epoch: 11 [1120/2566 (44%)]\tLoss: 1.236034\n",
      "Train Epoch: 11 [1160/2566 (45%)]\tLoss: 0.143208\n",
      "Train Epoch: 11 [1200/2566 (47%)]\tLoss: 0.281922\n",
      "Train Epoch: 11 [1240/2566 (48%)]\tLoss: 0.703777\n",
      "Train Epoch: 11 [1280/2566 (50%)]\tLoss: 0.055153\n",
      "Train Epoch: 11 [1320/2566 (51%)]\tLoss: 0.365758\n",
      "Train Epoch: 11 [1360/2566 (53%)]\tLoss: 0.087633\n",
      "Train Epoch: 11 [1400/2566 (55%)]\tLoss: 0.462526\n",
      "Train Epoch: 11 [1440/2566 (56%)]\tLoss: 0.033029\n",
      "Train Epoch: 11 [1480/2566 (58%)]\tLoss: 0.391395\n",
      "Train Epoch: 11 [1520/2566 (59%)]\tLoss: 0.157713\n",
      "Train Epoch: 11 [1560/2566 (61%)]\tLoss: 0.668951\n",
      "Train Epoch: 11 [1600/2566 (62%)]\tLoss: 0.106004\n",
      "Train Epoch: 11 [1640/2566 (64%)]\tLoss: 0.205610\n",
      "Train Epoch: 11 [1680/2566 (65%)]\tLoss: 0.880536\n",
      "Train Epoch: 11 [1720/2566 (67%)]\tLoss: 0.428831\n",
      "Train Epoch: 11 [1760/2566 (69%)]\tLoss: 0.422311\n",
      "Train Epoch: 11 [1800/2566 (70%)]\tLoss: 0.887490\n",
      "Train Epoch: 11 [1840/2566 (72%)]\tLoss: 0.107634\n",
      "Train Epoch: 11 [1880/2566 (73%)]\tLoss: 0.233657\n",
      "Train Epoch: 11 [1920/2566 (75%)]\tLoss: 0.228957\n",
      "Train Epoch: 11 [1960/2566 (76%)]\tLoss: 0.350353\n",
      "Train Epoch: 11 [2000/2566 (78%)]\tLoss: 0.097489\n",
      "Train Epoch: 11 [2040/2566 (79%)]\tLoss: 0.192112\n",
      "Train Epoch: 11 [2080/2566 (81%)]\tLoss: 0.303022\n",
      "Train Epoch: 11 [2120/2566 (83%)]\tLoss: 0.249622\n",
      "Train Epoch: 11 [2160/2566 (84%)]\tLoss: 0.168707\n",
      "Train Epoch: 11 [2200/2566 (86%)]\tLoss: 0.314039\n",
      "Train Epoch: 11 [2240/2566 (87%)]\tLoss: 0.063393\n",
      "Train Epoch: 11 [2280/2566 (89%)]\tLoss: 0.094508\n",
      "Train Epoch: 11 [2320/2566 (90%)]\tLoss: 0.651325\n",
      "Train Epoch: 11 [2360/2566 (92%)]\tLoss: 0.086311\n",
      "Train Epoch: 11 [2400/2566 (93%)]\tLoss: 0.175609\n",
      "Train Epoch: 11 [2440/2566 (95%)]\tLoss: 0.057307\n",
      "Train Epoch: 11 [2480/2566 (97%)]\tLoss: 0.119184\n",
      "Train Epoch: 11 [2520/2566 (98%)]\tLoss: 0.386830\n",
      "Train Epoch: 11 [2560/2566 (100%)]\tLoss: 0.950101\n",
      "epoch:11,loss:0.2507021889740433\n",
      "Train set: Average loss: 0.0832, Accuracy: 2523/2566 (98%)\n",
      "Val set: Average loss: 0.4790, Accuracy: 278/327 (85%)\n",
      "Train Epoch: 12 [40/2566 (2%)]\tLoss: 0.235119\n",
      "Train Epoch: 12 [80/2566 (3%)]\tLoss: 0.075546\n",
      "Train Epoch: 12 [120/2566 (5%)]\tLoss: 0.129853\n",
      "Train Epoch: 12 [160/2566 (6%)]\tLoss: 0.091871\n",
      "Train Epoch: 12 [200/2566 (8%)]\tLoss: 0.066000\n",
      "Train Epoch: 12 [240/2566 (9%)]\tLoss: 0.089816\n",
      "Train Epoch: 12 [280/2566 (11%)]\tLoss: 0.091064\n",
      "Train Epoch: 12 [320/2566 (12%)]\tLoss: 0.465606\n",
      "Train Epoch: 12 [360/2566 (14%)]\tLoss: 0.233335\n",
      "Train Epoch: 12 [400/2566 (16%)]\tLoss: 0.157452\n",
      "Train Epoch: 12 [440/2566 (17%)]\tLoss: 0.261086\n",
      "Train Epoch: 12 [480/2566 (19%)]\tLoss: 0.094445\n",
      "Train Epoch: 12 [520/2566 (20%)]\tLoss: 0.087407\n",
      "Train Epoch: 12 [560/2566 (22%)]\tLoss: 0.088048\n",
      "Train Epoch: 12 [600/2566 (23%)]\tLoss: 0.139308\n",
      "Train Epoch: 12 [640/2566 (25%)]\tLoss: 0.099873\n",
      "Train Epoch: 12 [680/2566 (26%)]\tLoss: 0.179243\n",
      "Train Epoch: 12 [720/2566 (28%)]\tLoss: 0.376173\n",
      "Train Epoch: 12 [760/2566 (30%)]\tLoss: 0.100188\n",
      "Train Epoch: 12 [800/2566 (31%)]\tLoss: 0.207198\n",
      "Train Epoch: 12 [840/2566 (33%)]\tLoss: 0.187133\n",
      "Train Epoch: 12 [880/2566 (34%)]\tLoss: 0.460485\n",
      "Train Epoch: 12 [920/2566 (36%)]\tLoss: 0.097534\n",
      "Train Epoch: 12 [960/2566 (37%)]\tLoss: 0.391441\n",
      "Train Epoch: 12 [1000/2566 (39%)]\tLoss: 0.040042\n",
      "Train Epoch: 12 [1040/2566 (40%)]\tLoss: 0.153279\n",
      "Train Epoch: 12 [1080/2566 (42%)]\tLoss: 0.210722\n",
      "Train Epoch: 12 [1120/2566 (44%)]\tLoss: 0.583173\n",
      "Train Epoch: 12 [1160/2566 (45%)]\tLoss: 0.037866\n",
      "Train Epoch: 12 [1200/2566 (47%)]\tLoss: 0.060634\n",
      "Train Epoch: 12 [1240/2566 (48%)]\tLoss: 0.137751\n",
      "Train Epoch: 12 [1280/2566 (50%)]\tLoss: 0.099008\n",
      "Train Epoch: 12 [1320/2566 (51%)]\tLoss: 0.088951\n",
      "Train Epoch: 12 [1360/2566 (53%)]\tLoss: 0.196584\n",
      "Train Epoch: 12 [1400/2566 (55%)]\tLoss: 0.114796\n",
      "Train Epoch: 12 [1440/2566 (56%)]\tLoss: 0.086073\n",
      "Train Epoch: 12 [1480/2566 (58%)]\tLoss: 0.367345\n",
      "Train Epoch: 12 [1520/2566 (59%)]\tLoss: 0.169347\n",
      "Train Epoch: 12 [1560/2566 (61%)]\tLoss: 0.157948\n",
      "Train Epoch: 12 [1600/2566 (62%)]\tLoss: 0.196320\n",
      "Train Epoch: 12 [1640/2566 (64%)]\tLoss: 0.229776\n",
      "Train Epoch: 12 [1680/2566 (65%)]\tLoss: 0.147663\n",
      "Train Epoch: 12 [1720/2566 (67%)]\tLoss: 0.255027\n",
      "Train Epoch: 12 [1760/2566 (69%)]\tLoss: 0.136641\n",
      "Train Epoch: 12 [1800/2566 (70%)]\tLoss: 0.320539\n",
      "Train Epoch: 12 [1840/2566 (72%)]\tLoss: 0.087343\n",
      "Train Epoch: 12 [1880/2566 (73%)]\tLoss: 0.106877\n",
      "Train Epoch: 12 [1920/2566 (75%)]\tLoss: 0.083223\n",
      "Train Epoch: 12 [1960/2566 (76%)]\tLoss: 0.096431\n",
      "Train Epoch: 12 [2000/2566 (78%)]\tLoss: 0.047464\n",
      "Train Epoch: 12 [2040/2566 (79%)]\tLoss: 0.158876\n",
      "Train Epoch: 12 [2080/2566 (81%)]\tLoss: 0.188128\n",
      "Train Epoch: 12 [2120/2566 (83%)]\tLoss: 0.290200\n",
      "Train Epoch: 12 [2160/2566 (84%)]\tLoss: 0.084571\n",
      "Train Epoch: 12 [2200/2566 (86%)]\tLoss: 0.166257\n",
      "Train Epoch: 12 [2240/2566 (87%)]\tLoss: 0.080057\n",
      "Train Epoch: 12 [2280/2566 (89%)]\tLoss: 0.211947\n",
      "Train Epoch: 12 [2320/2566 (90%)]\tLoss: 0.232159\n",
      "Train Epoch: 12 [2360/2566 (92%)]\tLoss: 0.113532\n",
      "Train Epoch: 12 [2400/2566 (93%)]\tLoss: 0.229034\n",
      "Train Epoch: 12 [2440/2566 (95%)]\tLoss: 0.076895\n",
      "Train Epoch: 12 [2480/2566 (97%)]\tLoss: 0.046546\n",
      "Train Epoch: 12 [2520/2566 (98%)]\tLoss: 0.207158\n",
      "Train Epoch: 12 [2560/2566 (100%)]\tLoss: 0.078802\n",
      "epoch:12,loss:0.18406701192979316\n",
      "Train set: Average loss: 0.0604, Accuracy: 2538/2566 (99%)\n",
      "Val set: Average loss: 0.4954, Accuracy: 272/327 (83%)\n",
      "Train Epoch: 13 [40/2566 (2%)]\tLoss: 0.170029\n",
      "Train Epoch: 13 [80/2566 (3%)]\tLoss: 0.069826\n",
      "Train Epoch: 13 [120/2566 (5%)]\tLoss: 0.472794\n",
      "Train Epoch: 13 [160/2566 (6%)]\tLoss: 0.154826\n",
      "Train Epoch: 13 [200/2566 (8%)]\tLoss: 0.090812\n",
      "Train Epoch: 13 [240/2566 (9%)]\tLoss: 0.230034\n",
      "Train Epoch: 13 [280/2566 (11%)]\tLoss: 0.155926\n",
      "Train Epoch: 13 [320/2566 (12%)]\tLoss: 0.071307\n",
      "Train Epoch: 13 [360/2566 (14%)]\tLoss: 0.095187\n",
      "Train Epoch: 13 [400/2566 (16%)]\tLoss: 0.159598\n",
      "Train Epoch: 13 [440/2566 (17%)]\tLoss: 0.063441\n",
      "Train Epoch: 13 [480/2566 (19%)]\tLoss: 0.117683\n",
      "Train Epoch: 13 [520/2566 (20%)]\tLoss: 0.034954\n",
      "Train Epoch: 13 [560/2566 (22%)]\tLoss: 0.289165\n",
      "Train Epoch: 13 [600/2566 (23%)]\tLoss: 0.102285\n",
      "Train Epoch: 13 [640/2566 (25%)]\tLoss: 0.040343\n",
      "Train Epoch: 13 [680/2566 (26%)]\tLoss: 0.107909\n",
      "Train Epoch: 13 [720/2566 (28%)]\tLoss: 0.206490\n",
      "Train Epoch: 13 [760/2566 (30%)]\tLoss: 0.095330\n",
      "Train Epoch: 13 [800/2566 (31%)]\tLoss: 0.229453\n",
      "Train Epoch: 13 [840/2566 (33%)]\tLoss: 0.073901\n",
      "Train Epoch: 13 [880/2566 (34%)]\tLoss: 0.567151\n",
      "Train Epoch: 13 [920/2566 (36%)]\tLoss: 0.219183\n",
      "Train Epoch: 13 [960/2566 (37%)]\tLoss: 0.212620\n",
      "Train Epoch: 13 [1000/2566 (39%)]\tLoss: 0.045039\n",
      "Train Epoch: 13 [1040/2566 (40%)]\tLoss: 0.258602\n",
      "Train Epoch: 13 [1080/2566 (42%)]\tLoss: 0.218644\n",
      "Train Epoch: 13 [1120/2566 (44%)]\tLoss: 0.159990\n",
      "Train Epoch: 13 [1160/2566 (45%)]\tLoss: 0.186441\n",
      "Train Epoch: 13 [1200/2566 (47%)]\tLoss: 0.264572\n",
      "Train Epoch: 13 [1240/2566 (48%)]\tLoss: 0.283327\n",
      "Train Epoch: 13 [1280/2566 (50%)]\tLoss: 0.039662\n",
      "Train Epoch: 13 [1320/2566 (51%)]\tLoss: 0.089102\n",
      "Train Epoch: 13 [1360/2566 (53%)]\tLoss: 0.241501\n",
      "Train Epoch: 13 [1400/2566 (55%)]\tLoss: 0.329859\n",
      "Train Epoch: 13 [1440/2566 (56%)]\tLoss: 0.049000\n",
      "Train Epoch: 13 [1480/2566 (58%)]\tLoss: 0.029912\n",
      "Train Epoch: 13 [1520/2566 (59%)]\tLoss: 0.050501\n",
      "Train Epoch: 13 [1560/2566 (61%)]\tLoss: 0.288662\n",
      "Train Epoch: 13 [1600/2566 (62%)]\tLoss: 0.040690\n",
      "Train Epoch: 13 [1640/2566 (64%)]\tLoss: 0.059840\n",
      "Train Epoch: 13 [1680/2566 (65%)]\tLoss: 0.078786\n",
      "Train Epoch: 13 [1720/2566 (67%)]\tLoss: 0.513440\n",
      "Train Epoch: 13 [1760/2566 (69%)]\tLoss: 0.126365\n",
      "Train Epoch: 13 [1800/2566 (70%)]\tLoss: 0.097357\n",
      "Train Epoch: 13 [1840/2566 (72%)]\tLoss: 0.024398\n",
      "Train Epoch: 13 [1880/2566 (73%)]\tLoss: 0.189046\n",
      "Train Epoch: 13 [1920/2566 (75%)]\tLoss: 0.088558\n",
      "Train Epoch: 13 [1960/2566 (76%)]\tLoss: 0.056428\n",
      "Train Epoch: 13 [2000/2566 (78%)]\tLoss: 0.242789\n",
      "Train Epoch: 13 [2040/2566 (79%)]\tLoss: 0.359379\n",
      "Train Epoch: 13 [2080/2566 (81%)]\tLoss: 0.057025\n",
      "Train Epoch: 13 [2120/2566 (83%)]\tLoss: 0.097197\n",
      "Train Epoch: 13 [2160/2566 (84%)]\tLoss: 0.051337\n",
      "Train Epoch: 13 [2200/2566 (86%)]\tLoss: 0.059393\n",
      "Train Epoch: 13 [2240/2566 (87%)]\tLoss: 0.186705\n",
      "Train Epoch: 13 [2280/2566 (89%)]\tLoss: 0.121289\n",
      "Train Epoch: 13 [2320/2566 (90%)]\tLoss: 0.127796\n",
      "Train Epoch: 13 [2360/2566 (92%)]\tLoss: 0.134842\n",
      "Train Epoch: 13 [2400/2566 (93%)]\tLoss: 0.293552\n",
      "Train Epoch: 13 [2440/2566 (95%)]\tLoss: 0.057101\n",
      "Train Epoch: 13 [2480/2566 (97%)]\tLoss: 0.408753\n",
      "Train Epoch: 13 [2520/2566 (98%)]\tLoss: 0.087350\n",
      "Train Epoch: 13 [2560/2566 (100%)]\tLoss: 0.051403\n",
      "epoch:13,loss:0.1588639377085405\n",
      "Train set: Average loss: 0.0501, Accuracy: 2543/2566 (99%)\n",
      "Val set: Average loss: 0.4924, Accuracy: 271/327 (83%)\n",
      "Train Epoch: 14 [40/2566 (2%)]\tLoss: 0.145211\n",
      "Train Epoch: 14 [80/2566 (3%)]\tLoss: 0.055457\n",
      "Train Epoch: 14 [120/2566 (5%)]\tLoss: 0.045270\n",
      "Train Epoch: 14 [160/2566 (6%)]\tLoss: 0.055083\n",
      "Train Epoch: 14 [200/2566 (8%)]\tLoss: 0.265470\n",
      "Train Epoch: 14 [240/2566 (9%)]\tLoss: 0.160158\n",
      "Train Epoch: 14 [280/2566 (11%)]\tLoss: 0.218322\n",
      "Train Epoch: 14 [320/2566 (12%)]\tLoss: 0.061189\n",
      "Train Epoch: 14 [360/2566 (14%)]\tLoss: 0.088159\n",
      "Train Epoch: 14 [400/2566 (16%)]\tLoss: 0.145817\n",
      "Train Epoch: 14 [440/2566 (17%)]\tLoss: 0.052855\n",
      "Train Epoch: 14 [480/2566 (19%)]\tLoss: 0.105201\n",
      "Train Epoch: 14 [520/2566 (20%)]\tLoss: 0.430219\n",
      "Train Epoch: 14 [560/2566 (22%)]\tLoss: 0.135328\n",
      "Train Epoch: 14 [600/2566 (23%)]\tLoss: 0.017374\n",
      "Train Epoch: 14 [640/2566 (25%)]\tLoss: 0.130679\n",
      "Train Epoch: 14 [680/2566 (26%)]\tLoss: 0.008531\n",
      "Train Epoch: 14 [720/2566 (28%)]\tLoss: 0.386868\n",
      "Train Epoch: 14 [760/2566 (30%)]\tLoss: 0.105213\n",
      "Train Epoch: 14 [800/2566 (31%)]\tLoss: 0.026094\n",
      "Train Epoch: 14 [840/2566 (33%)]\tLoss: 0.323308\n",
      "Train Epoch: 14 [880/2566 (34%)]\tLoss: 0.153664\n",
      "Train Epoch: 14 [920/2566 (36%)]\tLoss: 0.325463\n",
      "Train Epoch: 14 [960/2566 (37%)]\tLoss: 0.498593\n",
      "Train Epoch: 14 [1000/2566 (39%)]\tLoss: 0.141883\n",
      "Train Epoch: 14 [1040/2566 (40%)]\tLoss: 0.062527\n",
      "Train Epoch: 14 [1080/2566 (42%)]\tLoss: 0.017005\n",
      "Train Epoch: 14 [1120/2566 (44%)]\tLoss: 0.204723\n",
      "Train Epoch: 14 [1160/2566 (45%)]\tLoss: 0.272826\n",
      "Train Epoch: 14 [1200/2566 (47%)]\tLoss: 0.022942\n",
      "Train Epoch: 14 [1240/2566 (48%)]\tLoss: 0.152240\n",
      "Train Epoch: 14 [1280/2566 (50%)]\tLoss: 0.115804\n",
      "Train Epoch: 14 [1320/2566 (51%)]\tLoss: 0.040715\n",
      "Train Epoch: 14 [1360/2566 (53%)]\tLoss: 0.029292\n",
      "Train Epoch: 14 [1400/2566 (55%)]\tLoss: 0.403726\n",
      "Train Epoch: 14 [1440/2566 (56%)]\tLoss: 0.145218\n",
      "Train Epoch: 14 [1480/2566 (58%)]\tLoss: 0.035171\n",
      "Train Epoch: 14 [1520/2566 (59%)]\tLoss: 0.318739\n",
      "Train Epoch: 14 [1560/2566 (61%)]\tLoss: 0.137252\n",
      "Train Epoch: 14 [1600/2566 (62%)]\tLoss: 0.423499\n",
      "Train Epoch: 14 [1640/2566 (64%)]\tLoss: 0.024065\n",
      "Train Epoch: 14 [1680/2566 (65%)]\tLoss: 0.722763\n",
      "Train Epoch: 14 [1720/2566 (67%)]\tLoss: 0.024012\n",
      "Train Epoch: 14 [1760/2566 (69%)]\tLoss: 0.080120\n",
      "Train Epoch: 14 [1800/2566 (70%)]\tLoss: 0.267105\n",
      "Train Epoch: 14 [1840/2566 (72%)]\tLoss: 0.097447\n",
      "Train Epoch: 14 [1880/2566 (73%)]\tLoss: 0.055668\n",
      "Train Epoch: 14 [1920/2566 (75%)]\tLoss: 0.141682\n",
      "Train Epoch: 14 [1960/2566 (76%)]\tLoss: 0.030481\n",
      "Train Epoch: 14 [2000/2566 (78%)]\tLoss: 0.145741\n",
      "Train Epoch: 14 [2040/2566 (79%)]\tLoss: 0.051310\n",
      "Train Epoch: 14 [2080/2566 (81%)]\tLoss: 0.045987\n",
      "Train Epoch: 14 [2120/2566 (83%)]\tLoss: 0.166898\n",
      "Train Epoch: 14 [2160/2566 (84%)]\tLoss: 0.043602\n",
      "Train Epoch: 14 [2200/2566 (86%)]\tLoss: 0.041932\n",
      "Train Epoch: 14 [2240/2566 (87%)]\tLoss: 0.276801\n",
      "Train Epoch: 14 [2280/2566 (89%)]\tLoss: 0.127036\n",
      "Train Epoch: 14 [2320/2566 (90%)]\tLoss: 0.124145\n",
      "Train Epoch: 14 [2360/2566 (92%)]\tLoss: 0.214993\n",
      "Train Epoch: 14 [2400/2566 (93%)]\tLoss: 0.023744\n",
      "Train Epoch: 14 [2440/2566 (95%)]\tLoss: 0.177061\n",
      "Train Epoch: 14 [2480/2566 (97%)]\tLoss: 0.162386\n",
      "Train Epoch: 14 [2520/2566 (98%)]\tLoss: 0.326457\n",
      "Train Epoch: 14 [2560/2566 (100%)]\tLoss: 0.075079\n",
      "epoch:14,loss:0.14462121912913622\n",
      "Train set: Average loss: 0.0505, Accuracy: 2536/2566 (99%)\n",
      "Val set: Average loss: 0.5377, Accuracy: 271/327 (83%)\n",
      "Train Epoch: 15 [40/2566 (2%)]\tLoss: 0.072719\n",
      "Train Epoch: 15 [80/2566 (3%)]\tLoss: 0.198986\n",
      "Train Epoch: 15 [120/2566 (5%)]\tLoss: 0.051565\n",
      "Train Epoch: 15 [160/2566 (6%)]\tLoss: 0.124475\n",
      "Train Epoch: 15 [200/2566 (8%)]\tLoss: 0.023652\n",
      "Train Epoch: 15 [240/2566 (9%)]\tLoss: 0.417674\n",
      "Train Epoch: 15 [280/2566 (11%)]\tLoss: 0.130554\n",
      "Train Epoch: 15 [320/2566 (12%)]\tLoss: 0.046493\n",
      "Train Epoch: 15 [360/2566 (14%)]\tLoss: 0.033975\n",
      "Train Epoch: 15 [400/2566 (16%)]\tLoss: 0.061132\n",
      "Train Epoch: 15 [440/2566 (17%)]\tLoss: 0.079035\n",
      "Train Epoch: 15 [480/2566 (19%)]\tLoss: 0.066393\n",
      "Train Epoch: 15 [520/2566 (20%)]\tLoss: 0.150886\n",
      "Train Epoch: 15 [560/2566 (22%)]\tLoss: 0.047155\n",
      "Train Epoch: 15 [600/2566 (23%)]\tLoss: 0.049124\n",
      "Train Epoch: 15 [640/2566 (25%)]\tLoss: 0.170860\n",
      "Train Epoch: 15 [680/2566 (26%)]\tLoss: 0.138797\n",
      "Train Epoch: 15 [720/2566 (28%)]\tLoss: 0.035737\n",
      "Train Epoch: 15 [760/2566 (30%)]\tLoss: 0.070183\n",
      "Train Epoch: 15 [800/2566 (31%)]\tLoss: 0.053891\n",
      "Train Epoch: 15 [840/2566 (33%)]\tLoss: 0.100284\n",
      "Train Epoch: 15 [880/2566 (34%)]\tLoss: 0.130631\n",
      "Train Epoch: 15 [920/2566 (36%)]\tLoss: 0.052262\n",
      "Train Epoch: 15 [960/2566 (37%)]\tLoss: 0.011751\n",
      "Train Epoch: 15 [1000/2566 (39%)]\tLoss: 0.013990\n",
      "Train Epoch: 15 [1040/2566 (40%)]\tLoss: 0.146993\n",
      "Train Epoch: 15 [1080/2566 (42%)]\tLoss: 0.027918\n",
      "Train Epoch: 15 [1120/2566 (44%)]\tLoss: 0.036946\n",
      "Train Epoch: 15 [1160/2566 (45%)]\tLoss: 0.094448\n",
      "Train Epoch: 15 [1200/2566 (47%)]\tLoss: 0.389260\n",
      "Train Epoch: 15 [1240/2566 (48%)]\tLoss: 0.023365\n",
      "Train Epoch: 15 [1280/2566 (50%)]\tLoss: 0.027110\n",
      "Train Epoch: 15 [1320/2566 (51%)]\tLoss: 0.089374\n",
      "Train Epoch: 15 [1360/2566 (53%)]\tLoss: 0.210231\n",
      "Train Epoch: 15 [1400/2566 (55%)]\tLoss: 0.126813\n",
      "Train Epoch: 15 [1440/2566 (56%)]\tLoss: 0.114926\n",
      "Train Epoch: 15 [1480/2566 (58%)]\tLoss: 0.041728\n",
      "Train Epoch: 15 [1520/2566 (59%)]\tLoss: 0.921398\n",
      "Train Epoch: 15 [1560/2566 (61%)]\tLoss: 0.274694\n",
      "Train Epoch: 15 [1600/2566 (62%)]\tLoss: 0.010785\n",
      "Train Epoch: 15 [1640/2566 (64%)]\tLoss: 0.026372\n",
      "Train Epoch: 15 [1680/2566 (65%)]\tLoss: 0.015823\n",
      "Train Epoch: 15 [1720/2566 (67%)]\tLoss: 0.052167\n",
      "Train Epoch: 15 [1760/2566 (69%)]\tLoss: 0.270740\n",
      "Train Epoch: 15 [1800/2566 (70%)]\tLoss: 0.113826\n",
      "Train Epoch: 15 [1840/2566 (72%)]\tLoss: 0.229151\n",
      "Train Epoch: 15 [1880/2566 (73%)]\tLoss: 0.114346\n",
      "Train Epoch: 15 [1920/2566 (75%)]\tLoss: 0.182938\n",
      "Train Epoch: 15 [1960/2566 (76%)]\tLoss: 0.202401\n",
      "Train Epoch: 15 [2000/2566 (78%)]\tLoss: 0.185042\n",
      "Train Epoch: 15 [2040/2566 (79%)]\tLoss: 0.071469\n",
      "Train Epoch: 15 [2080/2566 (81%)]\tLoss: 0.054162\n",
      "Train Epoch: 15 [2120/2566 (83%)]\tLoss: 0.190264\n",
      "Train Epoch: 15 [2160/2566 (84%)]\tLoss: 0.069466\n",
      "Train Epoch: 15 [2200/2566 (86%)]\tLoss: 0.035145\n",
      "Train Epoch: 15 [2240/2566 (87%)]\tLoss: 0.160953\n",
      "Train Epoch: 15 [2280/2566 (89%)]\tLoss: 0.206738\n",
      "Train Epoch: 15 [2320/2566 (90%)]\tLoss: 0.060711\n",
      "Train Epoch: 15 [2360/2566 (92%)]\tLoss: 0.418623\n",
      "Train Epoch: 15 [2400/2566 (93%)]\tLoss: 0.025207\n",
      "Train Epoch: 15 [2440/2566 (95%)]\tLoss: 0.066205\n",
      "Train Epoch: 15 [2480/2566 (97%)]\tLoss: 0.066506\n",
      "Train Epoch: 15 [2520/2566 (98%)]\tLoss: 0.029788\n",
      "Train Epoch: 15 [2560/2566 (100%)]\tLoss: 0.322058\n",
      "epoch:15,loss:0.131289801612566\n",
      "Train set: Average loss: 0.0425, Accuracy: 2538/2566 (99%)\n",
      "Val set: Average loss: 0.5083, Accuracy: 272/327 (83%)\n",
      "Train Epoch: 16 [40/2566 (2%)]\tLoss: 0.169446\n",
      "Train Epoch: 16 [80/2566 (3%)]\tLoss: 0.148153\n",
      "Train Epoch: 16 [120/2566 (5%)]\tLoss: 0.053307\n",
      "Train Epoch: 16 [160/2566 (6%)]\tLoss: 0.112795\n",
      "Train Epoch: 16 [200/2566 (8%)]\tLoss: 0.087798\n",
      "Train Epoch: 16 [240/2566 (9%)]\tLoss: 0.187558\n",
      "Train Epoch: 16 [280/2566 (11%)]\tLoss: 0.092427\n",
      "Train Epoch: 16 [320/2566 (12%)]\tLoss: 0.064511\n",
      "Train Epoch: 16 [360/2566 (14%)]\tLoss: 0.150395\n",
      "Train Epoch: 16 [400/2566 (16%)]\tLoss: 0.023467\n",
      "Train Epoch: 16 [440/2566 (17%)]\tLoss: 0.175842\n",
      "Train Epoch: 16 [480/2566 (19%)]\tLoss: 0.293137\n",
      "Train Epoch: 16 [520/2566 (20%)]\tLoss: 0.054411\n",
      "Train Epoch: 16 [560/2566 (22%)]\tLoss: 0.251314\n",
      "Train Epoch: 16 [600/2566 (23%)]\tLoss: 0.045425\n",
      "Train Epoch: 16 [640/2566 (25%)]\tLoss: 0.109287\n",
      "Train Epoch: 16 [680/2566 (26%)]\tLoss: 0.047680\n",
      "Train Epoch: 16 [720/2566 (28%)]\tLoss: 0.053234\n",
      "Train Epoch: 16 [760/2566 (30%)]\tLoss: 0.029154\n",
      "Train Epoch: 16 [800/2566 (31%)]\tLoss: 0.437311\n",
      "Train Epoch: 16 [840/2566 (33%)]\tLoss: 0.021756\n",
      "Train Epoch: 16 [880/2566 (34%)]\tLoss: 0.153694\n",
      "Train Epoch: 16 [920/2566 (36%)]\tLoss: 0.074347\n",
      "Train Epoch: 16 [960/2566 (37%)]\tLoss: 0.105544\n",
      "Train Epoch: 16 [1000/2566 (39%)]\tLoss: 0.138612\n",
      "Train Epoch: 16 [1040/2566 (40%)]\tLoss: 0.086284\n",
      "Train Epoch: 16 [1080/2566 (42%)]\tLoss: 0.293595\n",
      "Train Epoch: 16 [1120/2566 (44%)]\tLoss: 0.151085\n",
      "Train Epoch: 16 [1160/2566 (45%)]\tLoss: 0.027829\n",
      "Train Epoch: 16 [1200/2566 (47%)]\tLoss: 0.097006\n",
      "Train Epoch: 16 [1240/2566 (48%)]\tLoss: 0.098312\n",
      "Train Epoch: 16 [1280/2566 (50%)]\tLoss: 0.138980\n",
      "Train Epoch: 16 [1320/2566 (51%)]\tLoss: 0.030301\n",
      "Train Epoch: 16 [1360/2566 (53%)]\tLoss: 0.033119\n",
      "Train Epoch: 16 [1400/2566 (55%)]\tLoss: 0.067536\n",
      "Train Epoch: 16 [1440/2566 (56%)]\tLoss: 0.256356\n",
      "Train Epoch: 16 [1480/2566 (58%)]\tLoss: 0.031795\n",
      "Train Epoch: 16 [1520/2566 (59%)]\tLoss: 0.202678\n",
      "Train Epoch: 16 [1560/2566 (61%)]\tLoss: 0.792450\n",
      "Train Epoch: 16 [1600/2566 (62%)]\tLoss: 0.051586\n",
      "Train Epoch: 16 [1640/2566 (64%)]\tLoss: 0.255641\n",
      "Train Epoch: 16 [1680/2566 (65%)]\tLoss: 0.295630\n",
      "Train Epoch: 16 [1720/2566 (67%)]\tLoss: 0.043451\n",
      "Train Epoch: 16 [1760/2566 (69%)]\tLoss: 0.050364\n",
      "Train Epoch: 16 [1800/2566 (70%)]\tLoss: 0.140378\n",
      "Train Epoch: 16 [1840/2566 (72%)]\tLoss: 0.152426\n",
      "Train Epoch: 16 [1880/2566 (73%)]\tLoss: 0.138015\n",
      "Train Epoch: 16 [1920/2566 (75%)]\tLoss: 0.016271\n",
      "Train Epoch: 16 [1960/2566 (76%)]\tLoss: 0.155574\n",
      "Train Epoch: 16 [2000/2566 (78%)]\tLoss: 0.029144\n",
      "Train Epoch: 16 [2040/2566 (79%)]\tLoss: 0.125074\n",
      "Train Epoch: 16 [2080/2566 (81%)]\tLoss: 0.004809\n",
      "Train Epoch: 16 [2120/2566 (83%)]\tLoss: 0.269514\n",
      "Train Epoch: 16 [2160/2566 (84%)]\tLoss: 0.037168\n",
      "Train Epoch: 16 [2200/2566 (86%)]\tLoss: 0.021769\n",
      "Train Epoch: 16 [2240/2566 (87%)]\tLoss: 0.016601\n",
      "Train Epoch: 16 [2280/2566 (89%)]\tLoss: 0.036704\n",
      "Train Epoch: 16 [2320/2566 (90%)]\tLoss: 0.065945\n",
      "Train Epoch: 16 [2360/2566 (92%)]\tLoss: 0.061022\n",
      "Train Epoch: 16 [2400/2566 (93%)]\tLoss: 0.180654\n",
      "Train Epoch: 16 [2440/2566 (95%)]\tLoss: 0.028879\n",
      "Train Epoch: 16 [2480/2566 (97%)]\tLoss: 0.182263\n",
      "Train Epoch: 16 [2520/2566 (98%)]\tLoss: 0.123958\n",
      "Train Epoch: 16 [2560/2566 (100%)]\tLoss: 0.041896\n",
      "epoch:16,loss:0.11122965232709951\n",
      "Train set: Average loss: 0.0322, Accuracy: 2543/2566 (99%)\n",
      "Val set: Average loss: 0.5652, Accuracy: 272/327 (83%)\n",
      "Train Epoch: 17 [40/2566 (2%)]\tLoss: 0.098169\n",
      "Train Epoch: 17 [80/2566 (3%)]\tLoss: 0.126566\n",
      "Train Epoch: 17 [120/2566 (5%)]\tLoss: 0.011691\n",
      "Train Epoch: 17 [160/2566 (6%)]\tLoss: 0.174445\n",
      "Train Epoch: 17 [200/2566 (8%)]\tLoss: 0.022912\n",
      "Train Epoch: 17 [240/2566 (9%)]\tLoss: 0.018946\n",
      "Train Epoch: 17 [280/2566 (11%)]\tLoss: 0.154103\n",
      "Train Epoch: 17 [320/2566 (12%)]\tLoss: 0.021739\n",
      "Train Epoch: 17 [360/2566 (14%)]\tLoss: 0.204124\n",
      "Train Epoch: 17 [400/2566 (16%)]\tLoss: 0.197254\n",
      "Train Epoch: 17 [440/2566 (17%)]\tLoss: 0.037855\n",
      "Train Epoch: 17 [480/2566 (19%)]\tLoss: 0.179503\n",
      "Train Epoch: 17 [520/2566 (20%)]\tLoss: 0.173916\n",
      "Train Epoch: 17 [560/2566 (22%)]\tLoss: 0.033312\n",
      "Train Epoch: 17 [600/2566 (23%)]\tLoss: 0.203817\n",
      "Train Epoch: 17 [640/2566 (25%)]\tLoss: 0.085325\n",
      "Train Epoch: 17 [680/2566 (26%)]\tLoss: 0.150573\n",
      "Train Epoch: 17 [720/2566 (28%)]\tLoss: 0.093945\n",
      "Train Epoch: 17 [760/2566 (30%)]\tLoss: 0.135114\n",
      "Train Epoch: 17 [800/2566 (31%)]\tLoss: 0.043809\n",
      "Train Epoch: 17 [840/2566 (33%)]\tLoss: 0.063102\n",
      "Train Epoch: 17 [880/2566 (34%)]\tLoss: 0.316048\n",
      "Train Epoch: 17 [920/2566 (36%)]\tLoss: 0.183295\n",
      "Train Epoch: 17 [960/2566 (37%)]\tLoss: 0.026972\n",
      "Train Epoch: 17 [1000/2566 (39%)]\tLoss: 0.019414\n",
      "Train Epoch: 17 [1040/2566 (40%)]\tLoss: 0.038359\n",
      "Train Epoch: 17 [1080/2566 (42%)]\tLoss: 0.033021\n",
      "Train Epoch: 17 [1120/2566 (44%)]\tLoss: 0.029315\n",
      "Train Epoch: 17 [1160/2566 (45%)]\tLoss: 0.031787\n",
      "Train Epoch: 17 [1200/2566 (47%)]\tLoss: 0.067375\n",
      "Train Epoch: 17 [1240/2566 (48%)]\tLoss: 0.019591\n",
      "Train Epoch: 17 [1280/2566 (50%)]\tLoss: 0.030843\n",
      "Train Epoch: 17 [1320/2566 (51%)]\tLoss: 0.259185\n",
      "Train Epoch: 17 [1360/2566 (53%)]\tLoss: 0.103331\n",
      "Train Epoch: 17 [1400/2566 (55%)]\tLoss: 0.010293\n",
      "Train Epoch: 17 [1440/2566 (56%)]\tLoss: 0.023985\n",
      "Train Epoch: 17 [1480/2566 (58%)]\tLoss: 0.021321\n",
      "Train Epoch: 17 [1520/2566 (59%)]\tLoss: 0.169721\n",
      "Train Epoch: 17 [1560/2566 (61%)]\tLoss: 0.042510\n",
      "Train Epoch: 17 [1600/2566 (62%)]\tLoss: 0.025725\n",
      "Train Epoch: 17 [1640/2566 (64%)]\tLoss: 0.033648\n",
      "Train Epoch: 17 [1680/2566 (65%)]\tLoss: 0.284539\n",
      "Train Epoch: 17 [1720/2566 (67%)]\tLoss: 0.395659\n",
      "Train Epoch: 17 [1760/2566 (69%)]\tLoss: 0.013347\n",
      "Train Epoch: 17 [1800/2566 (70%)]\tLoss: 0.058045\n",
      "Train Epoch: 17 [1840/2566 (72%)]\tLoss: 0.034516\n",
      "Train Epoch: 17 [1880/2566 (73%)]\tLoss: 0.020444\n",
      "Train Epoch: 17 [1920/2566 (75%)]\tLoss: 0.091332\n",
      "Train Epoch: 17 [1960/2566 (76%)]\tLoss: 0.210043\n",
      "Train Epoch: 17 [2000/2566 (78%)]\tLoss: 0.626111\n",
      "Train Epoch: 17 [2040/2566 (79%)]\tLoss: 0.078230\n",
      "Train Epoch: 17 [2080/2566 (81%)]\tLoss: 0.019760\n",
      "Train Epoch: 17 [2120/2566 (83%)]\tLoss: 0.032038\n",
      "Train Epoch: 17 [2160/2566 (84%)]\tLoss: 0.050870\n",
      "Train Epoch: 17 [2200/2566 (86%)]\tLoss: 0.009958\n",
      "Train Epoch: 17 [2240/2566 (87%)]\tLoss: 0.054474\n",
      "Train Epoch: 17 [2280/2566 (89%)]\tLoss: 0.218271\n",
      "Train Epoch: 17 [2320/2566 (90%)]\tLoss: 0.529356\n",
      "Train Epoch: 17 [2360/2566 (92%)]\tLoss: 0.050113\n",
      "Train Epoch: 17 [2400/2566 (93%)]\tLoss: 0.191211\n",
      "Train Epoch: 17 [2440/2566 (95%)]\tLoss: 0.027532\n",
      "Train Epoch: 17 [2480/2566 (97%)]\tLoss: 0.164665\n",
      "Train Epoch: 17 [2520/2566 (98%)]\tLoss: 0.050734\n",
      "Train Epoch: 17 [2560/2566 (100%)]\tLoss: 0.032748\n",
      "epoch:17,loss:0.10711877439548247\n",
      "Train set: Average loss: 0.0333, Accuracy: 2545/2566 (99%)\n",
      "Val set: Average loss: 0.5454, Accuracy: 269/327 (82%)\n",
      "Train Epoch: 18 [40/2566 (2%)]\tLoss: 0.013406\n",
      "Train Epoch: 18 [80/2566 (3%)]\tLoss: 0.040024\n",
      "Train Epoch: 18 [120/2566 (5%)]\tLoss: 0.014560\n",
      "Train Epoch: 18 [160/2566 (6%)]\tLoss: 0.014380\n",
      "Train Epoch: 18 [200/2566 (8%)]\tLoss: 0.022992\n",
      "Train Epoch: 18 [240/2566 (9%)]\tLoss: 0.029947\n",
      "Train Epoch: 18 [280/2566 (11%)]\tLoss: 0.210872\n",
      "Train Epoch: 18 [320/2566 (12%)]\tLoss: 0.027241\n",
      "Train Epoch: 18 [360/2566 (14%)]\tLoss: 0.015507\n",
      "Train Epoch: 18 [400/2566 (16%)]\tLoss: 0.024007\n",
      "Train Epoch: 18 [440/2566 (17%)]\tLoss: 0.022228\n",
      "Train Epoch: 18 [480/2566 (19%)]\tLoss: 0.039916\n",
      "Train Epoch: 18 [520/2566 (20%)]\tLoss: 0.042390\n",
      "Train Epoch: 18 [560/2566 (22%)]\tLoss: 0.055369\n",
      "Train Epoch: 18 [600/2566 (23%)]\tLoss: 0.048072\n",
      "Train Epoch: 18 [640/2566 (25%)]\tLoss: 0.032948\n",
      "Train Epoch: 18 [680/2566 (26%)]\tLoss: 0.021946\n",
      "Train Epoch: 18 [720/2566 (28%)]\tLoss: 0.322912\n",
      "Train Epoch: 18 [760/2566 (30%)]\tLoss: 0.013225\n",
      "Train Epoch: 18 [800/2566 (31%)]\tLoss: 0.055097\n",
      "Train Epoch: 18 [840/2566 (33%)]\tLoss: 0.032045\n",
      "Train Epoch: 18 [880/2566 (34%)]\tLoss: 0.021757\n",
      "Train Epoch: 18 [920/2566 (36%)]\tLoss: 0.035404\n",
      "Train Epoch: 18 [960/2566 (37%)]\tLoss: 0.123292\n",
      "Train Epoch: 18 [1000/2566 (39%)]\tLoss: 0.026541\n",
      "Train Epoch: 18 [1040/2566 (40%)]\tLoss: 0.055941\n",
      "Train Epoch: 18 [1080/2566 (42%)]\tLoss: 0.014236\n",
      "Train Epoch: 18 [1120/2566 (44%)]\tLoss: 0.081671\n",
      "Train Epoch: 18 [1160/2566 (45%)]\tLoss: 0.041404\n",
      "Train Epoch: 18 [1200/2566 (47%)]\tLoss: 0.100163\n",
      "Train Epoch: 18 [1240/2566 (48%)]\tLoss: 0.063920\n",
      "Train Epoch: 18 [1280/2566 (50%)]\tLoss: 0.109385\n",
      "Train Epoch: 18 [1320/2566 (51%)]\tLoss: 0.119777\n",
      "Train Epoch: 18 [1360/2566 (53%)]\tLoss: 0.113335\n",
      "Train Epoch: 18 [1400/2566 (55%)]\tLoss: 0.025903\n",
      "Train Epoch: 18 [1440/2566 (56%)]\tLoss: 0.025165\n",
      "Train Epoch: 18 [1480/2566 (58%)]\tLoss: 0.024170\n",
      "Train Epoch: 18 [1520/2566 (59%)]\tLoss: 0.042356\n",
      "Train Epoch: 18 [1560/2566 (61%)]\tLoss: 0.021832\n",
      "Train Epoch: 18 [1600/2566 (62%)]\tLoss: 0.015311\n",
      "Train Epoch: 18 [1640/2566 (64%)]\tLoss: 0.065238\n",
      "Train Epoch: 18 [1680/2566 (65%)]\tLoss: 0.039607\n",
      "Train Epoch: 18 [1720/2566 (67%)]\tLoss: 0.086971\n",
      "Train Epoch: 18 [1760/2566 (69%)]\tLoss: 0.308581\n",
      "Train Epoch: 18 [1800/2566 (70%)]\tLoss: 0.591836\n",
      "Train Epoch: 18 [1840/2566 (72%)]\tLoss: 0.131602\n",
      "Train Epoch: 18 [1880/2566 (73%)]\tLoss: 0.035498\n",
      "Train Epoch: 18 [1920/2566 (75%)]\tLoss: 0.095226\n",
      "Train Epoch: 18 [1960/2566 (76%)]\tLoss: 0.027747\n",
      "Train Epoch: 18 [2000/2566 (78%)]\tLoss: 0.161902\n",
      "Train Epoch: 18 [2040/2566 (79%)]\tLoss: 0.040527\n",
      "Train Epoch: 18 [2080/2566 (81%)]\tLoss: 0.105228\n",
      "Train Epoch: 18 [2120/2566 (83%)]\tLoss: 0.045434\n",
      "Train Epoch: 18 [2160/2566 (84%)]\tLoss: 0.165239\n",
      "Train Epoch: 18 [2200/2566 (86%)]\tLoss: 0.052545\n",
      "Train Epoch: 18 [2240/2566 (87%)]\tLoss: 0.077915\n",
      "Train Epoch: 18 [2280/2566 (89%)]\tLoss: 0.031694\n",
      "Train Epoch: 18 [2320/2566 (90%)]\tLoss: 0.053558\n",
      "Train Epoch: 18 [2360/2566 (92%)]\tLoss: 0.018713\n",
      "Train Epoch: 18 [2400/2566 (93%)]\tLoss: 0.136029\n",
      "Train Epoch: 18 [2440/2566 (95%)]\tLoss: 0.016599\n",
      "Train Epoch: 18 [2480/2566 (97%)]\tLoss: 0.124527\n",
      "Train Epoch: 18 [2520/2566 (98%)]\tLoss: 0.449466\n",
      "Train Epoch: 18 [2560/2566 (100%)]\tLoss: 0.169862\n",
      "epoch:18,loss:0.09478657434163527\n",
      "Train set: Average loss: 0.0270, Accuracy: 2548/2566 (99%)\n",
      "Val set: Average loss: 0.5778, Accuracy: 270/327 (83%)\n",
      "Train Epoch: 19 [40/2566 (2%)]\tLoss: 0.037651\n",
      "Train Epoch: 19 [80/2566 (3%)]\tLoss: 0.175855\n",
      "Train Epoch: 19 [120/2566 (5%)]\tLoss: 0.311968\n",
      "Train Epoch: 19 [160/2566 (6%)]\tLoss: 0.043291\n",
      "Train Epoch: 19 [200/2566 (8%)]\tLoss: 0.121144\n",
      "Train Epoch: 19 [240/2566 (9%)]\tLoss: 0.019828\n",
      "Train Epoch: 19 [280/2566 (11%)]\tLoss: 0.030058\n",
      "Train Epoch: 19 [320/2566 (12%)]\tLoss: 0.017895\n",
      "Train Epoch: 19 [360/2566 (14%)]\tLoss: 0.257467\n",
      "Train Epoch: 19 [400/2566 (16%)]\tLoss: 0.026969\n",
      "Train Epoch: 19 [440/2566 (17%)]\tLoss: 0.047389\n",
      "Train Epoch: 19 [480/2566 (19%)]\tLoss: 0.769432\n",
      "Train Epoch: 19 [520/2566 (20%)]\tLoss: 0.018317\n",
      "Train Epoch: 19 [560/2566 (22%)]\tLoss: 0.311637\n",
      "Train Epoch: 19 [600/2566 (23%)]\tLoss: 0.058963\n",
      "Train Epoch: 19 [640/2566 (25%)]\tLoss: 0.080454\n",
      "Train Epoch: 19 [680/2566 (26%)]\tLoss: 0.014272\n",
      "Train Epoch: 19 [720/2566 (28%)]\tLoss: 0.079500\n",
      "Train Epoch: 19 [760/2566 (30%)]\tLoss: 0.038401\n",
      "Train Epoch: 19 [800/2566 (31%)]\tLoss: 0.026557\n",
      "Train Epoch: 19 [840/2566 (33%)]\tLoss: 0.028797\n",
      "Train Epoch: 19 [880/2566 (34%)]\tLoss: 0.030154\n",
      "Train Epoch: 19 [920/2566 (36%)]\tLoss: 0.051712\n",
      "Train Epoch: 19 [960/2566 (37%)]\tLoss: 0.280155\n",
      "Train Epoch: 19 [1000/2566 (39%)]\tLoss: 0.085257\n",
      "Train Epoch: 19 [1040/2566 (40%)]\tLoss: 0.340040\n",
      "Train Epoch: 19 [1080/2566 (42%)]\tLoss: 0.222416\n",
      "Train Epoch: 19 [1120/2566 (44%)]\tLoss: 0.043081\n",
      "Train Epoch: 19 [1160/2566 (45%)]\tLoss: 0.252527\n",
      "Train Epoch: 19 [1200/2566 (47%)]\tLoss: 0.402060\n",
      "Train Epoch: 19 [1240/2566 (48%)]\tLoss: 0.073129\n",
      "Train Epoch: 19 [1280/2566 (50%)]\tLoss: 0.061166\n",
      "Train Epoch: 19 [1320/2566 (51%)]\tLoss: 0.028468\n",
      "Train Epoch: 19 [1360/2566 (53%)]\tLoss: 0.040213\n",
      "Train Epoch: 19 [1400/2566 (55%)]\tLoss: 0.025221\n",
      "Train Epoch: 19 [1440/2566 (56%)]\tLoss: 0.323238\n",
      "Train Epoch: 19 [1480/2566 (58%)]\tLoss: 0.032425\n",
      "Train Epoch: 19 [1520/2566 (59%)]\tLoss: 0.150110\n",
      "Train Epoch: 19 [1560/2566 (61%)]\tLoss: 0.004955\n",
      "Train Epoch: 19 [1600/2566 (62%)]\tLoss: 0.016400\n",
      "Train Epoch: 19 [1640/2566 (64%)]\tLoss: 0.060103\n",
      "Train Epoch: 19 [1680/2566 (65%)]\tLoss: 0.041919\n",
      "Train Epoch: 19 [1720/2566 (67%)]\tLoss: 0.041956\n",
      "Train Epoch: 19 [1760/2566 (69%)]\tLoss: 0.017692\n",
      "Train Epoch: 19 [1800/2566 (70%)]\tLoss: 0.013048\n",
      "Train Epoch: 19 [1840/2566 (72%)]\tLoss: 0.081658\n",
      "Train Epoch: 19 [1880/2566 (73%)]\tLoss: 0.032601\n",
      "Train Epoch: 19 [1920/2566 (75%)]\tLoss: 0.166160\n",
      "Train Epoch: 19 [1960/2566 (76%)]\tLoss: 0.052739\n",
      "Train Epoch: 19 [2000/2566 (78%)]\tLoss: 0.160992\n",
      "Train Epoch: 19 [2040/2566 (79%)]\tLoss: 0.069407\n",
      "Train Epoch: 19 [2080/2566 (81%)]\tLoss: 0.280219\n",
      "Train Epoch: 19 [2120/2566 (83%)]\tLoss: 0.007070\n",
      "Train Epoch: 19 [2160/2566 (84%)]\tLoss: 0.013463\n",
      "Train Epoch: 19 [2200/2566 (86%)]\tLoss: 0.036698\n",
      "Train Epoch: 19 [2240/2566 (87%)]\tLoss: 0.013421\n",
      "Train Epoch: 19 [2280/2566 (89%)]\tLoss: 0.012463\n",
      "Train Epoch: 19 [2320/2566 (90%)]\tLoss: 0.025133\n",
      "Train Epoch: 19 [2360/2566 (92%)]\tLoss: 0.018315\n",
      "Train Epoch: 19 [2400/2566 (93%)]\tLoss: 0.049428\n",
      "Train Epoch: 19 [2440/2566 (95%)]\tLoss: 0.049448\n",
      "Train Epoch: 19 [2480/2566 (97%)]\tLoss: 0.226586\n",
      "Train Epoch: 19 [2520/2566 (98%)]\tLoss: 0.012824\n",
      "Train Epoch: 19 [2560/2566 (100%)]\tLoss: 0.065141\n",
      "epoch:19,loss:0.08780358055739945\n",
      "Train set: Average loss: 0.0390, Accuracy: 2541/2566 (99%)\n",
      "Val set: Average loss: 0.5639, Accuracy: 267/327 (82%)\n",
      "Train Epoch: 20 [40/2566 (2%)]\tLoss: 0.087617\n",
      "Train Epoch: 20 [80/2566 (3%)]\tLoss: 0.070521\n",
      "Train Epoch: 20 [120/2566 (5%)]\tLoss: 0.012424\n",
      "Train Epoch: 20 [160/2566 (6%)]\tLoss: 0.084647\n",
      "Train Epoch: 20 [200/2566 (8%)]\tLoss: 0.017031\n",
      "Train Epoch: 20 [240/2566 (9%)]\tLoss: 0.010415\n",
      "Train Epoch: 20 [280/2566 (11%)]\tLoss: 0.031759\n",
      "Train Epoch: 20 [320/2566 (12%)]\tLoss: 0.188334\n",
      "Train Epoch: 20 [360/2566 (14%)]\tLoss: 0.016841\n",
      "Train Epoch: 20 [400/2566 (16%)]\tLoss: 0.015915\n",
      "Train Epoch: 20 [440/2566 (17%)]\tLoss: 0.038687\n",
      "Train Epoch: 20 [480/2566 (19%)]\tLoss: 0.009176\n",
      "Train Epoch: 20 [520/2566 (20%)]\tLoss: 0.083937\n",
      "Train Epoch: 20 [560/2566 (22%)]\tLoss: 0.037205\n",
      "Train Epoch: 20 [600/2566 (23%)]\tLoss: 0.042220\n",
      "Train Epoch: 20 [640/2566 (25%)]\tLoss: 0.046784\n",
      "Train Epoch: 20 [680/2566 (26%)]\tLoss: 0.154976\n",
      "Train Epoch: 20 [720/2566 (28%)]\tLoss: 0.025582\n",
      "Train Epoch: 20 [760/2566 (30%)]\tLoss: 0.082019\n",
      "Train Epoch: 20 [800/2566 (31%)]\tLoss: 0.083898\n",
      "Train Epoch: 20 [840/2566 (33%)]\tLoss: 0.130989\n",
      "Train Epoch: 20 [880/2566 (34%)]\tLoss: 0.138822\n",
      "Train Epoch: 20 [920/2566 (36%)]\tLoss: 0.039163\n",
      "Train Epoch: 20 [960/2566 (37%)]\tLoss: 0.163569\n",
      "Train Epoch: 20 [1000/2566 (39%)]\tLoss: 0.020531\n",
      "Train Epoch: 20 [1040/2566 (40%)]\tLoss: 0.025082\n",
      "Train Epoch: 20 [1080/2566 (42%)]\tLoss: 0.045648\n",
      "Train Epoch: 20 [1120/2566 (44%)]\tLoss: 0.010103\n",
      "Train Epoch: 20 [1160/2566 (45%)]\tLoss: 0.130384\n",
      "Train Epoch: 20 [1200/2566 (47%)]\tLoss: 0.028634\n",
      "Train Epoch: 20 [1240/2566 (48%)]\tLoss: 0.054072\n",
      "Train Epoch: 20 [1280/2566 (50%)]\tLoss: 0.252662\n",
      "Train Epoch: 20 [1320/2566 (51%)]\tLoss: 0.027751\n",
      "Train Epoch: 20 [1360/2566 (53%)]\tLoss: 0.015572\n",
      "Train Epoch: 20 [1400/2566 (55%)]\tLoss: 0.168117\n",
      "Train Epoch: 20 [1440/2566 (56%)]\tLoss: 0.052075\n",
      "Train Epoch: 20 [1480/2566 (58%)]\tLoss: 0.024621\n",
      "Train Epoch: 20 [1520/2566 (59%)]\tLoss: 0.034571\n",
      "Train Epoch: 20 [1560/2566 (61%)]\tLoss: 0.110637\n",
      "Train Epoch: 20 [1600/2566 (62%)]\tLoss: 0.090918\n",
      "Train Epoch: 20 [1640/2566 (64%)]\tLoss: 0.070730\n",
      "Train Epoch: 20 [1680/2566 (65%)]\tLoss: 0.011349\n",
      "Train Epoch: 20 [1720/2566 (67%)]\tLoss: 0.060335\n",
      "Train Epoch: 20 [1760/2566 (69%)]\tLoss: 0.015394\n",
      "Train Epoch: 20 [1800/2566 (70%)]\tLoss: 0.036692\n",
      "Train Epoch: 20 [1840/2566 (72%)]\tLoss: 0.037877\n",
      "Train Epoch: 20 [1880/2566 (73%)]\tLoss: 0.071711\n",
      "Train Epoch: 20 [1920/2566 (75%)]\tLoss: 0.053656\n",
      "Train Epoch: 20 [1960/2566 (76%)]\tLoss: 0.131876\n",
      "Train Epoch: 20 [2000/2566 (78%)]\tLoss: 0.037014\n",
      "Train Epoch: 20 [2040/2566 (79%)]\tLoss: 0.059182\n",
      "Train Epoch: 20 [2080/2566 (81%)]\tLoss: 0.033369\n",
      "Train Epoch: 20 [2120/2566 (83%)]\tLoss: 0.230482\n",
      "Train Epoch: 20 [2160/2566 (84%)]\tLoss: 0.140018\n",
      "Train Epoch: 20 [2200/2566 (86%)]\tLoss: 0.127155\n",
      "Train Epoch: 20 [2240/2566 (87%)]\tLoss: 0.010932\n",
      "Train Epoch: 20 [2280/2566 (89%)]\tLoss: 0.005856\n",
      "Train Epoch: 20 [2320/2566 (90%)]\tLoss: 0.478311\n",
      "Train Epoch: 20 [2360/2566 (92%)]\tLoss: 0.005562\n",
      "Train Epoch: 20 [2400/2566 (93%)]\tLoss: 0.029749\n",
      "Train Epoch: 20 [2440/2566 (95%)]\tLoss: 0.016843\n",
      "Train Epoch: 20 [2480/2566 (97%)]\tLoss: 0.036966\n",
      "Train Epoch: 20 [2520/2566 (98%)]\tLoss: 0.012426\n",
      "Train Epoch: 20 [2560/2566 (100%)]\tLoss: 0.052328\n",
      "epoch:20,loss:0.08968158778110723\n",
      "Train set: Average loss: 0.0314, Accuracy: 2546/2566 (99%)\n",
      "Val set: Average loss: 0.5738, Accuracy: 269/327 (82%)\n",
      "Train Epoch: 21 [40/2566 (2%)]\tLoss: 0.029811\n",
      "Train Epoch: 21 [80/2566 (3%)]\tLoss: 0.122676\n",
      "Train Epoch: 21 [120/2566 (5%)]\tLoss: 0.067554\n",
      "Train Epoch: 21 [160/2566 (6%)]\tLoss: 0.077774\n",
      "Train Epoch: 21 [200/2566 (8%)]\tLoss: 0.013120\n",
      "Train Epoch: 21 [240/2566 (9%)]\tLoss: 0.063829\n",
      "Train Epoch: 21 [280/2566 (11%)]\tLoss: 0.068823\n",
      "Train Epoch: 21 [320/2566 (12%)]\tLoss: 0.020586\n",
      "Train Epoch: 21 [360/2566 (14%)]\tLoss: 0.059719\n",
      "Train Epoch: 21 [400/2566 (16%)]\tLoss: 0.041121\n",
      "Train Epoch: 21 [440/2566 (17%)]\tLoss: 0.054151\n",
      "Train Epoch: 21 [480/2566 (19%)]\tLoss: 0.013932\n",
      "Train Epoch: 21 [520/2566 (20%)]\tLoss: 0.082190\n",
      "Train Epoch: 21 [560/2566 (22%)]\tLoss: 0.017148\n",
      "Train Epoch: 21 [600/2566 (23%)]\tLoss: 0.086328\n",
      "Train Epoch: 21 [640/2566 (25%)]\tLoss: 0.024620\n",
      "Train Epoch: 21 [680/2566 (26%)]\tLoss: 0.131198\n",
      "Train Epoch: 21 [720/2566 (28%)]\tLoss: 0.017088\n",
      "Train Epoch: 21 [760/2566 (30%)]\tLoss: 0.021259\n",
      "Train Epoch: 21 [800/2566 (31%)]\tLoss: 0.048077\n",
      "Train Epoch: 21 [840/2566 (33%)]\tLoss: 0.008252\n",
      "Train Epoch: 21 [880/2566 (34%)]\tLoss: 0.152298\n",
      "Train Epoch: 21 [920/2566 (36%)]\tLoss: 0.365139\n",
      "Train Epoch: 21 [960/2566 (37%)]\tLoss: 0.116062\n",
      "Train Epoch: 21 [1000/2566 (39%)]\tLoss: 0.041925\n",
      "Train Epoch: 21 [1040/2566 (40%)]\tLoss: 0.033940\n",
      "Train Epoch: 21 [1080/2566 (42%)]\tLoss: 0.960109\n",
      "Train Epoch: 21 [1120/2566 (44%)]\tLoss: 0.025920\n",
      "Train Epoch: 21 [1160/2566 (45%)]\tLoss: 0.058277\n",
      "Train Epoch: 21 [1200/2566 (47%)]\tLoss: 0.028602\n",
      "Train Epoch: 21 [1240/2566 (48%)]\tLoss: 0.270121\n",
      "Train Epoch: 21 [1280/2566 (50%)]\tLoss: 0.268627\n",
      "Train Epoch: 21 [1320/2566 (51%)]\tLoss: 0.024197\n",
      "Train Epoch: 21 [1360/2566 (53%)]\tLoss: 0.032826\n",
      "Train Epoch: 21 [1400/2566 (55%)]\tLoss: 0.125702\n",
      "Train Epoch: 21 [1440/2566 (56%)]\tLoss: 0.007549\n",
      "Train Epoch: 21 [1480/2566 (58%)]\tLoss: 0.229325\n",
      "Train Epoch: 21 [1520/2566 (59%)]\tLoss: 0.006546\n",
      "Train Epoch: 21 [1560/2566 (61%)]\tLoss: 0.012781\n",
      "Train Epoch: 21 [1600/2566 (62%)]\tLoss: 0.009032\n",
      "Train Epoch: 21 [1640/2566 (64%)]\tLoss: 0.066243\n",
      "Train Epoch: 21 [1680/2566 (65%)]\tLoss: 0.012585\n",
      "Train Epoch: 21 [1720/2566 (67%)]\tLoss: 0.011841\n",
      "Train Epoch: 21 [1760/2566 (69%)]\tLoss: 0.037953\n",
      "Train Epoch: 21 [1800/2566 (70%)]\tLoss: 0.010782\n",
      "Train Epoch: 21 [1840/2566 (72%)]\tLoss: 0.014721\n",
      "Train Epoch: 21 [1880/2566 (73%)]\tLoss: 0.017614\n",
      "Train Epoch: 21 [1920/2566 (75%)]\tLoss: 0.004443\n",
      "Train Epoch: 21 [1960/2566 (76%)]\tLoss: 0.036685\n",
      "Train Epoch: 21 [2000/2566 (78%)]\tLoss: 0.082586\n",
      "Train Epoch: 21 [2040/2566 (79%)]\tLoss: 0.075458\n",
      "Train Epoch: 21 [2080/2566 (81%)]\tLoss: 0.034699\n",
      "Train Epoch: 21 [2120/2566 (83%)]\tLoss: 0.089167\n",
      "Train Epoch: 21 [2160/2566 (84%)]\tLoss: 0.014067\n",
      "Train Epoch: 21 [2200/2566 (86%)]\tLoss: 0.054705\n",
      "Train Epoch: 21 [2240/2566 (87%)]\tLoss: 0.028425\n",
      "Train Epoch: 21 [2280/2566 (89%)]\tLoss: 0.232146\n",
      "Train Epoch: 21 [2320/2566 (90%)]\tLoss: 0.019238\n",
      "Train Epoch: 21 [2360/2566 (92%)]\tLoss: 0.033864\n",
      "Train Epoch: 21 [2400/2566 (93%)]\tLoss: 0.043133\n",
      "Train Epoch: 21 [2440/2566 (95%)]\tLoss: 0.139080\n",
      "Train Epoch: 21 [2480/2566 (97%)]\tLoss: 0.047524\n",
      "Train Epoch: 21 [2520/2566 (98%)]\tLoss: 0.018805\n",
      "Train Epoch: 21 [2560/2566 (100%)]\tLoss: 0.478976\n",
      "epoch:21,loss:0.0935360746359528\n",
      "Train set: Average loss: 0.0295, Accuracy: 2542/2566 (99%)\n",
      "Val set: Average loss: 0.5855, Accuracy: 264/327 (81%)\n",
      "Train Epoch: 22 [40/2566 (2%)]\tLoss: 0.043417\n",
      "Train Epoch: 22 [80/2566 (3%)]\tLoss: 0.128489\n",
      "Train Epoch: 22 [120/2566 (5%)]\tLoss: 0.145933\n",
      "Train Epoch: 22 [160/2566 (6%)]\tLoss: 0.027017\n",
      "Train Epoch: 22 [200/2566 (8%)]\tLoss: 0.009800\n",
      "Train Epoch: 22 [240/2566 (9%)]\tLoss: 0.053143\n",
      "Train Epoch: 22 [280/2566 (11%)]\tLoss: 0.016534\n",
      "Train Epoch: 22 [320/2566 (12%)]\tLoss: 0.015514\n",
      "Train Epoch: 22 [360/2566 (14%)]\tLoss: 0.012941\n",
      "Train Epoch: 22 [400/2566 (16%)]\tLoss: 0.103695\n",
      "Train Epoch: 22 [440/2566 (17%)]\tLoss: 0.260110\n",
      "Train Epoch: 22 [480/2566 (19%)]\tLoss: 0.027603\n",
      "Train Epoch: 22 [520/2566 (20%)]\tLoss: 0.019417\n",
      "Train Epoch: 22 [560/2566 (22%)]\tLoss: 0.024898\n",
      "Train Epoch: 22 [600/2566 (23%)]\tLoss: 0.113830\n",
      "Train Epoch: 22 [640/2566 (25%)]\tLoss: 0.037381\n",
      "Train Epoch: 22 [680/2566 (26%)]\tLoss: 0.396421\n",
      "Train Epoch: 22 [720/2566 (28%)]\tLoss: 0.031924\n",
      "Train Epoch: 22 [760/2566 (30%)]\tLoss: 0.084820\n",
      "Train Epoch: 22 [800/2566 (31%)]\tLoss: 0.007126\n",
      "Train Epoch: 22 [840/2566 (33%)]\tLoss: 0.018533\n",
      "Train Epoch: 22 [880/2566 (34%)]\tLoss: 0.051666\n",
      "Train Epoch: 22 [920/2566 (36%)]\tLoss: 0.017320\n",
      "Train Epoch: 22 [960/2566 (37%)]\tLoss: 0.048580\n",
      "Train Epoch: 22 [1000/2566 (39%)]\tLoss: 0.044300\n",
      "Train Epoch: 22 [1040/2566 (40%)]\tLoss: 0.097512\n",
      "Train Epoch: 22 [1080/2566 (42%)]\tLoss: 0.016126\n",
      "Train Epoch: 22 [1120/2566 (44%)]\tLoss: 0.012054\n",
      "Train Epoch: 22 [1160/2566 (45%)]\tLoss: 0.098429\n",
      "Train Epoch: 22 [1200/2566 (47%)]\tLoss: 0.027341\n",
      "Train Epoch: 22 [1240/2566 (48%)]\tLoss: 0.045176\n",
      "Train Epoch: 22 [1280/2566 (50%)]\tLoss: 0.043001\n",
      "Train Epoch: 22 [1320/2566 (51%)]\tLoss: 0.009705\n",
      "Train Epoch: 22 [1360/2566 (53%)]\tLoss: 0.654832\n",
      "Train Epoch: 22 [1400/2566 (55%)]\tLoss: 0.006849\n",
      "Train Epoch: 22 [1440/2566 (56%)]\tLoss: 0.034551\n",
      "Train Epoch: 22 [1480/2566 (58%)]\tLoss: 0.012272\n",
      "Train Epoch: 22 [1520/2566 (59%)]\tLoss: 0.021610\n",
      "Train Epoch: 22 [1560/2566 (61%)]\tLoss: 0.025048\n",
      "Train Epoch: 22 [1600/2566 (62%)]\tLoss: 0.285151\n",
      "Train Epoch: 22 [1640/2566 (64%)]\tLoss: 0.012419\n",
      "Train Epoch: 22 [1680/2566 (65%)]\tLoss: 0.045279\n",
      "Train Epoch: 22 [1720/2566 (67%)]\tLoss: 0.025460\n",
      "Train Epoch: 22 [1760/2566 (69%)]\tLoss: 0.084953\n",
      "Train Epoch: 22 [1800/2566 (70%)]\tLoss: 0.186392\n",
      "Train Epoch: 22 [1840/2566 (72%)]\tLoss: 0.559824\n",
      "Train Epoch: 22 [1880/2566 (73%)]\tLoss: 0.121353\n",
      "Train Epoch: 22 [1920/2566 (75%)]\tLoss: 0.014118\n",
      "Train Epoch: 22 [1960/2566 (76%)]\tLoss: 0.124884\n",
      "Train Epoch: 22 [2000/2566 (78%)]\tLoss: 0.451856\n",
      "Train Epoch: 22 [2040/2566 (79%)]\tLoss: 0.017816\n",
      "Train Epoch: 22 [2080/2566 (81%)]\tLoss: 0.014853\n",
      "Train Epoch: 22 [2120/2566 (83%)]\tLoss: 0.010344\n",
      "Train Epoch: 22 [2160/2566 (84%)]\tLoss: 0.018598\n",
      "Train Epoch: 22 [2200/2566 (86%)]\tLoss: 0.029455\n",
      "Train Epoch: 22 [2240/2566 (87%)]\tLoss: 0.032703\n",
      "Train Epoch: 22 [2280/2566 (89%)]\tLoss: 0.031955\n",
      "Train Epoch: 22 [2320/2566 (90%)]\tLoss: 0.017614\n",
      "Train Epoch: 22 [2360/2566 (92%)]\tLoss: 0.015270\n",
      "Train Epoch: 22 [2400/2566 (93%)]\tLoss: 0.215118\n",
      "Train Epoch: 22 [2440/2566 (95%)]\tLoss: 0.141354\n",
      "Train Epoch: 22 [2480/2566 (97%)]\tLoss: 0.051904\n",
      "Train Epoch: 22 [2520/2566 (98%)]\tLoss: 0.021606\n",
      "Train Epoch: 22 [2560/2566 (100%)]\tLoss: 0.103607\n",
      "epoch:22,loss:0.08266629387314121\n",
      "Train set: Average loss: 0.0270, Accuracy: 2547/2566 (99%)\n",
      "Val set: Average loss: 0.5848, Accuracy: 268/327 (82%)\n",
      "Train Epoch: 23 [40/2566 (2%)]\tLoss: 0.032017\n",
      "Train Epoch: 23 [80/2566 (3%)]\tLoss: 0.007030\n",
      "Train Epoch: 23 [120/2566 (5%)]\tLoss: 0.024514\n",
      "Train Epoch: 23 [160/2566 (6%)]\tLoss: 0.023371\n",
      "Train Epoch: 23 [200/2566 (8%)]\tLoss: 0.072619\n",
      "Train Epoch: 23 [240/2566 (9%)]\tLoss: 0.016159\n",
      "Train Epoch: 23 [280/2566 (11%)]\tLoss: 0.014553\n",
      "Train Epoch: 23 [320/2566 (12%)]\tLoss: 0.011657\n",
      "Train Epoch: 23 [360/2566 (14%)]\tLoss: 0.016853\n",
      "Train Epoch: 23 [400/2566 (16%)]\tLoss: 0.019285\n",
      "Train Epoch: 23 [440/2566 (17%)]\tLoss: 0.004584\n",
      "Train Epoch: 23 [480/2566 (19%)]\tLoss: 0.039529\n",
      "Train Epoch: 23 [520/2566 (20%)]\tLoss: 0.013583\n",
      "Train Epoch: 23 [560/2566 (22%)]\tLoss: 0.102842\n",
      "Train Epoch: 23 [600/2566 (23%)]\tLoss: 0.770079\n",
      "Train Epoch: 23 [640/2566 (25%)]\tLoss: 0.035857\n",
      "Train Epoch: 23 [680/2566 (26%)]\tLoss: 0.115041\n",
      "Train Epoch: 23 [720/2566 (28%)]\tLoss: 0.004676\n",
      "Train Epoch: 23 [760/2566 (30%)]\tLoss: 0.012605\n",
      "Train Epoch: 23 [800/2566 (31%)]\tLoss: 0.009999\n",
      "Train Epoch: 23 [840/2566 (33%)]\tLoss: 0.009433\n",
      "Train Epoch: 23 [880/2566 (34%)]\tLoss: 0.018332\n",
      "Train Epoch: 23 [920/2566 (36%)]\tLoss: 0.034355\n",
      "Train Epoch: 23 [960/2566 (37%)]\tLoss: 0.057909\n",
      "Train Epoch: 23 [1000/2566 (39%)]\tLoss: 0.026121\n",
      "Train Epoch: 23 [1040/2566 (40%)]\tLoss: 0.034813\n",
      "Train Epoch: 23 [1080/2566 (42%)]\tLoss: 0.089074\n",
      "Train Epoch: 23 [1120/2566 (44%)]\tLoss: 0.051608\n",
      "Train Epoch: 23 [1160/2566 (45%)]\tLoss: 0.025588\n",
      "Train Epoch: 23 [1200/2566 (47%)]\tLoss: 0.019205\n",
      "Train Epoch: 23 [1240/2566 (48%)]\tLoss: 0.022192\n",
      "Train Epoch: 23 [1280/2566 (50%)]\tLoss: 0.016078\n",
      "Train Epoch: 23 [1320/2566 (51%)]\tLoss: 0.028748\n",
      "Train Epoch: 23 [1360/2566 (53%)]\tLoss: 0.009100\n",
      "Train Epoch: 23 [1400/2566 (55%)]\tLoss: 0.031967\n",
      "Train Epoch: 23 [1440/2566 (56%)]\tLoss: 0.019682\n",
      "Train Epoch: 23 [1480/2566 (58%)]\tLoss: 0.083735\n",
      "Train Epoch: 23 [1520/2566 (59%)]\tLoss: 0.206684\n",
      "Train Epoch: 23 [1560/2566 (61%)]\tLoss: 0.046329\n",
      "Train Epoch: 23 [1600/2566 (62%)]\tLoss: 0.037682\n",
      "Train Epoch: 23 [1640/2566 (64%)]\tLoss: 0.045651\n",
      "Train Epoch: 23 [1680/2566 (65%)]\tLoss: 0.060669\n",
      "Train Epoch: 23 [1720/2566 (67%)]\tLoss: 0.026249\n",
      "Train Epoch: 23 [1760/2566 (69%)]\tLoss: 0.016981\n",
      "Train Epoch: 23 [1800/2566 (70%)]\tLoss: 0.147590\n",
      "Train Epoch: 23 [1840/2566 (72%)]\tLoss: 0.044410\n",
      "Train Epoch: 23 [1880/2566 (73%)]\tLoss: 0.102701\n",
      "Train Epoch: 23 [1920/2566 (75%)]\tLoss: 0.129090\n",
      "Train Epoch: 23 [1960/2566 (76%)]\tLoss: 0.039904\n",
      "Train Epoch: 23 [2000/2566 (78%)]\tLoss: 0.021507\n",
      "Train Epoch: 23 [2040/2566 (79%)]\tLoss: 0.024110\n",
      "Train Epoch: 23 [2080/2566 (81%)]\tLoss: 0.018083\n",
      "Train Epoch: 23 [2120/2566 (83%)]\tLoss: 0.029481\n",
      "Train Epoch: 23 [2160/2566 (84%)]\tLoss: 0.020772\n",
      "Train Epoch: 23 [2200/2566 (86%)]\tLoss: 0.012894\n",
      "Train Epoch: 23 [2240/2566 (87%)]\tLoss: 0.088560\n",
      "Train Epoch: 23 [2280/2566 (89%)]\tLoss: 0.019513\n",
      "Train Epoch: 23 [2320/2566 (90%)]\tLoss: 0.184498\n",
      "Train Epoch: 23 [2360/2566 (92%)]\tLoss: 0.006601\n",
      "Train Epoch: 23 [2400/2566 (93%)]\tLoss: 0.175664\n",
      "Train Epoch: 23 [2440/2566 (95%)]\tLoss: 0.070814\n",
      "Train Epoch: 23 [2480/2566 (97%)]\tLoss: 0.014331\n",
      "Train Epoch: 23 [2520/2566 (98%)]\tLoss: 0.501646\n",
      "Train Epoch: 23 [2560/2566 (100%)]\tLoss: 0.357796\n",
      "epoch:23,loss:0.0704600768950057\n",
      "Train set: Average loss: 0.0285, Accuracy: 2541/2566 (99%)\n",
      "Val set: Average loss: 0.5878, Accuracy: 269/327 (82%)\n",
      "Train Epoch: 24 [40/2566 (2%)]\tLoss: 0.116516\n",
      "Train Epoch: 24 [80/2566 (3%)]\tLoss: 0.016154\n",
      "Train Epoch: 24 [120/2566 (5%)]\tLoss: 0.002900\n",
      "Train Epoch: 24 [160/2566 (6%)]\tLoss: 0.020484\n",
      "Train Epoch: 24 [200/2566 (8%)]\tLoss: 0.019187\n",
      "Train Epoch: 24 [240/2566 (9%)]\tLoss: 0.009304\n",
      "Train Epoch: 24 [280/2566 (11%)]\tLoss: 0.029641\n",
      "Train Epoch: 24 [320/2566 (12%)]\tLoss: 0.011508\n",
      "Train Epoch: 24 [360/2566 (14%)]\tLoss: 0.012817\n",
      "Train Epoch: 24 [400/2566 (16%)]\tLoss: 0.010263\n",
      "Train Epoch: 24 [440/2566 (17%)]\tLoss: 0.006497\n",
      "Train Epoch: 24 [480/2566 (19%)]\tLoss: 0.025396\n",
      "Train Epoch: 24 [520/2566 (20%)]\tLoss: 0.010759\n",
      "Train Epoch: 24 [560/2566 (22%)]\tLoss: 0.006609\n",
      "Train Epoch: 24 [600/2566 (23%)]\tLoss: 0.025894\n",
      "Train Epoch: 24 [640/2566 (25%)]\tLoss: 0.005963\n",
      "Train Epoch: 24 [680/2566 (26%)]\tLoss: 0.013634\n",
      "Train Epoch: 24 [720/2566 (28%)]\tLoss: 0.092958\n",
      "Train Epoch: 24 [760/2566 (30%)]\tLoss: 0.005783\n",
      "Train Epoch: 24 [800/2566 (31%)]\tLoss: 0.177257\n",
      "Train Epoch: 24 [840/2566 (33%)]\tLoss: 0.352649\n",
      "Train Epoch: 24 [880/2566 (34%)]\tLoss: 0.077903\n",
      "Train Epoch: 24 [920/2566 (36%)]\tLoss: 0.021554\n",
      "Train Epoch: 24 [960/2566 (37%)]\tLoss: 0.012581\n",
      "Train Epoch: 24 [1000/2566 (39%)]\tLoss: 0.076916\n",
      "Train Epoch: 24 [1040/2566 (40%)]\tLoss: 0.004437\n",
      "Train Epoch: 24 [1080/2566 (42%)]\tLoss: 0.036788\n",
      "Train Epoch: 24 [1120/2566 (44%)]\tLoss: 0.024994\n",
      "Train Epoch: 24 [1160/2566 (45%)]\tLoss: 0.064267\n",
      "Train Epoch: 24 [1200/2566 (47%)]\tLoss: 0.141899\n",
      "Train Epoch: 24 [1240/2566 (48%)]\tLoss: 0.023063\n",
      "Train Epoch: 24 [1280/2566 (50%)]\tLoss: 0.012659\n",
      "Train Epoch: 24 [1320/2566 (51%)]\tLoss: 0.056315\n",
      "Train Epoch: 24 [1360/2566 (53%)]\tLoss: 0.006723\n",
      "Train Epoch: 24 [1400/2566 (55%)]\tLoss: 0.028605\n",
      "Train Epoch: 24 [1440/2566 (56%)]\tLoss: 0.009762\n",
      "Train Epoch: 24 [1480/2566 (58%)]\tLoss: 0.021127\n",
      "Train Epoch: 24 [1520/2566 (59%)]\tLoss: 0.004837\n",
      "Train Epoch: 24 [1560/2566 (61%)]\tLoss: 0.033241\n",
      "Train Epoch: 24 [1600/2566 (62%)]\tLoss: 0.183266\n",
      "Train Epoch: 24 [1640/2566 (64%)]\tLoss: 0.028687\n",
      "Train Epoch: 24 [1680/2566 (65%)]\tLoss: 0.020545\n",
      "Train Epoch: 24 [1720/2566 (67%)]\tLoss: 0.072522\n",
      "Train Epoch: 24 [1760/2566 (69%)]\tLoss: 0.027245\n",
      "Train Epoch: 24 [1800/2566 (70%)]\tLoss: 0.031292\n",
      "Train Epoch: 24 [1840/2566 (72%)]\tLoss: 0.144127\n",
      "Train Epoch: 24 [1880/2566 (73%)]\tLoss: 0.012207\n",
      "Train Epoch: 24 [1920/2566 (75%)]\tLoss: 0.045848\n",
      "Train Epoch: 24 [1960/2566 (76%)]\tLoss: 0.027686\n",
      "Train Epoch: 24 [2000/2566 (78%)]\tLoss: 0.141769\n",
      "Train Epoch: 24 [2040/2566 (79%)]\tLoss: 0.015402\n",
      "Train Epoch: 24 [2080/2566 (81%)]\tLoss: 0.021348\n",
      "Train Epoch: 24 [2120/2566 (83%)]\tLoss: 0.010018\n",
      "Train Epoch: 24 [2160/2566 (84%)]\tLoss: 0.006776\n",
      "Train Epoch: 24 [2200/2566 (86%)]\tLoss: 0.050833\n",
      "Train Epoch: 24 [2240/2566 (87%)]\tLoss: 0.057832\n",
      "Train Epoch: 24 [2280/2566 (89%)]\tLoss: 0.084509\n",
      "Train Epoch: 24 [2320/2566 (90%)]\tLoss: 0.004994\n",
      "Train Epoch: 24 [2360/2566 (92%)]\tLoss: 0.054055\n",
      "Train Epoch: 24 [2400/2566 (93%)]\tLoss: 0.090541\n",
      "Train Epoch: 24 [2440/2566 (95%)]\tLoss: 0.477554\n",
      "Train Epoch: 24 [2480/2566 (97%)]\tLoss: 0.007664\n",
      "Train Epoch: 24 [2520/2566 (98%)]\tLoss: 0.028585\n",
      "Train Epoch: 24 [2560/2566 (100%)]\tLoss: 0.059297\n",
      "epoch:24,loss:0.06688549908783252\n",
      "Train set: Average loss: 0.0258, Accuracy: 2547/2566 (99%)\n",
      "Val set: Average loss: 0.6405, Accuracy: 270/327 (83%)\n",
      "Train Epoch: 25 [40/2566 (2%)]\tLoss: 0.008523\n",
      "Train Epoch: 25 [80/2566 (3%)]\tLoss: 0.019882\n",
      "Train Epoch: 25 [120/2566 (5%)]\tLoss: 0.004350\n",
      "Train Epoch: 25 [160/2566 (6%)]\tLoss: 0.156883\n",
      "Train Epoch: 25 [200/2566 (8%)]\tLoss: 0.033265\n",
      "Train Epoch: 25 [240/2566 (9%)]\tLoss: 0.259940\n",
      "Train Epoch: 25 [280/2566 (11%)]\tLoss: 0.025878\n",
      "Train Epoch: 25 [320/2566 (12%)]\tLoss: 0.011142\n",
      "Train Epoch: 25 [360/2566 (14%)]\tLoss: 0.137366\n",
      "Train Epoch: 25 [400/2566 (16%)]\tLoss: 0.005784\n",
      "Train Epoch: 25 [440/2566 (17%)]\tLoss: 0.048221\n",
      "Train Epoch: 25 [480/2566 (19%)]\tLoss: 0.019926\n",
      "Train Epoch: 25 [520/2566 (20%)]\tLoss: 0.007700\n",
      "Train Epoch: 25 [560/2566 (22%)]\tLoss: 0.008528\n",
      "Train Epoch: 25 [600/2566 (23%)]\tLoss: 0.053810\n",
      "Train Epoch: 25 [640/2566 (25%)]\tLoss: 0.028415\n",
      "Train Epoch: 25 [680/2566 (26%)]\tLoss: 0.072279\n",
      "Train Epoch: 25 [720/2566 (28%)]\tLoss: 0.015184\n",
      "Train Epoch: 25 [760/2566 (30%)]\tLoss: 0.008928\n",
      "Train Epoch: 25 [800/2566 (31%)]\tLoss: 0.022457\n",
      "Train Epoch: 25 [840/2566 (33%)]\tLoss: 0.006694\n",
      "Train Epoch: 25 [880/2566 (34%)]\tLoss: 0.033448\n",
      "Train Epoch: 25 [920/2566 (36%)]\tLoss: 0.006043\n",
      "Train Epoch: 25 [960/2566 (37%)]\tLoss: 0.155576\n",
      "Train Epoch: 25 [1000/2566 (39%)]\tLoss: 0.009329\n",
      "Train Epoch: 25 [1040/2566 (40%)]\tLoss: 0.105142\n",
      "Train Epoch: 25 [1080/2566 (42%)]\tLoss: 0.012266\n",
      "Train Epoch: 25 [1120/2566 (44%)]\tLoss: 0.039997\n",
      "Train Epoch: 25 [1160/2566 (45%)]\tLoss: 0.067593\n",
      "Train Epoch: 25 [1200/2566 (47%)]\tLoss: 0.083576\n",
      "Train Epoch: 25 [1240/2566 (48%)]\tLoss: 0.165817\n",
      "Train Epoch: 25 [1280/2566 (50%)]\tLoss: 0.007555\n",
      "Train Epoch: 25 [1320/2566 (51%)]\tLoss: 0.038125\n",
      "Train Epoch: 25 [1360/2566 (53%)]\tLoss: 0.121269\n",
      "Train Epoch: 25 [1400/2566 (55%)]\tLoss: 0.007975\n",
      "Train Epoch: 25 [1440/2566 (56%)]\tLoss: 0.455309\n",
      "Train Epoch: 25 [1480/2566 (58%)]\tLoss: 0.006660\n",
      "Train Epoch: 25 [1520/2566 (59%)]\tLoss: 0.011396\n",
      "Train Epoch: 25 [1560/2566 (61%)]\tLoss: 0.005114\n",
      "Train Epoch: 25 [1600/2566 (62%)]\tLoss: 0.021289\n",
      "Train Epoch: 25 [1640/2566 (64%)]\tLoss: 0.038648\n",
      "Train Epoch: 25 [1680/2566 (65%)]\tLoss: 0.432856\n",
      "Train Epoch: 25 [1720/2566 (67%)]\tLoss: 0.023967\n",
      "Train Epoch: 25 [1760/2566 (69%)]\tLoss: 0.060675\n",
      "Train Epoch: 25 [1800/2566 (70%)]\tLoss: 0.089813\n",
      "Train Epoch: 25 [1840/2566 (72%)]\tLoss: 0.010034\n",
      "Train Epoch: 25 [1880/2566 (73%)]\tLoss: 0.015951\n",
      "Train Epoch: 25 [1920/2566 (75%)]\tLoss: 0.149104\n",
      "Train Epoch: 25 [1960/2566 (76%)]\tLoss: 0.049462\n",
      "Train Epoch: 25 [2000/2566 (78%)]\tLoss: 0.013817\n",
      "Train Epoch: 25 [2040/2566 (79%)]\tLoss: 0.024546\n",
      "Train Epoch: 25 [2080/2566 (81%)]\tLoss: 0.037435\n",
      "Train Epoch: 25 [2120/2566 (83%)]\tLoss: 0.008537\n",
      "Train Epoch: 25 [2160/2566 (84%)]\tLoss: 0.007182\n",
      "Train Epoch: 25 [2200/2566 (86%)]\tLoss: 0.034825\n",
      "Train Epoch: 25 [2240/2566 (87%)]\tLoss: 0.008458\n",
      "Train Epoch: 25 [2280/2566 (89%)]\tLoss: 0.060379\n",
      "Train Epoch: 25 [2320/2566 (90%)]\tLoss: 0.092065\n",
      "Train Epoch: 25 [2360/2566 (92%)]\tLoss: 0.022445\n",
      "Train Epoch: 25 [2400/2566 (93%)]\tLoss: 0.375763\n",
      "Train Epoch: 25 [2440/2566 (95%)]\tLoss: 0.010907\n",
      "Train Epoch: 25 [2480/2566 (97%)]\tLoss: 0.007360\n",
      "Train Epoch: 25 [2520/2566 (98%)]\tLoss: 0.004584\n",
      "Train Epoch: 25 [2560/2566 (100%)]\tLoss: 0.015909\n",
      "epoch:25,loss:0.06681101274389391\n",
      "Train set: Average loss: 0.0218, Accuracy: 2551/2566 (99%)\n",
      "Val set: Average loss: 0.5877, Accuracy: 268/327 (82%)\n",
      "Train Epoch: 26 [40/2566 (2%)]\tLoss: 0.010571\n",
      "Train Epoch: 26 [80/2566 (3%)]\tLoss: 0.088943\n",
      "Train Epoch: 26 [120/2566 (5%)]\tLoss: 0.052143\n",
      "Train Epoch: 26 [160/2566 (6%)]\tLoss: 0.011279\n",
      "Train Epoch: 26 [200/2566 (8%)]\tLoss: 0.047742\n",
      "Train Epoch: 26 [240/2566 (9%)]\tLoss: 0.022547\n",
      "Train Epoch: 26 [280/2566 (11%)]\tLoss: 0.086783\n",
      "Train Epoch: 26 [320/2566 (12%)]\tLoss: 0.067145\n",
      "Train Epoch: 26 [360/2566 (14%)]\tLoss: 0.576505\n",
      "Train Epoch: 26 [400/2566 (16%)]\tLoss: 0.150407\n",
      "Train Epoch: 26 [440/2566 (17%)]\tLoss: 0.016857\n",
      "Train Epoch: 26 [480/2566 (19%)]\tLoss: 0.021625\n",
      "Train Epoch: 26 [520/2566 (20%)]\tLoss: 0.016712\n",
      "Train Epoch: 26 [560/2566 (22%)]\tLoss: 0.010265\n",
      "Train Epoch: 26 [600/2566 (23%)]\tLoss: 0.069594\n",
      "Train Epoch: 26 [640/2566 (25%)]\tLoss: 0.144387\n",
      "Train Epoch: 26 [680/2566 (26%)]\tLoss: 0.004060\n",
      "Train Epoch: 26 [720/2566 (28%)]\tLoss: 0.019985\n",
      "Train Epoch: 26 [760/2566 (30%)]\tLoss: 0.012599\n",
      "Train Epoch: 26 [800/2566 (31%)]\tLoss: 0.048766\n",
      "Train Epoch: 26 [840/2566 (33%)]\tLoss: 0.032093\n",
      "Train Epoch: 26 [880/2566 (34%)]\tLoss: 0.016854\n",
      "Train Epoch: 26 [920/2566 (36%)]\tLoss: 0.009615\n",
      "Train Epoch: 26 [960/2566 (37%)]\tLoss: 0.028664\n",
      "Train Epoch: 26 [1000/2566 (39%)]\tLoss: 0.094633\n",
      "Train Epoch: 26 [1040/2566 (40%)]\tLoss: 0.018710\n",
      "Train Epoch: 26 [1080/2566 (42%)]\tLoss: 0.213989\n",
      "Train Epoch: 26 [1120/2566 (44%)]\tLoss: 0.129179\n",
      "Train Epoch: 26 [1160/2566 (45%)]\tLoss: 0.164582\n",
      "Train Epoch: 26 [1200/2566 (47%)]\tLoss: 0.009969\n",
      "Train Epoch: 26 [1240/2566 (48%)]\tLoss: 0.003513\n",
      "Train Epoch: 26 [1280/2566 (50%)]\tLoss: 0.034379\n",
      "Train Epoch: 26 [1320/2566 (51%)]\tLoss: 0.208050\n",
      "Train Epoch: 26 [1360/2566 (53%)]\tLoss: 0.023612\n",
      "Train Epoch: 26 [1400/2566 (55%)]\tLoss: 0.015081\n",
      "Train Epoch: 26 [1440/2566 (56%)]\tLoss: 0.007055\n",
      "Train Epoch: 26 [1480/2566 (58%)]\tLoss: 0.087367\n",
      "Train Epoch: 26 [1520/2566 (59%)]\tLoss: 0.038486\n",
      "Train Epoch: 26 [1560/2566 (61%)]\tLoss: 0.024422\n",
      "Train Epoch: 26 [1600/2566 (62%)]\tLoss: 0.009562\n",
      "Train Epoch: 26 [1640/2566 (64%)]\tLoss: 1.106105\n",
      "Train Epoch: 26 [1680/2566 (65%)]\tLoss: 0.021062\n",
      "Train Epoch: 26 [1720/2566 (67%)]\tLoss: 0.008670\n",
      "Train Epoch: 26 [1760/2566 (69%)]\tLoss: 0.186582\n",
      "Train Epoch: 26 [1800/2566 (70%)]\tLoss: 0.005701\n",
      "Train Epoch: 26 [1840/2566 (72%)]\tLoss: 0.007627\n",
      "Train Epoch: 26 [1880/2566 (73%)]\tLoss: 0.045871\n",
      "Train Epoch: 26 [1920/2566 (75%)]\tLoss: 0.004272\n",
      "Train Epoch: 26 [1960/2566 (76%)]\tLoss: 0.159543\n",
      "Train Epoch: 26 [2000/2566 (78%)]\tLoss: 0.004422\n",
      "Train Epoch: 26 [2040/2566 (79%)]\tLoss: 0.021670\n",
      "Train Epoch: 26 [2080/2566 (81%)]\tLoss: 0.010073\n",
      "Train Epoch: 26 [2120/2566 (83%)]\tLoss: 0.043445\n",
      "Train Epoch: 26 [2160/2566 (84%)]\tLoss: 0.079457\n",
      "Train Epoch: 26 [2200/2566 (86%)]\tLoss: 0.342188\n",
      "Train Epoch: 26 [2240/2566 (87%)]\tLoss: 0.073656\n",
      "Train Epoch: 26 [2280/2566 (89%)]\tLoss: 0.691940\n",
      "Train Epoch: 26 [2320/2566 (90%)]\tLoss: 0.009665\n",
      "Train Epoch: 26 [2360/2566 (92%)]\tLoss: 0.211875\n",
      "Train Epoch: 26 [2400/2566 (93%)]\tLoss: 0.006491\n",
      "Train Epoch: 26 [2440/2566 (95%)]\tLoss: 0.003050\n",
      "Train Epoch: 26 [2480/2566 (97%)]\tLoss: 0.028103\n",
      "Train Epoch: 26 [2520/2566 (98%)]\tLoss: 0.015185\n",
      "Train Epoch: 26 [2560/2566 (100%)]\tLoss: 0.007062\n",
      "epoch:26,loss:0.0704462692348977\n",
      "Train set: Average loss: 0.0250, Accuracy: 2543/2566 (99%)\n",
      "Val set: Average loss: 0.5923, Accuracy: 264/327 (81%)\n",
      "Train Epoch: 27 [40/2566 (2%)]\tLoss: 0.006879\n",
      "Train Epoch: 27 [80/2566 (3%)]\tLoss: 0.087790\n",
      "Train Epoch: 27 [120/2566 (5%)]\tLoss: 0.133088\n",
      "Train Epoch: 27 [160/2566 (6%)]\tLoss: 0.070147\n",
      "Train Epoch: 27 [200/2566 (8%)]\tLoss: 0.164383\n",
      "Train Epoch: 27 [240/2566 (9%)]\tLoss: 0.050407\n",
      "Train Epoch: 27 [280/2566 (11%)]\tLoss: 0.377966\n",
      "Train Epoch: 27 [320/2566 (12%)]\tLoss: 0.029794\n",
      "Train Epoch: 27 [360/2566 (14%)]\tLoss: 0.094600\n",
      "Train Epoch: 27 [400/2566 (16%)]\tLoss: 0.044316\n",
      "Train Epoch: 27 [440/2566 (17%)]\tLoss: 0.002667\n",
      "Train Epoch: 27 [480/2566 (19%)]\tLoss: 0.092293\n",
      "Train Epoch: 27 [520/2566 (20%)]\tLoss: 0.037234\n",
      "Train Epoch: 27 [560/2566 (22%)]\tLoss: 0.020353\n",
      "Train Epoch: 27 [600/2566 (23%)]\tLoss: 0.007026\n",
      "Train Epoch: 27 [640/2566 (25%)]\tLoss: 0.023467\n",
      "Train Epoch: 27 [680/2566 (26%)]\tLoss: 0.005414\n",
      "Train Epoch: 27 [720/2566 (28%)]\tLoss: 0.112594\n",
      "Train Epoch: 27 [760/2566 (30%)]\tLoss: 0.079243\n",
      "Train Epoch: 27 [800/2566 (31%)]\tLoss: 0.014510\n",
      "Train Epoch: 27 [840/2566 (33%)]\tLoss: 0.134631\n",
      "Train Epoch: 27 [880/2566 (34%)]\tLoss: 0.055126\n",
      "Train Epoch: 27 [920/2566 (36%)]\tLoss: 0.083597\n",
      "Train Epoch: 27 [960/2566 (37%)]\tLoss: 0.004188\n",
      "Train Epoch: 27 [1000/2566 (39%)]\tLoss: 0.017624\n",
      "Train Epoch: 27 [1040/2566 (40%)]\tLoss: 0.004542\n",
      "Train Epoch: 27 [1080/2566 (42%)]\tLoss: 0.056111\n",
      "Train Epoch: 27 [1120/2566 (44%)]\tLoss: 0.481820\n",
      "Train Epoch: 27 [1160/2566 (45%)]\tLoss: 0.005201\n",
      "Train Epoch: 27 [1200/2566 (47%)]\tLoss: 0.025524\n",
      "Train Epoch: 27 [1240/2566 (48%)]\tLoss: 0.389594\n",
      "Train Epoch: 27 [1280/2566 (50%)]\tLoss: 0.041952\n",
      "Train Epoch: 27 [1320/2566 (51%)]\tLoss: 0.040568\n",
      "Train Epoch: 27 [1360/2566 (53%)]\tLoss: 0.091173\n",
      "Train Epoch: 27 [1400/2566 (55%)]\tLoss: 0.083888\n",
      "Train Epoch: 27 [1440/2566 (56%)]\tLoss: 0.035707\n",
      "Train Epoch: 27 [1480/2566 (58%)]\tLoss: 0.535714\n",
      "Train Epoch: 27 [1520/2566 (59%)]\tLoss: 0.100067\n",
      "Train Epoch: 27 [1560/2566 (61%)]\tLoss: 0.009734\n",
      "Train Epoch: 27 [1600/2566 (62%)]\tLoss: 0.355763\n",
      "Train Epoch: 27 [1640/2566 (64%)]\tLoss: 0.018798\n",
      "Train Epoch: 27 [1680/2566 (65%)]\tLoss: 0.015937\n",
      "Train Epoch: 27 [1720/2566 (67%)]\tLoss: 0.010707\n",
      "Train Epoch: 27 [1760/2566 (69%)]\tLoss: 0.096845\n",
      "Train Epoch: 27 [1800/2566 (70%)]\tLoss: 0.173669\n",
      "Train Epoch: 27 [1840/2566 (72%)]\tLoss: 0.153091\n",
      "Train Epoch: 27 [1880/2566 (73%)]\tLoss: 0.009222\n",
      "Train Epoch: 27 [1920/2566 (75%)]\tLoss: 0.254747\n",
      "Train Epoch: 27 [1960/2566 (76%)]\tLoss: 0.016292\n",
      "Train Epoch: 27 [2000/2566 (78%)]\tLoss: 0.028016\n",
      "Train Epoch: 27 [2040/2566 (79%)]\tLoss: 0.023966\n",
      "Train Epoch: 27 [2080/2566 (81%)]\tLoss: 0.010821\n",
      "Train Epoch: 27 [2120/2566 (83%)]\tLoss: 0.082523\n",
      "Train Epoch: 27 [2160/2566 (84%)]\tLoss: 0.043851\n",
      "Train Epoch: 27 [2200/2566 (86%)]\tLoss: 0.061378\n",
      "Train Epoch: 27 [2240/2566 (87%)]\tLoss: 0.022281\n",
      "Train Epoch: 27 [2280/2566 (89%)]\tLoss: 0.006741\n",
      "Train Epoch: 27 [2320/2566 (90%)]\tLoss: 0.280261\n",
      "Train Epoch: 27 [2360/2566 (92%)]\tLoss: 0.395318\n",
      "Train Epoch: 27 [2400/2566 (93%)]\tLoss: 0.023179\n",
      "Train Epoch: 27 [2440/2566 (95%)]\tLoss: 0.012884\n",
      "Train Epoch: 27 [2480/2566 (97%)]\tLoss: 0.011207\n",
      "Train Epoch: 27 [2520/2566 (98%)]\tLoss: 0.812492\n",
      "Train Epoch: 27 [2560/2566 (100%)]\tLoss: 0.026076\n",
      "epoch:27,loss:0.07127004803950403\n",
      "Train set: Average loss: 0.0257, Accuracy: 2541/2566 (99%)\n",
      "Val set: Average loss: 0.5968, Accuracy: 273/327 (83%)\n",
      "Train Epoch: 28 [40/2566 (2%)]\tLoss: 0.006746\n",
      "Train Epoch: 28 [80/2566 (3%)]\tLoss: 0.168228\n",
      "Train Epoch: 28 [120/2566 (5%)]\tLoss: 0.061355\n",
      "Train Epoch: 28 [160/2566 (6%)]\tLoss: 0.017134\n",
      "Train Epoch: 28 [200/2566 (8%)]\tLoss: 0.007110\n",
      "Train Epoch: 28 [240/2566 (9%)]\tLoss: 0.055575\n",
      "Train Epoch: 28 [280/2566 (11%)]\tLoss: 0.005859\n",
      "Train Epoch: 28 [320/2566 (12%)]\tLoss: 0.006254\n",
      "Train Epoch: 28 [360/2566 (14%)]\tLoss: 0.007688\n",
      "Train Epoch: 28 [400/2566 (16%)]\tLoss: 0.051002\n",
      "Train Epoch: 28 [440/2566 (17%)]\tLoss: 0.002591\n",
      "Train Epoch: 28 [480/2566 (19%)]\tLoss: 0.006054\n",
      "Train Epoch: 28 [520/2566 (20%)]\tLoss: 0.009908\n",
      "Train Epoch: 28 [560/2566 (22%)]\tLoss: 0.066365\n",
      "Train Epoch: 28 [600/2566 (23%)]\tLoss: 0.019630\n",
      "Train Epoch: 28 [640/2566 (25%)]\tLoss: 0.006640\n",
      "Train Epoch: 28 [680/2566 (26%)]\tLoss: 0.009784\n",
      "Train Epoch: 28 [720/2566 (28%)]\tLoss: 0.007904\n",
      "Train Epoch: 28 [760/2566 (30%)]\tLoss: 0.006053\n",
      "Train Epoch: 28 [800/2566 (31%)]\tLoss: 0.015459\n",
      "Train Epoch: 28 [840/2566 (33%)]\tLoss: 0.005636\n",
      "Train Epoch: 28 [880/2566 (34%)]\tLoss: 0.017134\n",
      "Train Epoch: 28 [920/2566 (36%)]\tLoss: 0.032280\n",
      "Train Epoch: 28 [960/2566 (37%)]\tLoss: 0.021022\n",
      "Train Epoch: 28 [1000/2566 (39%)]\tLoss: 0.019138\n",
      "Train Epoch: 28 [1040/2566 (40%)]\tLoss: 0.024304\n",
      "Train Epoch: 28 [1080/2566 (42%)]\tLoss: 0.150818\n",
      "Train Epoch: 28 [1120/2566 (44%)]\tLoss: 0.009188\n",
      "Train Epoch: 28 [1160/2566 (45%)]\tLoss: 0.010668\n",
      "Train Epoch: 28 [1200/2566 (47%)]\tLoss: 0.077768\n",
      "Train Epoch: 28 [1240/2566 (48%)]\tLoss: 0.005898\n",
      "Train Epoch: 28 [1280/2566 (50%)]\tLoss: 0.087270\n",
      "Train Epoch: 28 [1320/2566 (51%)]\tLoss: 0.031684\n",
      "Train Epoch: 28 [1360/2566 (53%)]\tLoss: 1.382047\n",
      "Train Epoch: 28 [1400/2566 (55%)]\tLoss: 0.061935\n",
      "Train Epoch: 28 [1440/2566 (56%)]\tLoss: 0.029777\n",
      "Train Epoch: 28 [1480/2566 (58%)]\tLoss: 0.021307\n",
      "Train Epoch: 28 [1520/2566 (59%)]\tLoss: 0.013527\n",
      "Train Epoch: 28 [1560/2566 (61%)]\tLoss: 0.095713\n",
      "Train Epoch: 28 [1600/2566 (62%)]\tLoss: 0.020114\n",
      "Train Epoch: 28 [1640/2566 (64%)]\tLoss: 0.018083\n",
      "Train Epoch: 28 [1680/2566 (65%)]\tLoss: 0.015501\n",
      "Train Epoch: 28 [1720/2566 (67%)]\tLoss: 0.047127\n",
      "Train Epoch: 28 [1760/2566 (69%)]\tLoss: 0.124687\n",
      "Train Epoch: 28 [1800/2566 (70%)]\tLoss: 0.041692\n",
      "Train Epoch: 28 [1840/2566 (72%)]\tLoss: 0.136555\n",
      "Train Epoch: 28 [1880/2566 (73%)]\tLoss: 0.018712\n",
      "Train Epoch: 28 [1920/2566 (75%)]\tLoss: 0.006289\n",
      "Train Epoch: 28 [1960/2566 (76%)]\tLoss: 0.021340\n",
      "Train Epoch: 28 [2000/2566 (78%)]\tLoss: 0.055374\n",
      "Train Epoch: 28 [2040/2566 (79%)]\tLoss: 0.190670\n",
      "Train Epoch: 28 [2080/2566 (81%)]\tLoss: 0.055128\n",
      "Train Epoch: 28 [2120/2566 (83%)]\tLoss: 0.014798\n",
      "Train Epoch: 28 [2160/2566 (84%)]\tLoss: 0.015606\n",
      "Train Epoch: 28 [2200/2566 (86%)]\tLoss: 0.012994\n",
      "Train Epoch: 28 [2240/2566 (87%)]\tLoss: 0.006395\n",
      "Train Epoch: 28 [2280/2566 (89%)]\tLoss: 0.006044\n",
      "Train Epoch: 28 [2320/2566 (90%)]\tLoss: 0.034560\n",
      "Train Epoch: 28 [2360/2566 (92%)]\tLoss: 0.009727\n",
      "Train Epoch: 28 [2400/2566 (93%)]\tLoss: 0.485984\n",
      "Train Epoch: 28 [2440/2566 (95%)]\tLoss: 0.005271\n",
      "Train Epoch: 28 [2480/2566 (97%)]\tLoss: 0.006946\n",
      "Train Epoch: 28 [2520/2566 (98%)]\tLoss: 0.008772\n",
      "Train Epoch: 28 [2560/2566 (100%)]\tLoss: 0.272657\n",
      "epoch:28,loss:0.05994448658895629\n",
      "Train set: Average loss: 0.0254, Accuracy: 2544/2566 (99%)\n",
      "Val set: Average loss: 0.6073, Accuracy: 265/327 (81%)\n",
      "Train Epoch: 29 [40/2566 (2%)]\tLoss: 0.018583\n",
      "Train Epoch: 29 [80/2566 (3%)]\tLoss: 0.041620\n",
      "Train Epoch: 29 [120/2566 (5%)]\tLoss: 0.025736\n",
      "Train Epoch: 29 [160/2566 (6%)]\tLoss: 0.023652\n",
      "Train Epoch: 29 [200/2566 (8%)]\tLoss: 0.019559\n",
      "Train Epoch: 29 [240/2566 (9%)]\tLoss: 0.027151\n",
      "Train Epoch: 29 [280/2566 (11%)]\tLoss: 0.040931\n",
      "Train Epoch: 29 [320/2566 (12%)]\tLoss: 0.019186\n",
      "Train Epoch: 29 [360/2566 (14%)]\tLoss: 0.009346\n",
      "Train Epoch: 29 [400/2566 (16%)]\tLoss: 0.010336\n",
      "Train Epoch: 29 [440/2566 (17%)]\tLoss: 0.004077\n",
      "Train Epoch: 29 [480/2566 (19%)]\tLoss: 0.006039\n",
      "Train Epoch: 29 [520/2566 (20%)]\tLoss: 0.004389\n",
      "Train Epoch: 29 [560/2566 (22%)]\tLoss: 0.023876\n",
      "Train Epoch: 29 [600/2566 (23%)]\tLoss: 0.009298\n",
      "Train Epoch: 29 [640/2566 (25%)]\tLoss: 0.010638\n",
      "Train Epoch: 29 [680/2566 (26%)]\tLoss: 0.005305\n",
      "Train Epoch: 29 [720/2566 (28%)]\tLoss: 0.022481\n",
      "Train Epoch: 29 [760/2566 (30%)]\tLoss: 0.004732\n",
      "Train Epoch: 29 [800/2566 (31%)]\tLoss: 0.011144\n",
      "Train Epoch: 29 [840/2566 (33%)]\tLoss: 0.018321\n",
      "Train Epoch: 29 [880/2566 (34%)]\tLoss: 0.008429\n",
      "Train Epoch: 29 [920/2566 (36%)]\tLoss: 0.007818\n",
      "Train Epoch: 29 [960/2566 (37%)]\tLoss: 0.584640\n",
      "Train Epoch: 29 [1000/2566 (39%)]\tLoss: 0.019279\n",
      "Train Epoch: 29 [1040/2566 (40%)]\tLoss: 0.081526\n",
      "Train Epoch: 29 [1080/2566 (42%)]\tLoss: 0.003632\n",
      "Train Epoch: 29 [1120/2566 (44%)]\tLoss: 0.031541\n",
      "Train Epoch: 29 [1160/2566 (45%)]\tLoss: 0.032204\n",
      "Train Epoch: 29 [1200/2566 (47%)]\tLoss: 0.260325\n",
      "Train Epoch: 29 [1240/2566 (48%)]\tLoss: 0.192940\n",
      "Train Epoch: 29 [1280/2566 (50%)]\tLoss: 0.074006\n",
      "Train Epoch: 29 [1320/2566 (51%)]\tLoss: 0.053684\n",
      "Train Epoch: 29 [1360/2566 (53%)]\tLoss: 0.244301\n",
      "Train Epoch: 29 [1400/2566 (55%)]\tLoss: 0.103484\n",
      "Train Epoch: 29 [1440/2566 (56%)]\tLoss: 0.004388\n",
      "Train Epoch: 29 [1480/2566 (58%)]\tLoss: 0.004702\n",
      "Train Epoch: 29 [1520/2566 (59%)]\tLoss: 0.014210\n",
      "Train Epoch: 29 [1560/2566 (61%)]\tLoss: 0.006837\n",
      "Train Epoch: 29 [1600/2566 (62%)]\tLoss: 0.028484\n",
      "Train Epoch: 29 [1640/2566 (64%)]\tLoss: 0.005455\n",
      "Train Epoch: 29 [1680/2566 (65%)]\tLoss: 0.093278\n",
      "Train Epoch: 29 [1720/2566 (67%)]\tLoss: 0.022273\n",
      "Train Epoch: 29 [1760/2566 (69%)]\tLoss: 0.010217\n",
      "Train Epoch: 29 [1800/2566 (70%)]\tLoss: 0.040024\n",
      "Train Epoch: 29 [1840/2566 (72%)]\tLoss: 0.038947\n",
      "Train Epoch: 29 [1880/2566 (73%)]\tLoss: 0.036351\n",
      "Train Epoch: 29 [1920/2566 (75%)]\tLoss: 0.126364\n",
      "Train Epoch: 29 [1960/2566 (76%)]\tLoss: 0.055647\n",
      "Train Epoch: 29 [2000/2566 (78%)]\tLoss: 1.032667\n",
      "Train Epoch: 29 [2040/2566 (79%)]\tLoss: 0.011595\n",
      "Train Epoch: 29 [2080/2566 (81%)]\tLoss: 0.008143\n",
      "Train Epoch: 29 [2120/2566 (83%)]\tLoss: 0.608178\n",
      "Train Epoch: 29 [2160/2566 (84%)]\tLoss: 0.012447\n",
      "Train Epoch: 29 [2200/2566 (86%)]\tLoss: 0.009568\n",
      "Train Epoch: 29 [2240/2566 (87%)]\tLoss: 0.004293\n",
      "Train Epoch: 29 [2280/2566 (89%)]\tLoss: 0.017902\n",
      "Train Epoch: 29 [2320/2566 (90%)]\tLoss: 0.027062\n",
      "Train Epoch: 29 [2360/2566 (92%)]\tLoss: 0.004577\n",
      "Train Epoch: 29 [2400/2566 (93%)]\tLoss: 0.002048\n",
      "Train Epoch: 29 [2440/2566 (95%)]\tLoss: 0.010569\n",
      "Train Epoch: 29 [2480/2566 (97%)]\tLoss: 0.014094\n",
      "Train Epoch: 29 [2520/2566 (98%)]\tLoss: 0.030970\n",
      "Train Epoch: 29 [2560/2566 (100%)]\tLoss: 0.002722\n",
      "epoch:29,loss:0.0598538356134668\n",
      "Train set: Average loss: 0.0227, Accuracy: 2545/2566 (99%)\n",
      "Val set: Average loss: 0.6413, Accuracy: 270/327 (83%)\n",
      "Train Epoch: 30 [40/2566 (2%)]\tLoss: 0.022551\n",
      "Train Epoch: 30 [80/2566 (3%)]\tLoss: 0.046704\n",
      "Train Epoch: 30 [120/2566 (5%)]\tLoss: 0.021378\n",
      "Train Epoch: 30 [160/2566 (6%)]\tLoss: 0.369478\n",
      "Train Epoch: 30 [200/2566 (8%)]\tLoss: 0.007983\n",
      "Train Epoch: 30 [240/2566 (9%)]\tLoss: 0.004362\n",
      "Train Epoch: 30 [280/2566 (11%)]\tLoss: 0.015944\n",
      "Train Epoch: 30 [320/2566 (12%)]\tLoss: 0.008313\n",
      "Train Epoch: 30 [360/2566 (14%)]\tLoss: 0.017618\n",
      "Train Epoch: 30 [400/2566 (16%)]\tLoss: 0.002846\n",
      "Train Epoch: 30 [440/2566 (17%)]\tLoss: 0.012787\n",
      "Train Epoch: 30 [480/2566 (19%)]\tLoss: 0.023951\n",
      "Train Epoch: 30 [520/2566 (20%)]\tLoss: 0.024318\n",
      "Train Epoch: 30 [560/2566 (22%)]\tLoss: 0.025628\n",
      "Train Epoch: 30 [600/2566 (23%)]\tLoss: 0.066170\n",
      "Train Epoch: 30 [640/2566 (25%)]\tLoss: 0.022365\n",
      "Train Epoch: 30 [680/2566 (26%)]\tLoss: 0.010826\n",
      "Train Epoch: 30 [720/2566 (28%)]\tLoss: 0.014512\n",
      "Train Epoch: 30 [760/2566 (30%)]\tLoss: 0.009029\n",
      "Train Epoch: 30 [800/2566 (31%)]\tLoss: 0.037583\n",
      "Train Epoch: 30 [840/2566 (33%)]\tLoss: 0.012639\n",
      "Train Epoch: 30 [880/2566 (34%)]\tLoss: 0.086518\n",
      "Train Epoch: 30 [920/2566 (36%)]\tLoss: 0.003736\n",
      "Train Epoch: 30 [960/2566 (37%)]\tLoss: 0.009277\n",
      "Train Epoch: 30 [1000/2566 (39%)]\tLoss: 0.034079\n",
      "Train Epoch: 30 [1040/2566 (40%)]\tLoss: 0.050337\n",
      "Train Epoch: 30 [1080/2566 (42%)]\tLoss: 0.018689\n",
      "Train Epoch: 30 [1120/2566 (44%)]\tLoss: 0.028316\n",
      "Train Epoch: 30 [1160/2566 (45%)]\tLoss: 0.007563\n",
      "Train Epoch: 30 [1200/2566 (47%)]\tLoss: 0.006938\n",
      "Train Epoch: 30 [1240/2566 (48%)]\tLoss: 0.014285\n",
      "Train Epoch: 30 [1280/2566 (50%)]\tLoss: 0.012817\n",
      "Train Epoch: 30 [1320/2566 (51%)]\tLoss: 0.007599\n",
      "Train Epoch: 30 [1360/2566 (53%)]\tLoss: 0.009913\n",
      "Train Epoch: 30 [1400/2566 (55%)]\tLoss: 0.012382\n",
      "Train Epoch: 30 [1440/2566 (56%)]\tLoss: 0.054427\n",
      "Train Epoch: 30 [1480/2566 (58%)]\tLoss: 0.037534\n",
      "Train Epoch: 30 [1520/2566 (59%)]\tLoss: 0.002104\n",
      "Train Epoch: 30 [1560/2566 (61%)]\tLoss: 0.003542\n",
      "Train Epoch: 30 [1600/2566 (62%)]\tLoss: 0.004728\n",
      "Train Epoch: 30 [1640/2566 (64%)]\tLoss: 0.089717\n",
      "Train Epoch: 30 [1680/2566 (65%)]\tLoss: 0.022267\n",
      "Train Epoch: 30 [1720/2566 (67%)]\tLoss: 0.009223\n",
      "Train Epoch: 30 [1760/2566 (69%)]\tLoss: 0.029649\n",
      "Train Epoch: 30 [1800/2566 (70%)]\tLoss: 0.038140\n",
      "Train Epoch: 30 [1840/2566 (72%)]\tLoss: 0.007086\n",
      "Train Epoch: 30 [1880/2566 (73%)]\tLoss: 0.016619\n",
      "Train Epoch: 30 [1920/2566 (75%)]\tLoss: 0.015056\n",
      "Train Epoch: 30 [1960/2566 (76%)]\tLoss: 0.007836\n",
      "Train Epoch: 30 [2000/2566 (78%)]\tLoss: 0.045025\n",
      "Train Epoch: 30 [2040/2566 (79%)]\tLoss: 0.027602\n",
      "Train Epoch: 30 [2080/2566 (81%)]\tLoss: 0.327991\n",
      "Train Epoch: 30 [2120/2566 (83%)]\tLoss: 0.037471\n",
      "Train Epoch: 30 [2160/2566 (84%)]\tLoss: 0.010355\n",
      "Train Epoch: 30 [2200/2566 (86%)]\tLoss: 0.005561\n",
      "Train Epoch: 30 [2240/2566 (87%)]\tLoss: 0.030205\n",
      "Train Epoch: 30 [2280/2566 (89%)]\tLoss: 0.020769\n",
      "Train Epoch: 30 [2320/2566 (90%)]\tLoss: 0.004680\n",
      "Train Epoch: 30 [2360/2566 (92%)]\tLoss: 0.024783\n",
      "Train Epoch: 30 [2400/2566 (93%)]\tLoss: 0.031420\n",
      "Train Epoch: 30 [2440/2566 (95%)]\tLoss: 0.004599\n",
      "Train Epoch: 30 [2480/2566 (97%)]\tLoss: 0.670918\n",
      "Train Epoch: 30 [2520/2566 (98%)]\tLoss: 0.008518\n",
      "Train Epoch: 30 [2560/2566 (100%)]\tLoss: 0.104329\n",
      "epoch:30,loss:0.0580268786143732\n",
      "Train set: Average loss: 0.0196, Accuracy: 2548/2566 (99%)\n",
      "Val set: Average loss: 0.5976, Accuracy: 269/327 (82%)\n",
      "Train Epoch: 31 [40/2566 (2%)]\tLoss: 0.007584\n",
      "Train Epoch: 31 [80/2566 (3%)]\tLoss: 0.122720\n",
      "Train Epoch: 31 [120/2566 (5%)]\tLoss: 0.003611\n",
      "Train Epoch: 31 [160/2566 (6%)]\tLoss: 0.020862\n",
      "Train Epoch: 31 [200/2566 (8%)]\tLoss: 0.004942\n",
      "Train Epoch: 31 [240/2566 (9%)]\tLoss: 0.008502\n",
      "Train Epoch: 31 [280/2566 (11%)]\tLoss: 0.005605\n",
      "Train Epoch: 31 [320/2566 (12%)]\tLoss: 0.026879\n",
      "Train Epoch: 31 [360/2566 (14%)]\tLoss: 0.011261\n",
      "Train Epoch: 31 [400/2566 (16%)]\tLoss: 0.003727\n",
      "Train Epoch: 31 [440/2566 (17%)]\tLoss: 0.278958\n",
      "Train Epoch: 31 [480/2566 (19%)]\tLoss: 0.003994\n",
      "Train Epoch: 31 [520/2566 (20%)]\tLoss: 0.025188\n",
      "Train Epoch: 31 [560/2566 (22%)]\tLoss: 0.053859\n",
      "Train Epoch: 31 [600/2566 (23%)]\tLoss: 0.023773\n",
      "Train Epoch: 31 [640/2566 (25%)]\tLoss: 0.022940\n",
      "Train Epoch: 31 [680/2566 (26%)]\tLoss: 0.023344\n",
      "Train Epoch: 31 [720/2566 (28%)]\tLoss: 0.005353\n",
      "Train Epoch: 31 [760/2566 (30%)]\tLoss: 0.003588\n",
      "Train Epoch: 31 [800/2566 (31%)]\tLoss: 0.391211\n",
      "Train Epoch: 31 [840/2566 (33%)]\tLoss: 0.052835\n",
      "Train Epoch: 31 [880/2566 (34%)]\tLoss: 0.003908\n",
      "Train Epoch: 31 [920/2566 (36%)]\tLoss: 0.007450\n",
      "Train Epoch: 31 [960/2566 (37%)]\tLoss: 0.004212\n",
      "Train Epoch: 31 [1000/2566 (39%)]\tLoss: 0.032494\n",
      "Train Epoch: 31 [1040/2566 (40%)]\tLoss: 0.001756\n",
      "Train Epoch: 31 [1080/2566 (42%)]\tLoss: 0.003746\n",
      "Train Epoch: 31 [1120/2566 (44%)]\tLoss: 0.095543\n",
      "Train Epoch: 31 [1160/2566 (45%)]\tLoss: 0.060631\n",
      "Train Epoch: 31 [1200/2566 (47%)]\tLoss: 0.015631\n",
      "Train Epoch: 31 [1240/2566 (48%)]\tLoss: 0.017338\n",
      "Train Epoch: 31 [1280/2566 (50%)]\tLoss: 0.289700\n",
      "Train Epoch: 31 [1320/2566 (51%)]\tLoss: 0.228048\n",
      "Train Epoch: 31 [1360/2566 (53%)]\tLoss: 0.003328\n",
      "Train Epoch: 31 [1400/2566 (55%)]\tLoss: 0.028545\n",
      "Train Epoch: 31 [1440/2566 (56%)]\tLoss: 0.010679\n",
      "Train Epoch: 31 [1480/2566 (58%)]\tLoss: 0.004793\n",
      "Train Epoch: 31 [1520/2566 (59%)]\tLoss: 0.008731\n",
      "Train Epoch: 31 [1560/2566 (61%)]\tLoss: 0.014097\n",
      "Train Epoch: 31 [1600/2566 (62%)]\tLoss: 0.436474\n",
      "Train Epoch: 31 [1640/2566 (64%)]\tLoss: 0.009460\n",
      "Train Epoch: 31 [1680/2566 (65%)]\tLoss: 0.004620\n",
      "Train Epoch: 31 [1720/2566 (67%)]\tLoss: 0.102993\n",
      "Train Epoch: 31 [1760/2566 (69%)]\tLoss: 0.130084\n",
      "Train Epoch: 31 [1800/2566 (70%)]\tLoss: 0.024891\n",
      "Train Epoch: 31 [1840/2566 (72%)]\tLoss: 0.003689\n",
      "Train Epoch: 31 [1880/2566 (73%)]\tLoss: 0.014738\n",
      "Train Epoch: 31 [1920/2566 (75%)]\tLoss: 0.014778\n",
      "Train Epoch: 31 [1960/2566 (76%)]\tLoss: 0.007834\n",
      "Train Epoch: 31 [2000/2566 (78%)]\tLoss: 0.176923\n",
      "Train Epoch: 31 [2040/2566 (79%)]\tLoss: 0.017298\n",
      "Train Epoch: 31 [2080/2566 (81%)]\tLoss: 0.004153\n",
      "Train Epoch: 31 [2120/2566 (83%)]\tLoss: 0.060725\n",
      "Train Epoch: 31 [2160/2566 (84%)]\tLoss: 0.011205\n",
      "Train Epoch: 31 [2200/2566 (86%)]\tLoss: 0.009632\n",
      "Train Epoch: 31 [2240/2566 (87%)]\tLoss: 0.324984\n",
      "Train Epoch: 31 [2280/2566 (89%)]\tLoss: 0.159060\n",
      "Train Epoch: 31 [2320/2566 (90%)]\tLoss: 0.323289\n",
      "Train Epoch: 31 [2360/2566 (92%)]\tLoss: 0.037180\n",
      "Train Epoch: 31 [2400/2566 (93%)]\tLoss: 0.064499\n",
      "Train Epoch: 31 [2440/2566 (95%)]\tLoss: 0.026242\n",
      "Train Epoch: 31 [2480/2566 (97%)]\tLoss: 0.022901\n",
      "Train Epoch: 31 [2520/2566 (98%)]\tLoss: 0.114108\n",
      "Train Epoch: 31 [2560/2566 (100%)]\tLoss: 0.019251\n",
      "epoch:31,loss:0.05816995448503945\n",
      "Train set: Average loss: 0.0233, Accuracy: 2546/2566 (99%)\n",
      "Val set: Average loss: 0.5920, Accuracy: 263/327 (80%)\n",
      "Train Epoch: 32 [40/2566 (2%)]\tLoss: 0.015469\n",
      "Train Epoch: 32 [80/2566 (3%)]\tLoss: 0.004502\n",
      "Train Epoch: 32 [120/2566 (5%)]\tLoss: 0.007512\n",
      "Train Epoch: 32 [160/2566 (6%)]\tLoss: 0.022118\n",
      "Train Epoch: 32 [200/2566 (8%)]\tLoss: 0.168644\n",
      "Train Epoch: 32 [240/2566 (9%)]\tLoss: 0.013069\n",
      "Train Epoch: 32 [280/2566 (11%)]\tLoss: 0.002621\n",
      "Train Epoch: 32 [320/2566 (12%)]\tLoss: 0.041034\n",
      "Train Epoch: 32 [360/2566 (14%)]\tLoss: 0.010271\n",
      "Train Epoch: 32 [400/2566 (16%)]\tLoss: 0.008361\n",
      "Train Epoch: 32 [440/2566 (17%)]\tLoss: 0.003930\n",
      "Train Epoch: 32 [480/2566 (19%)]\tLoss: 0.011542\n",
      "Train Epoch: 32 [520/2566 (20%)]\tLoss: 0.380802\n",
      "Train Epoch: 32 [560/2566 (22%)]\tLoss: 0.078268\n",
      "Train Epoch: 32 [600/2566 (23%)]\tLoss: 0.004673\n",
      "Train Epoch: 32 [640/2566 (25%)]\tLoss: 0.036324\n",
      "Train Epoch: 32 [680/2566 (26%)]\tLoss: 0.007233\n",
      "Train Epoch: 32 [720/2566 (28%)]\tLoss: 0.047718\n",
      "Train Epoch: 32 [760/2566 (30%)]\tLoss: 0.008515\n",
      "Train Epoch: 32 [800/2566 (31%)]\tLoss: 0.008356\n",
      "Train Epoch: 32 [840/2566 (33%)]\tLoss: 0.266540\n",
      "Train Epoch: 32 [880/2566 (34%)]\tLoss: 0.010294\n",
      "Train Epoch: 32 [920/2566 (36%)]\tLoss: 0.041282\n",
      "Train Epoch: 32 [960/2566 (37%)]\tLoss: 0.014493\n",
      "Train Epoch: 32 [1000/2566 (39%)]\tLoss: 0.003578\n",
      "Train Epoch: 32 [1040/2566 (40%)]\tLoss: 0.015502\n",
      "Train Epoch: 32 [1080/2566 (42%)]\tLoss: 0.008209\n",
      "Train Epoch: 32 [1120/2566 (44%)]\tLoss: 0.151783\n",
      "Train Epoch: 32 [1160/2566 (45%)]\tLoss: 0.192244\n",
      "Train Epoch: 32 [1200/2566 (47%)]\tLoss: 0.005899\n",
      "Train Epoch: 32 [1240/2566 (48%)]\tLoss: 0.003243\n",
      "Train Epoch: 32 [1280/2566 (50%)]\tLoss: 0.029649\n",
      "Train Epoch: 32 [1320/2566 (51%)]\tLoss: 0.015654\n",
      "Train Epoch: 32 [1360/2566 (53%)]\tLoss: 0.019381\n",
      "Train Epoch: 32 [1400/2566 (55%)]\tLoss: 0.006740\n",
      "Train Epoch: 32 [1440/2566 (56%)]\tLoss: 0.270344\n",
      "Train Epoch: 32 [1480/2566 (58%)]\tLoss: 0.010556\n",
      "Train Epoch: 32 [1520/2566 (59%)]\tLoss: 0.098305\n",
      "Train Epoch: 32 [1560/2566 (61%)]\tLoss: 0.245161\n",
      "Train Epoch: 32 [1600/2566 (62%)]\tLoss: 0.229596\n",
      "Train Epoch: 32 [1640/2566 (64%)]\tLoss: 0.016599\n",
      "Train Epoch: 32 [1680/2566 (65%)]\tLoss: 0.004283\n",
      "Train Epoch: 32 [1720/2566 (67%)]\tLoss: 0.024002\n",
      "Train Epoch: 32 [1760/2566 (69%)]\tLoss: 0.011671\n",
      "Train Epoch: 32 [1800/2566 (70%)]\tLoss: 0.001647\n",
      "Train Epoch: 32 [1840/2566 (72%)]\tLoss: 0.035518\n",
      "Train Epoch: 32 [1880/2566 (73%)]\tLoss: 0.014282\n",
      "Train Epoch: 32 [1920/2566 (75%)]\tLoss: 0.055811\n",
      "Train Epoch: 32 [1960/2566 (76%)]\tLoss: 0.327700\n",
      "Train Epoch: 32 [2000/2566 (78%)]\tLoss: 0.033360\n",
      "Train Epoch: 32 [2040/2566 (79%)]\tLoss: 0.018130\n",
      "Train Epoch: 32 [2080/2566 (81%)]\tLoss: 0.005566\n",
      "Train Epoch: 32 [2120/2566 (83%)]\tLoss: 0.058313\n",
      "Train Epoch: 32 [2160/2566 (84%)]\tLoss: 0.046780\n",
      "Train Epoch: 32 [2200/2566 (86%)]\tLoss: 0.012922\n",
      "Train Epoch: 32 [2240/2566 (87%)]\tLoss: 0.036374\n",
      "Train Epoch: 32 [2280/2566 (89%)]\tLoss: 0.021659\n",
      "Train Epoch: 32 [2320/2566 (90%)]\tLoss: 0.447568\n",
      "Train Epoch: 32 [2360/2566 (92%)]\tLoss: 0.013515\n",
      "Train Epoch: 32 [2400/2566 (93%)]\tLoss: 0.031994\n",
      "Train Epoch: 32 [2440/2566 (95%)]\tLoss: 0.005428\n",
      "Train Epoch: 32 [2480/2566 (97%)]\tLoss: 0.016567\n",
      "Train Epoch: 32 [2520/2566 (98%)]\tLoss: 0.042805\n",
      "Train Epoch: 32 [2560/2566 (100%)]\tLoss: 0.102675\n",
      "epoch:32,loss:0.06226362521227774\n",
      "Train set: Average loss: 0.0233, Accuracy: 2540/2566 (99%)\n",
      "Val set: Average loss: 0.5987, Accuracy: 262/327 (80%)\n",
      "Train Epoch: 33 [40/2566 (2%)]\tLoss: 0.016620\n",
      "Train Epoch: 33 [80/2566 (3%)]\tLoss: 0.028737\n",
      "Train Epoch: 33 [120/2566 (5%)]\tLoss: 0.029453\n",
      "Train Epoch: 33 [160/2566 (6%)]\tLoss: 0.003665\n",
      "Train Epoch: 33 [200/2566 (8%)]\tLoss: 0.028452\n",
      "Train Epoch: 33 [240/2566 (9%)]\tLoss: 0.012703\n",
      "Train Epoch: 33 [280/2566 (11%)]\tLoss: 0.004034\n",
      "Train Epoch: 33 [320/2566 (12%)]\tLoss: 0.013525\n",
      "Train Epoch: 33 [360/2566 (14%)]\tLoss: 0.013641\n",
      "Train Epoch: 33 [400/2566 (16%)]\tLoss: 0.003131\n",
      "Train Epoch: 33 [440/2566 (17%)]\tLoss: 0.005446\n",
      "Train Epoch: 33 [480/2566 (19%)]\tLoss: 0.008078\n",
      "Train Epoch: 33 [520/2566 (20%)]\tLoss: 0.011794\n",
      "Train Epoch: 33 [560/2566 (22%)]\tLoss: 0.020174\n",
      "Train Epoch: 33 [600/2566 (23%)]\tLoss: 0.015133\n",
      "Train Epoch: 33 [640/2566 (25%)]\tLoss: 0.027941\n",
      "Train Epoch: 33 [680/2566 (26%)]\tLoss: 0.082660\n",
      "Train Epoch: 33 [720/2566 (28%)]\tLoss: 0.026397\n",
      "Train Epoch: 33 [760/2566 (30%)]\tLoss: 0.011911\n",
      "Train Epoch: 33 [800/2566 (31%)]\tLoss: 0.060709\n",
      "Train Epoch: 33 [840/2566 (33%)]\tLoss: 0.006548\n",
      "Train Epoch: 33 [880/2566 (34%)]\tLoss: 0.019955\n",
      "Train Epoch: 33 [920/2566 (36%)]\tLoss: 0.522117\n",
      "Train Epoch: 33 [960/2566 (37%)]\tLoss: 0.064998\n",
      "Train Epoch: 33 [1000/2566 (39%)]\tLoss: 0.021123\n",
      "Train Epoch: 33 [1040/2566 (40%)]\tLoss: 0.020307\n",
      "Train Epoch: 33 [1080/2566 (42%)]\tLoss: 0.025445\n",
      "Train Epoch: 33 [1120/2566 (44%)]\tLoss: 0.019262\n",
      "Train Epoch: 33 [1160/2566 (45%)]\tLoss: 0.002900\n",
      "Train Epoch: 33 [1200/2566 (47%)]\tLoss: 0.024790\n",
      "Train Epoch: 33 [1240/2566 (48%)]\tLoss: 0.006326\n",
      "Train Epoch: 33 [1280/2566 (50%)]\tLoss: 0.003950\n",
      "Train Epoch: 33 [1320/2566 (51%)]\tLoss: 0.005609\n",
      "Train Epoch: 33 [1360/2566 (53%)]\tLoss: 0.083156\n",
      "Train Epoch: 33 [1400/2566 (55%)]\tLoss: 0.007027\n",
      "Train Epoch: 33 [1440/2566 (56%)]\tLoss: 0.006998\n",
      "Train Epoch: 33 [1480/2566 (58%)]\tLoss: 0.012140\n",
      "Train Epoch: 33 [1520/2566 (59%)]\tLoss: 0.007971\n",
      "Train Epoch: 33 [1560/2566 (61%)]\tLoss: 0.021669\n",
      "Train Epoch: 33 [1600/2566 (62%)]\tLoss: 0.006164\n",
      "Train Epoch: 33 [1640/2566 (64%)]\tLoss: 0.008129\n",
      "Train Epoch: 33 [1680/2566 (65%)]\tLoss: 0.007762\n",
      "Train Epoch: 33 [1720/2566 (67%)]\tLoss: 0.003993\n",
      "Train Epoch: 33 [1760/2566 (69%)]\tLoss: 0.092655\n",
      "Train Epoch: 33 [1800/2566 (70%)]\tLoss: 0.025609\n",
      "Train Epoch: 33 [1840/2566 (72%)]\tLoss: 0.001571\n",
      "Train Epoch: 33 [1880/2566 (73%)]\tLoss: 0.021313\n",
      "Train Epoch: 33 [1920/2566 (75%)]\tLoss: 0.006874\n",
      "Train Epoch: 33 [1960/2566 (76%)]\tLoss: 0.019019\n",
      "Train Epoch: 33 [2000/2566 (78%)]\tLoss: 0.161367\n",
      "Train Epoch: 33 [2040/2566 (79%)]\tLoss: 0.008990\n",
      "Train Epoch: 33 [2080/2566 (81%)]\tLoss: 0.031503\n",
      "Train Epoch: 33 [2120/2566 (83%)]\tLoss: 0.009252\n",
      "Train Epoch: 33 [2160/2566 (84%)]\tLoss: 0.008615\n",
      "Train Epoch: 33 [2200/2566 (86%)]\tLoss: 0.006228\n",
      "Train Epoch: 33 [2240/2566 (87%)]\tLoss: 0.034128\n",
      "Train Epoch: 33 [2280/2566 (89%)]\tLoss: 0.066412\n",
      "Train Epoch: 33 [2320/2566 (90%)]\tLoss: 0.004447\n",
      "Train Epoch: 33 [2360/2566 (92%)]\tLoss: 0.505420\n",
      "Train Epoch: 33 [2400/2566 (93%)]\tLoss: 0.006753\n",
      "Train Epoch: 33 [2440/2566 (95%)]\tLoss: 0.009090\n",
      "Train Epoch: 33 [2480/2566 (97%)]\tLoss: 0.034424\n",
      "Train Epoch: 33 [2520/2566 (98%)]\tLoss: 0.031339\n",
      "Train Epoch: 33 [2560/2566 (100%)]\tLoss: 0.003583\n",
      "epoch:33,loss:0.049875346795406277\n",
      "Train set: Average loss: 0.0226, Accuracy: 2549/2566 (99%)\n",
      "Val set: Average loss: 0.6331, Accuracy: 264/327 (81%)\n",
      "Train Epoch: 34 [40/2566 (2%)]\tLoss: 0.017188\n",
      "Train Epoch: 34 [80/2566 (3%)]\tLoss: 0.010997\n",
      "Train Epoch: 34 [120/2566 (5%)]\tLoss: 0.030092\n",
      "Train Epoch: 34 [160/2566 (6%)]\tLoss: 0.007580\n",
      "Train Epoch: 34 [200/2566 (8%)]\tLoss: 0.008651\n",
      "Train Epoch: 34 [240/2566 (9%)]\tLoss: 0.026250\n",
      "Train Epoch: 34 [280/2566 (11%)]\tLoss: 0.011502\n",
      "Train Epoch: 34 [320/2566 (12%)]\tLoss: 0.003807\n",
      "Train Epoch: 34 [360/2566 (14%)]\tLoss: 0.027019\n",
      "Train Epoch: 34 [400/2566 (16%)]\tLoss: 0.006294\n",
      "Train Epoch: 34 [440/2566 (17%)]\tLoss: 0.021798\n",
      "Train Epoch: 34 [480/2566 (19%)]\tLoss: 0.002228\n",
      "Train Epoch: 34 [520/2566 (20%)]\tLoss: 0.006360\n",
      "Train Epoch: 34 [560/2566 (22%)]\tLoss: 0.004572\n",
      "Train Epoch: 34 [600/2566 (23%)]\tLoss: 0.002001\n",
      "Train Epoch: 34 [640/2566 (25%)]\tLoss: 0.020770\n",
      "Train Epoch: 34 [680/2566 (26%)]\tLoss: 0.015702\n",
      "Train Epoch: 34 [720/2566 (28%)]\tLoss: 0.345752\n",
      "Train Epoch: 34 [760/2566 (30%)]\tLoss: 0.012104\n",
      "Train Epoch: 34 [800/2566 (31%)]\tLoss: 0.001607\n",
      "Train Epoch: 34 [840/2566 (33%)]\tLoss: 0.006907\n",
      "Train Epoch: 34 [880/2566 (34%)]\tLoss: 0.017771\n",
      "Train Epoch: 34 [920/2566 (36%)]\tLoss: 0.897954\n",
      "Train Epoch: 34 [960/2566 (37%)]\tLoss: 0.004607\n",
      "Train Epoch: 34 [1000/2566 (39%)]\tLoss: 0.087824\n",
      "Train Epoch: 34 [1040/2566 (40%)]\tLoss: 0.009933\n",
      "Train Epoch: 34 [1080/2566 (42%)]\tLoss: 0.012424\n",
      "Train Epoch: 34 [1120/2566 (44%)]\tLoss: 0.012589\n",
      "Train Epoch: 34 [1160/2566 (45%)]\tLoss: 0.013826\n",
      "Train Epoch: 34 [1200/2566 (47%)]\tLoss: 0.010366\n",
      "Train Epoch: 34 [1240/2566 (48%)]\tLoss: 0.026608\n",
      "Train Epoch: 34 [1280/2566 (50%)]\tLoss: 0.230405\n",
      "Train Epoch: 34 [1320/2566 (51%)]\tLoss: 0.639585\n",
      "Train Epoch: 34 [1360/2566 (53%)]\tLoss: 0.006350\n",
      "Train Epoch: 34 [1400/2566 (55%)]\tLoss: 0.056830\n",
      "Train Epoch: 34 [1440/2566 (56%)]\tLoss: 0.010424\n",
      "Train Epoch: 34 [1480/2566 (58%)]\tLoss: 0.024678\n",
      "Train Epoch: 34 [1520/2566 (59%)]\tLoss: 0.011762\n",
      "Train Epoch: 34 [1560/2566 (61%)]\tLoss: 0.002864\n",
      "Train Epoch: 34 [1600/2566 (62%)]\tLoss: 0.032036\n",
      "Train Epoch: 34 [1640/2566 (64%)]\tLoss: 0.026628\n",
      "Train Epoch: 34 [1680/2566 (65%)]\tLoss: 0.032258\n",
      "Train Epoch: 34 [1720/2566 (67%)]\tLoss: 0.029862\n",
      "Train Epoch: 34 [1760/2566 (69%)]\tLoss: 0.008872\n",
      "Train Epoch: 34 [1800/2566 (70%)]\tLoss: 0.107217\n",
      "Train Epoch: 34 [1840/2566 (72%)]\tLoss: 0.029457\n",
      "Train Epoch: 34 [1880/2566 (73%)]\tLoss: 0.009355\n",
      "Train Epoch: 34 [1920/2566 (75%)]\tLoss: 0.004738\n",
      "Train Epoch: 34 [1960/2566 (76%)]\tLoss: 0.236887\n",
      "Train Epoch: 34 [2000/2566 (78%)]\tLoss: 0.156352\n",
      "Train Epoch: 34 [2040/2566 (79%)]\tLoss: 0.006029\n",
      "Train Epoch: 34 [2080/2566 (81%)]\tLoss: 0.007504\n",
      "Train Epoch: 34 [2120/2566 (83%)]\tLoss: 0.003442\n",
      "Train Epoch: 34 [2160/2566 (84%)]\tLoss: 0.002604\n",
      "Train Epoch: 34 [2200/2566 (86%)]\tLoss: 0.237222\n",
      "Train Epoch: 34 [2240/2566 (87%)]\tLoss: 0.387225\n",
      "Train Epoch: 34 [2280/2566 (89%)]\tLoss: 0.040128\n",
      "Train Epoch: 34 [2320/2566 (90%)]\tLoss: 0.001823\n",
      "Train Epoch: 34 [2360/2566 (92%)]\tLoss: 0.008159\n",
      "Train Epoch: 34 [2400/2566 (93%)]\tLoss: 0.003607\n",
      "Train Epoch: 34 [2440/2566 (95%)]\tLoss: 0.006025\n",
      "Train Epoch: 34 [2480/2566 (97%)]\tLoss: 0.009386\n",
      "Train Epoch: 34 [2520/2566 (98%)]\tLoss: 0.009266\n",
      "Train Epoch: 34 [2560/2566 (100%)]\tLoss: 0.045656\n",
      "epoch:34,loss:0.05461533376192703\n",
      "Train set: Average loss: 0.0189, Accuracy: 2547/2566 (99%)\n",
      "Val set: Average loss: 0.5952, Accuracy: 266/327 (81%)\n",
      "Train Epoch: 35 [40/2566 (2%)]\tLoss: 0.264609\n",
      "Train Epoch: 35 [80/2566 (3%)]\tLoss: 0.043069\n",
      "Train Epoch: 35 [120/2566 (5%)]\tLoss: 0.115282\n",
      "Train Epoch: 35 [160/2566 (6%)]\tLoss: 0.057149\n",
      "Train Epoch: 35 [200/2566 (8%)]\tLoss: 0.013933\n",
      "Train Epoch: 35 [240/2566 (9%)]\tLoss: 0.006016\n",
      "Train Epoch: 35 [280/2566 (11%)]\tLoss: 0.010537\n",
      "Train Epoch: 35 [320/2566 (12%)]\tLoss: 0.012087\n",
      "Train Epoch: 35 [360/2566 (14%)]\tLoss: 0.602663\n",
      "Train Epoch: 35 [400/2566 (16%)]\tLoss: 0.012552\n",
      "Train Epoch: 35 [440/2566 (17%)]\tLoss: 0.020691\n",
      "Train Epoch: 35 [480/2566 (19%)]\tLoss: 0.011969\n",
      "Train Epoch: 35 [520/2566 (20%)]\tLoss: 0.007026\n",
      "Train Epoch: 35 [560/2566 (22%)]\tLoss: 0.030572\n",
      "Train Epoch: 35 [600/2566 (23%)]\tLoss: 0.024048\n",
      "Train Epoch: 35 [640/2566 (25%)]\tLoss: 0.004573\n",
      "Train Epoch: 35 [680/2566 (26%)]\tLoss: 0.023069\n",
      "Train Epoch: 35 [720/2566 (28%)]\tLoss: 0.039441\n",
      "Train Epoch: 35 [760/2566 (30%)]\tLoss: 0.003706\n",
      "Train Epoch: 35 [800/2566 (31%)]\tLoss: 0.221545\n",
      "Train Epoch: 35 [840/2566 (33%)]\tLoss: 0.003255\n",
      "Train Epoch: 35 [880/2566 (34%)]\tLoss: 0.060640\n",
      "Train Epoch: 35 [920/2566 (36%)]\tLoss: 0.393901\n",
      "Train Epoch: 35 [960/2566 (37%)]\tLoss: 0.027378\n",
      "Train Epoch: 35 [1000/2566 (39%)]\tLoss: 0.002746\n",
      "Train Epoch: 35 [1040/2566 (40%)]\tLoss: 0.057168\n",
      "Train Epoch: 35 [1080/2566 (42%)]\tLoss: 0.006799\n",
      "Train Epoch: 35 [1120/2566 (44%)]\tLoss: 0.068502\n",
      "Train Epoch: 35 [1160/2566 (45%)]\tLoss: 0.007608\n",
      "Train Epoch: 35 [1200/2566 (47%)]\tLoss: 0.021912\n",
      "Train Epoch: 35 [1240/2566 (48%)]\tLoss: 0.020915\n",
      "Train Epoch: 35 [1280/2566 (50%)]\tLoss: 0.013127\n",
      "Train Epoch: 35 [1320/2566 (51%)]\tLoss: 0.014250\n",
      "Train Epoch: 35 [1360/2566 (53%)]\tLoss: 0.071409\n",
      "Train Epoch: 35 [1400/2566 (55%)]\tLoss: 0.003517\n",
      "Train Epoch: 35 [1440/2566 (56%)]\tLoss: 0.082451\n",
      "Train Epoch: 35 [1480/2566 (58%)]\tLoss: 0.007105\n",
      "Train Epoch: 35 [1520/2566 (59%)]\tLoss: 0.168637\n",
      "Train Epoch: 35 [1560/2566 (61%)]\tLoss: 0.005734\n",
      "Train Epoch: 35 [1600/2566 (62%)]\tLoss: 0.007089\n",
      "Train Epoch: 35 [1640/2566 (64%)]\tLoss: 0.010512\n",
      "Train Epoch: 35 [1680/2566 (65%)]\tLoss: 0.014659\n",
      "Train Epoch: 35 [1720/2566 (67%)]\tLoss: 0.320301\n",
      "Train Epoch: 35 [1760/2566 (69%)]\tLoss: 0.003149\n",
      "Train Epoch: 35 [1800/2566 (70%)]\tLoss: 0.002819\n",
      "Train Epoch: 35 [1840/2566 (72%)]\tLoss: 0.024021\n",
      "Train Epoch: 35 [1880/2566 (73%)]\tLoss: 0.003853\n",
      "Train Epoch: 35 [1920/2566 (75%)]\tLoss: 0.031290\n",
      "Train Epoch: 35 [1960/2566 (76%)]\tLoss: 0.008592\n",
      "Train Epoch: 35 [2000/2566 (78%)]\tLoss: 0.081880\n",
      "Train Epoch: 35 [2040/2566 (79%)]\tLoss: 0.006601\n",
      "Train Epoch: 35 [2080/2566 (81%)]\tLoss: 0.356025\n",
      "Train Epoch: 35 [2120/2566 (83%)]\tLoss: 0.049465\n",
      "Train Epoch: 35 [2160/2566 (84%)]\tLoss: 0.004766\n",
      "Train Epoch: 35 [2200/2566 (86%)]\tLoss: 0.003454\n",
      "Train Epoch: 35 [2240/2566 (87%)]\tLoss: 0.069218\n",
      "Train Epoch: 35 [2280/2566 (89%)]\tLoss: 0.010909\n",
      "Train Epoch: 35 [2320/2566 (90%)]\tLoss: 0.084886\n",
      "Train Epoch: 35 [2360/2566 (92%)]\tLoss: 0.107990\n",
      "Train Epoch: 35 [2400/2566 (93%)]\tLoss: 0.009064\n",
      "Train Epoch: 35 [2440/2566 (95%)]\tLoss: 0.212365\n",
      "Train Epoch: 35 [2480/2566 (97%)]\tLoss: 0.003359\n",
      "Train Epoch: 35 [2520/2566 (98%)]\tLoss: 0.018658\n",
      "Train Epoch: 35 [2560/2566 (100%)]\tLoss: 0.136548\n",
      "epoch:35,loss:0.05485162698240179\n",
      "Train set: Average loss: 0.0183, Accuracy: 2544/2566 (99%)\n",
      "Val set: Average loss: 0.6547, Accuracy: 267/327 (82%)\n",
      "Train Epoch: 36 [40/2566 (2%)]\tLoss: 0.009899\n",
      "Train Epoch: 36 [80/2566 (3%)]\tLoss: 0.002407\n",
      "Train Epoch: 36 [120/2566 (5%)]\tLoss: 0.044294\n",
      "Train Epoch: 36 [160/2566 (6%)]\tLoss: 0.020161\n",
      "Train Epoch: 36 [200/2566 (8%)]\tLoss: 0.009454\n",
      "Train Epoch: 36 [240/2566 (9%)]\tLoss: 0.016351\n",
      "Train Epoch: 36 [280/2566 (11%)]\tLoss: 0.039382\n",
      "Train Epoch: 36 [320/2566 (12%)]\tLoss: 0.012122\n",
      "Train Epoch: 36 [360/2566 (14%)]\tLoss: 0.087756\n",
      "Train Epoch: 36 [400/2566 (16%)]\tLoss: 0.011821\n",
      "Train Epoch: 36 [440/2566 (17%)]\tLoss: 0.095147\n",
      "Train Epoch: 36 [480/2566 (19%)]\tLoss: 0.003061\n",
      "Train Epoch: 36 [520/2566 (20%)]\tLoss: 0.012515\n",
      "Train Epoch: 36 [560/2566 (22%)]\tLoss: 0.004697\n",
      "Train Epoch: 36 [600/2566 (23%)]\tLoss: 0.008194\n",
      "Train Epoch: 36 [640/2566 (25%)]\tLoss: 0.008301\n",
      "Train Epoch: 36 [680/2566 (26%)]\tLoss: 0.206889\n",
      "Train Epoch: 36 [720/2566 (28%)]\tLoss: 0.009357\n",
      "Train Epoch: 36 [760/2566 (30%)]\tLoss: 0.023447\n",
      "Train Epoch: 36 [800/2566 (31%)]\tLoss: 0.020429\n",
      "Train Epoch: 36 [840/2566 (33%)]\tLoss: 0.025886\n",
      "Train Epoch: 36 [880/2566 (34%)]\tLoss: 0.009288\n",
      "Train Epoch: 36 [920/2566 (36%)]\tLoss: 0.005269\n",
      "Train Epoch: 36 [960/2566 (37%)]\tLoss: 0.134812\n",
      "Train Epoch: 36 [1000/2566 (39%)]\tLoss: 0.013687\n",
      "Train Epoch: 36 [1040/2566 (40%)]\tLoss: 0.029959\n",
      "Train Epoch: 36 [1080/2566 (42%)]\tLoss: 0.026202\n",
      "Train Epoch: 36 [1120/2566 (44%)]\tLoss: 0.007722\n",
      "Train Epoch: 36 [1160/2566 (45%)]\tLoss: 0.025905\n",
      "Train Epoch: 36 [1200/2566 (47%)]\tLoss: 0.007946\n",
      "Train Epoch: 36 [1240/2566 (48%)]\tLoss: 0.056201\n",
      "Train Epoch: 36 [1280/2566 (50%)]\tLoss: 0.003178\n",
      "Train Epoch: 36 [1320/2566 (51%)]\tLoss: 0.004223\n",
      "Train Epoch: 36 [1360/2566 (53%)]\tLoss: 0.005960\n",
      "Train Epoch: 36 [1400/2566 (55%)]\tLoss: 0.009994\n",
      "Train Epoch: 36 [1440/2566 (56%)]\tLoss: 0.005078\n",
      "Train Epoch: 36 [1480/2566 (58%)]\tLoss: 0.004114\n",
      "Train Epoch: 36 [1520/2566 (59%)]\tLoss: 0.033849\n",
      "Train Epoch: 36 [1560/2566 (61%)]\tLoss: 0.007446\n",
      "Train Epoch: 36 [1600/2566 (62%)]\tLoss: 0.001754\n",
      "Train Epoch: 36 [1640/2566 (64%)]\tLoss: 0.014866\n",
      "Train Epoch: 36 [1680/2566 (65%)]\tLoss: 0.007080\n",
      "Train Epoch: 36 [1720/2566 (67%)]\tLoss: 0.078864\n",
      "Train Epoch: 36 [1760/2566 (69%)]\tLoss: 0.027418\n",
      "Train Epoch: 36 [1800/2566 (70%)]\tLoss: 0.012049\n",
      "Train Epoch: 36 [1840/2566 (72%)]\tLoss: 0.005429\n",
      "Train Epoch: 36 [1880/2566 (73%)]\tLoss: 0.001109\n",
      "Train Epoch: 36 [1920/2566 (75%)]\tLoss: 0.004403\n",
      "Train Epoch: 36 [1960/2566 (76%)]\tLoss: 0.003652\n",
      "Train Epoch: 36 [2000/2566 (78%)]\tLoss: 0.011633\n",
      "Train Epoch: 36 [2040/2566 (79%)]\tLoss: 0.041576\n",
      "Train Epoch: 36 [2080/2566 (81%)]\tLoss: 0.261631\n",
      "Train Epoch: 36 [2120/2566 (83%)]\tLoss: 0.002501\n",
      "Train Epoch: 36 [2160/2566 (84%)]\tLoss: 0.012141\n",
      "Train Epoch: 36 [2200/2566 (86%)]\tLoss: 0.005663\n",
      "Train Epoch: 36 [2240/2566 (87%)]\tLoss: 0.044942\n",
      "Train Epoch: 36 [2280/2566 (89%)]\tLoss: 0.239882\n",
      "Train Epoch: 36 [2320/2566 (90%)]\tLoss: 0.012008\n",
      "Train Epoch: 36 [2360/2566 (92%)]\tLoss: 0.016926\n",
      "Train Epoch: 36 [2400/2566 (93%)]\tLoss: 0.042295\n",
      "Train Epoch: 36 [2440/2566 (95%)]\tLoss: 0.021874\n",
      "Train Epoch: 36 [2480/2566 (97%)]\tLoss: 0.003108\n",
      "Train Epoch: 36 [2520/2566 (98%)]\tLoss: 0.002735\n",
      "Train Epoch: 36 [2560/2566 (100%)]\tLoss: 0.005135\n",
      "epoch:36,loss:0.043077845971036206\n",
      "Train set: Average loss: 0.0195, Accuracy: 2547/2566 (99%)\n",
      "Val set: Average loss: 0.6147, Accuracy: 269/327 (82%)\n",
      "Train Epoch: 37 [40/2566 (2%)]\tLoss: 0.062801\n",
      "Train Epoch: 37 [80/2566 (3%)]\tLoss: 0.019631\n",
      "Train Epoch: 37 [120/2566 (5%)]\tLoss: 0.008363\n",
      "Train Epoch: 37 [160/2566 (6%)]\tLoss: 0.019461\n",
      "Train Epoch: 37 [200/2566 (8%)]\tLoss: 0.025879\n",
      "Train Epoch: 37 [240/2566 (9%)]\tLoss: 0.016501\n",
      "Train Epoch: 37 [280/2566 (11%)]\tLoss: 0.008012\n",
      "Train Epoch: 37 [320/2566 (12%)]\tLoss: 0.048726\n",
      "Train Epoch: 37 [360/2566 (14%)]\tLoss: 0.004843\n",
      "Train Epoch: 37 [400/2566 (16%)]\tLoss: 0.030873\n",
      "Train Epoch: 37 [440/2566 (17%)]\tLoss: 2.071230\n",
      "Train Epoch: 37 [480/2566 (19%)]\tLoss: 0.139564\n",
      "Train Epoch: 37 [520/2566 (20%)]\tLoss: 0.004084\n",
      "Train Epoch: 37 [560/2566 (22%)]\tLoss: 0.004321\n",
      "Train Epoch: 37 [600/2566 (23%)]\tLoss: 0.009521\n",
      "Train Epoch: 37 [640/2566 (25%)]\tLoss: 0.028894\n",
      "Train Epoch: 37 [680/2566 (26%)]\tLoss: 0.009545\n",
      "Train Epoch: 37 [720/2566 (28%)]\tLoss: 0.010490\n",
      "Train Epoch: 37 [760/2566 (30%)]\tLoss: 0.003725\n",
      "Train Epoch: 37 [800/2566 (31%)]\tLoss: 0.014594\n",
      "Train Epoch: 37 [840/2566 (33%)]\tLoss: 0.021221\n",
      "Train Epoch: 37 [880/2566 (34%)]\tLoss: 0.021747\n",
      "Train Epoch: 37 [920/2566 (36%)]\tLoss: 0.007227\n",
      "Train Epoch: 37 [960/2566 (37%)]\tLoss: 0.004654\n",
      "Train Epoch: 37 [1000/2566 (39%)]\tLoss: 0.004632\n",
      "Train Epoch: 37 [1040/2566 (40%)]\tLoss: 0.006686\n",
      "Train Epoch: 37 [1080/2566 (42%)]\tLoss: 0.144638\n",
      "Train Epoch: 37 [1120/2566 (44%)]\tLoss: 0.002155\n",
      "Train Epoch: 37 [1160/2566 (45%)]\tLoss: 0.003092\n",
      "Train Epoch: 37 [1200/2566 (47%)]\tLoss: 0.009875\n",
      "Train Epoch: 37 [1240/2566 (48%)]\tLoss: 0.017896\n",
      "Train Epoch: 37 [1280/2566 (50%)]\tLoss: 0.001569\n",
      "Train Epoch: 37 [1320/2566 (51%)]\tLoss: 0.095290\n",
      "Train Epoch: 37 [1360/2566 (53%)]\tLoss: 0.011891\n",
      "Train Epoch: 37 [1400/2566 (55%)]\tLoss: 0.008992\n",
      "Train Epoch: 37 [1440/2566 (56%)]\tLoss: 0.310594\n",
      "Train Epoch: 37 [1480/2566 (58%)]\tLoss: 0.002777\n",
      "Train Epoch: 37 [1520/2566 (59%)]\tLoss: 0.004295\n",
      "Train Epoch: 37 [1560/2566 (61%)]\tLoss: 0.024559\n",
      "Train Epoch: 37 [1600/2566 (62%)]\tLoss: 0.075724\n",
      "Train Epoch: 37 [1640/2566 (64%)]\tLoss: 0.006585\n",
      "Train Epoch: 37 [1680/2566 (65%)]\tLoss: 0.005403\n",
      "Train Epoch: 37 [1720/2566 (67%)]\tLoss: 0.010203\n",
      "Train Epoch: 37 [1760/2566 (69%)]\tLoss: 0.021842\n",
      "Train Epoch: 37 [1800/2566 (70%)]\tLoss: 0.018277\n",
      "Train Epoch: 37 [1840/2566 (72%)]\tLoss: 0.003876\n",
      "Train Epoch: 37 [1880/2566 (73%)]\tLoss: 0.008527\n",
      "Train Epoch: 37 [1920/2566 (75%)]\tLoss: 0.020092\n",
      "Train Epoch: 37 [1960/2566 (76%)]\tLoss: 0.014431\n",
      "Train Epoch: 37 [2000/2566 (78%)]\tLoss: 0.010980\n",
      "Train Epoch: 37 [2040/2566 (79%)]\tLoss: 0.032976\n",
      "Train Epoch: 37 [2080/2566 (81%)]\tLoss: 0.110378\n",
      "Train Epoch: 37 [2120/2566 (83%)]\tLoss: 0.016813\n",
      "Train Epoch: 37 [2160/2566 (84%)]\tLoss: 0.016655\n",
      "Train Epoch: 37 [2200/2566 (86%)]\tLoss: 0.030969\n",
      "Train Epoch: 37 [2240/2566 (87%)]\tLoss: 0.013254\n",
      "Train Epoch: 37 [2280/2566 (89%)]\tLoss: 0.042124\n",
      "Train Epoch: 37 [2320/2566 (90%)]\tLoss: 0.002452\n",
      "Train Epoch: 37 [2360/2566 (92%)]\tLoss: 0.094294\n",
      "Train Epoch: 37 [2400/2566 (93%)]\tLoss: 0.038348\n",
      "Train Epoch: 37 [2440/2566 (95%)]\tLoss: 0.008924\n",
      "Train Epoch: 37 [2480/2566 (97%)]\tLoss: 0.002467\n",
      "Train Epoch: 37 [2520/2566 (98%)]\tLoss: 0.330496\n",
      "Train Epoch: 37 [2560/2566 (100%)]\tLoss: 0.081557\n",
      "epoch:37,loss:0.043144303298558215\n",
      "Train set: Average loss: 0.0207, Accuracy: 2546/2566 (99%)\n",
      "Val set: Average loss: 0.6468, Accuracy: 262/327 (80%)\n",
      "Train Epoch: 38 [40/2566 (2%)]\tLoss: 0.002671\n",
      "Train Epoch: 38 [80/2566 (3%)]\tLoss: 0.016528\n",
      "Train Epoch: 38 [120/2566 (5%)]\tLoss: 0.007514\n",
      "Train Epoch: 38 [160/2566 (6%)]\tLoss: 0.009979\n",
      "Train Epoch: 38 [200/2566 (8%)]\tLoss: 0.042491\n",
      "Train Epoch: 38 [240/2566 (9%)]\tLoss: 0.049821\n",
      "Train Epoch: 38 [280/2566 (11%)]\tLoss: 0.004340\n",
      "Train Epoch: 38 [320/2566 (12%)]\tLoss: 0.002890\n",
      "Train Epoch: 38 [360/2566 (14%)]\tLoss: 0.011173\n",
      "Train Epoch: 38 [400/2566 (16%)]\tLoss: 0.007127\n",
      "Train Epoch: 38 [440/2566 (17%)]\tLoss: 0.019249\n",
      "Train Epoch: 38 [480/2566 (19%)]\tLoss: 0.001161\n",
      "Train Epoch: 38 [520/2566 (20%)]\tLoss: 0.123824\n",
      "Train Epoch: 38 [560/2566 (22%)]\tLoss: 0.005328\n",
      "Train Epoch: 38 [600/2566 (23%)]\tLoss: 0.005876\n",
      "Train Epoch: 38 [640/2566 (25%)]\tLoss: 0.005290\n",
      "Train Epoch: 38 [680/2566 (26%)]\tLoss: 0.009850\n",
      "Train Epoch: 38 [720/2566 (28%)]\tLoss: 0.007326\n",
      "Train Epoch: 38 [760/2566 (30%)]\tLoss: 0.008641\n",
      "Train Epoch: 38 [800/2566 (31%)]\tLoss: 0.001678\n",
      "Train Epoch: 38 [840/2566 (33%)]\tLoss: 0.014667\n",
      "Train Epoch: 38 [880/2566 (34%)]\tLoss: 0.184973\n",
      "Train Epoch: 38 [920/2566 (36%)]\tLoss: 0.088198\n",
      "Train Epoch: 38 [960/2566 (37%)]\tLoss: 0.014691\n",
      "Train Epoch: 38 [1000/2566 (39%)]\tLoss: 0.020350\n",
      "Train Epoch: 38 [1040/2566 (40%)]\tLoss: 0.007877\n",
      "Train Epoch: 38 [1080/2566 (42%)]\tLoss: 0.005248\n",
      "Train Epoch: 38 [1120/2566 (44%)]\tLoss: 0.013802\n",
      "Train Epoch: 38 [1160/2566 (45%)]\tLoss: 0.009582\n",
      "Train Epoch: 38 [1200/2566 (47%)]\tLoss: 0.005184\n",
      "Train Epoch: 38 [1240/2566 (48%)]\tLoss: 0.010010\n",
      "Train Epoch: 38 [1280/2566 (50%)]\tLoss: 0.004923\n",
      "Train Epoch: 38 [1320/2566 (51%)]\tLoss: 0.011674\n",
      "Train Epoch: 38 [1360/2566 (53%)]\tLoss: 0.006640\n",
      "Train Epoch: 38 [1400/2566 (55%)]\tLoss: 0.061054\n",
      "Train Epoch: 38 [1440/2566 (56%)]\tLoss: 0.006165\n",
      "Train Epoch: 38 [1480/2566 (58%)]\tLoss: 0.002270\n",
      "Train Epoch: 38 [1520/2566 (59%)]\tLoss: 0.024030\n",
      "Train Epoch: 38 [1560/2566 (61%)]\tLoss: 0.002214\n",
      "Train Epoch: 38 [1600/2566 (62%)]\tLoss: 0.001840\n",
      "Train Epoch: 38 [1640/2566 (64%)]\tLoss: 0.031460\n",
      "Train Epoch: 38 [1680/2566 (65%)]\tLoss: 0.002524\n",
      "Train Epoch: 38 [1720/2566 (67%)]\tLoss: 0.029724\n",
      "Train Epoch: 38 [1760/2566 (69%)]\tLoss: 0.003375\n",
      "Train Epoch: 38 [1800/2566 (70%)]\tLoss: 0.022101\n",
      "Train Epoch: 38 [1840/2566 (72%)]\tLoss: 0.001514\n",
      "Train Epoch: 38 [1880/2566 (73%)]\tLoss: 0.248295\n",
      "Train Epoch: 38 [1920/2566 (75%)]\tLoss: 0.118282\n",
      "Train Epoch: 38 [1960/2566 (76%)]\tLoss: 0.002764\n",
      "Train Epoch: 38 [2000/2566 (78%)]\tLoss: 0.006561\n",
      "Train Epoch: 38 [2040/2566 (79%)]\tLoss: 0.014262\n",
      "Train Epoch: 38 [2080/2566 (81%)]\tLoss: 0.009012\n",
      "Train Epoch: 38 [2120/2566 (83%)]\tLoss: 0.025869\n",
      "Train Epoch: 38 [2160/2566 (84%)]\tLoss: 0.031425\n",
      "Train Epoch: 38 [2200/2566 (86%)]\tLoss: 0.001443\n",
      "Train Epoch: 38 [2240/2566 (87%)]\tLoss: 0.002398\n",
      "Train Epoch: 38 [2280/2566 (89%)]\tLoss: 0.099264\n",
      "Train Epoch: 38 [2320/2566 (90%)]\tLoss: 0.227828\n",
      "Train Epoch: 38 [2360/2566 (92%)]\tLoss: 0.106758\n",
      "Train Epoch: 38 [2400/2566 (93%)]\tLoss: 0.008995\n",
      "Train Epoch: 38 [2440/2566 (95%)]\tLoss: 0.002453\n",
      "Train Epoch: 38 [2480/2566 (97%)]\tLoss: 0.032271\n",
      "Train Epoch: 38 [2520/2566 (98%)]\tLoss: 0.004790\n",
      "Train Epoch: 38 [2560/2566 (100%)]\tLoss: 0.007281\n",
      "epoch:38,loss:0.05077431050388177\n",
      "Train set: Average loss: 0.0226, Accuracy: 2543/2566 (99%)\n",
      "Val set: Average loss: 0.7053, Accuracy: 263/327 (80%)\n",
      "Train Epoch: 39 [40/2566 (2%)]\tLoss: 0.040690\n",
      "Train Epoch: 39 [80/2566 (3%)]\tLoss: 0.186696\n",
      "Train Epoch: 39 [120/2566 (5%)]\tLoss: 0.098745\n",
      "Train Epoch: 39 [160/2566 (6%)]\tLoss: 0.069693\n",
      "Train Epoch: 39 [200/2566 (8%)]\tLoss: 0.008384\n",
      "Train Epoch: 39 [240/2566 (9%)]\tLoss: 0.311601\n",
      "Train Epoch: 39 [280/2566 (11%)]\tLoss: 0.192963\n",
      "Train Epoch: 39 [320/2566 (12%)]\tLoss: 0.012020\n",
      "Train Epoch: 39 [360/2566 (14%)]\tLoss: 0.005783\n",
      "Train Epoch: 39 [400/2566 (16%)]\tLoss: 0.030170\n",
      "Train Epoch: 39 [440/2566 (17%)]\tLoss: 0.010034\n",
      "Train Epoch: 39 [480/2566 (19%)]\tLoss: 0.002517\n",
      "Train Epoch: 39 [520/2566 (20%)]\tLoss: 0.085872\n",
      "Train Epoch: 39 [560/2566 (22%)]\tLoss: 0.002351\n",
      "Train Epoch: 39 [600/2566 (23%)]\tLoss: 0.076990\n",
      "Train Epoch: 39 [640/2566 (25%)]\tLoss: 0.013812\n",
      "Train Epoch: 39 [680/2566 (26%)]\tLoss: 0.005715\n",
      "Train Epoch: 39 [720/2566 (28%)]\tLoss: 0.011065\n",
      "Train Epoch: 39 [760/2566 (30%)]\tLoss: 0.007561\n",
      "Train Epoch: 39 [800/2566 (31%)]\tLoss: 0.002683\n",
      "Train Epoch: 39 [840/2566 (33%)]\tLoss: 0.010122\n",
      "Train Epoch: 39 [880/2566 (34%)]\tLoss: 0.371498\n",
      "Train Epoch: 39 [920/2566 (36%)]\tLoss: 0.007618\n",
      "Train Epoch: 39 [960/2566 (37%)]\tLoss: 0.018214\n",
      "Train Epoch: 39 [1000/2566 (39%)]\tLoss: 0.006748\n",
      "Train Epoch: 39 [1040/2566 (40%)]\tLoss: 0.013405\n",
      "Train Epoch: 39 [1080/2566 (42%)]\tLoss: 0.007750\n",
      "Train Epoch: 39 [1120/2566 (44%)]\tLoss: 0.001961\n",
      "Train Epoch: 39 [1160/2566 (45%)]\tLoss: 0.039817\n",
      "Train Epoch: 39 [1200/2566 (47%)]\tLoss: 0.058619\n",
      "Train Epoch: 39 [1240/2566 (48%)]\tLoss: 0.004058\n",
      "Train Epoch: 39 [1280/2566 (50%)]\tLoss: 0.030420\n",
      "Train Epoch: 39 [1320/2566 (51%)]\tLoss: 0.200299\n",
      "Train Epoch: 39 [1360/2566 (53%)]\tLoss: 0.005058\n",
      "Train Epoch: 39 [1400/2566 (55%)]\tLoss: 0.022246\n",
      "Train Epoch: 39 [1440/2566 (56%)]\tLoss: 0.131969\n",
      "Train Epoch: 39 [1480/2566 (58%)]\tLoss: 0.006442\n",
      "Train Epoch: 39 [1520/2566 (59%)]\tLoss: 0.008100\n",
      "Train Epoch: 39 [1560/2566 (61%)]\tLoss: 0.002336\n",
      "Train Epoch: 39 [1600/2566 (62%)]\tLoss: 0.000947\n",
      "Train Epoch: 39 [1640/2566 (64%)]\tLoss: 0.112630\n",
      "Train Epoch: 39 [1680/2566 (65%)]\tLoss: 0.274615\n",
      "Train Epoch: 39 [1720/2566 (67%)]\tLoss: 0.014646\n",
      "Train Epoch: 39 [1760/2566 (69%)]\tLoss: 0.001685\n",
      "Train Epoch: 39 [1800/2566 (70%)]\tLoss: 0.241046\n",
      "Train Epoch: 39 [1840/2566 (72%)]\tLoss: 0.005484\n",
      "Train Epoch: 39 [1880/2566 (73%)]\tLoss: 0.023247\n",
      "Train Epoch: 39 [1920/2566 (75%)]\tLoss: 0.006889\n",
      "Train Epoch: 39 [1960/2566 (76%)]\tLoss: 0.020547\n",
      "Train Epoch: 39 [2000/2566 (78%)]\tLoss: 0.043333\n",
      "Train Epoch: 39 [2040/2566 (79%)]\tLoss: 0.002883\n",
      "Train Epoch: 39 [2080/2566 (81%)]\tLoss: 0.006545\n",
      "Train Epoch: 39 [2120/2566 (83%)]\tLoss: 0.003607\n",
      "Train Epoch: 39 [2160/2566 (84%)]\tLoss: 0.041151\n",
      "Train Epoch: 39 [2200/2566 (86%)]\tLoss: 0.013023\n",
      "Train Epoch: 39 [2240/2566 (87%)]\tLoss: 0.016287\n",
      "Train Epoch: 39 [2280/2566 (89%)]\tLoss: 0.003471\n",
      "Train Epoch: 39 [2320/2566 (90%)]\tLoss: 0.248798\n",
      "Train Epoch: 39 [2360/2566 (92%)]\tLoss: 0.022434\n",
      "Train Epoch: 39 [2400/2566 (93%)]\tLoss: 0.011214\n",
      "Train Epoch: 39 [2440/2566 (95%)]\tLoss: 0.132965\n",
      "Train Epoch: 39 [2480/2566 (97%)]\tLoss: 0.008693\n",
      "Train Epoch: 39 [2520/2566 (98%)]\tLoss: 0.005607\n",
      "Train Epoch: 39 [2560/2566 (100%)]\tLoss: 0.002944\n",
      "epoch:39,loss:0.039754495302119476\n",
      "Train set: Average loss: 0.0197, Accuracy: 2545/2566 (99%)\n",
      "Val set: Average loss: 0.6771, Accuracy: 266/327 (81%)\n",
      "Train Epoch: 40 [40/2566 (2%)]\tLoss: 0.014213\n",
      "Train Epoch: 40 [80/2566 (3%)]\tLoss: 0.003627\n",
      "Train Epoch: 40 [120/2566 (5%)]\tLoss: 0.002199\n",
      "Train Epoch: 40 [160/2566 (6%)]\tLoss: 0.478394\n",
      "Train Epoch: 40 [200/2566 (8%)]\tLoss: 0.003889\n",
      "Train Epoch: 40 [240/2566 (9%)]\tLoss: 0.050320\n",
      "Train Epoch: 40 [280/2566 (11%)]\tLoss: 0.005865\n",
      "Train Epoch: 40 [320/2566 (12%)]\tLoss: 0.001216\n",
      "Train Epoch: 40 [360/2566 (14%)]\tLoss: 0.020222\n",
      "Train Epoch: 40 [400/2566 (16%)]\tLoss: 0.082893\n",
      "Train Epoch: 40 [440/2566 (17%)]\tLoss: 0.009176\n",
      "Train Epoch: 40 [480/2566 (19%)]\tLoss: 0.002501\n",
      "Train Epoch: 40 [520/2566 (20%)]\tLoss: 0.003696\n",
      "Train Epoch: 40 [560/2566 (22%)]\tLoss: 0.006696\n",
      "Train Epoch: 40 [600/2566 (23%)]\tLoss: 0.012141\n",
      "Train Epoch: 40 [640/2566 (25%)]\tLoss: 0.021850\n",
      "Train Epoch: 40 [680/2566 (26%)]\tLoss: 0.019986\n",
      "Train Epoch: 40 [720/2566 (28%)]\tLoss: 0.005163\n",
      "Train Epoch: 40 [760/2566 (30%)]\tLoss: 0.009026\n",
      "Train Epoch: 40 [800/2566 (31%)]\tLoss: 0.003473\n",
      "Train Epoch: 40 [840/2566 (33%)]\tLoss: 0.000567\n",
      "Train Epoch: 40 [880/2566 (34%)]\tLoss: 0.013220\n",
      "Train Epoch: 40 [920/2566 (36%)]\tLoss: 0.013979\n",
      "Train Epoch: 40 [960/2566 (37%)]\tLoss: 0.004583\n",
      "Train Epoch: 40 [1000/2566 (39%)]\tLoss: 0.005631\n",
      "Train Epoch: 40 [1040/2566 (40%)]\tLoss: 0.087341\n",
      "Train Epoch: 40 [1080/2566 (42%)]\tLoss: 0.009349\n",
      "Train Epoch: 40 [1120/2566 (44%)]\tLoss: 0.006416\n",
      "Train Epoch: 40 [1160/2566 (45%)]\tLoss: 0.008170\n",
      "Train Epoch: 40 [1200/2566 (47%)]\tLoss: 0.011223\n",
      "Train Epoch: 40 [1240/2566 (48%)]\tLoss: 0.024616\n",
      "Train Epoch: 40 [1280/2566 (50%)]\tLoss: 0.000895\n",
      "Train Epoch: 40 [1320/2566 (51%)]\tLoss: 0.004218\n",
      "Train Epoch: 40 [1360/2566 (53%)]\tLoss: 0.008907\n",
      "Train Epoch: 40 [1400/2566 (55%)]\tLoss: 0.005709\n",
      "Train Epoch: 40 [1440/2566 (56%)]\tLoss: 0.016779\n",
      "Train Epoch: 40 [1480/2566 (58%)]\tLoss: 0.273034\n",
      "Train Epoch: 40 [1520/2566 (59%)]\tLoss: 0.004150\n",
      "Train Epoch: 40 [1560/2566 (61%)]\tLoss: 0.001432\n",
      "Train Epoch: 40 [1600/2566 (62%)]\tLoss: 0.009694\n",
      "Train Epoch: 40 [1640/2566 (64%)]\tLoss: 0.005970\n",
      "Train Epoch: 40 [1680/2566 (65%)]\tLoss: 0.026000\n",
      "Train Epoch: 40 [1720/2566 (67%)]\tLoss: 0.008786\n",
      "Train Epoch: 40 [1760/2566 (69%)]\tLoss: 0.118856\n",
      "Train Epoch: 40 [1800/2566 (70%)]\tLoss: 0.133978\n",
      "Train Epoch: 40 [1840/2566 (72%)]\tLoss: 0.038871\n",
      "Train Epoch: 40 [1880/2566 (73%)]\tLoss: 0.007933\n",
      "Train Epoch: 40 [1920/2566 (75%)]\tLoss: 0.008935\n",
      "Train Epoch: 40 [1960/2566 (76%)]\tLoss: 0.005893\n",
      "Train Epoch: 40 [2000/2566 (78%)]\tLoss: 0.003951\n",
      "Train Epoch: 40 [2040/2566 (79%)]\tLoss: 0.011995\n",
      "Train Epoch: 40 [2080/2566 (81%)]\tLoss: 0.562041\n",
      "Train Epoch: 40 [2120/2566 (83%)]\tLoss: 0.007781\n",
      "Train Epoch: 40 [2160/2566 (84%)]\tLoss: 0.012221\n",
      "Train Epoch: 40 [2200/2566 (86%)]\tLoss: 0.021020\n",
      "Train Epoch: 40 [2240/2566 (87%)]\tLoss: 0.235765\n",
      "Train Epoch: 40 [2280/2566 (89%)]\tLoss: 0.010957\n",
      "Train Epoch: 40 [2320/2566 (90%)]\tLoss: 0.022780\n",
      "Train Epoch: 40 [2360/2566 (92%)]\tLoss: 0.018785\n",
      "Train Epoch: 40 [2400/2566 (93%)]\tLoss: 0.101650\n",
      "Train Epoch: 40 [2440/2566 (95%)]\tLoss: 0.040161\n",
      "Train Epoch: 40 [2480/2566 (97%)]\tLoss: 0.015852\n",
      "Train Epoch: 40 [2520/2566 (98%)]\tLoss: 0.007450\n",
      "Train Epoch: 40 [2560/2566 (100%)]\tLoss: 0.002533\n",
      "epoch:40,loss:0.0442382411899283\n",
      "Train set: Average loss: 0.0238, Accuracy: 2540/2566 (99%)\n",
      "Val set: Average loss: 0.7749, Accuracy: 258/327 (79%)\n",
      "Train Epoch: 41 [40/2566 (2%)]\tLoss: 0.024133\n",
      "Train Epoch: 41 [80/2566 (3%)]\tLoss: 0.023833\n",
      "Train Epoch: 41 [120/2566 (5%)]\tLoss: 0.005972\n",
      "Train Epoch: 41 [160/2566 (6%)]\tLoss: 0.037663\n",
      "Train Epoch: 41 [200/2566 (8%)]\tLoss: 0.007217\n",
      "Train Epoch: 41 [240/2566 (9%)]\tLoss: 0.002701\n",
      "Train Epoch: 41 [280/2566 (11%)]\tLoss: 0.004257\n",
      "Train Epoch: 41 [320/2566 (12%)]\tLoss: 0.006158\n",
      "Train Epoch: 41 [360/2566 (14%)]\tLoss: 0.004957\n",
      "Train Epoch: 41 [400/2566 (16%)]\tLoss: 0.024542\n",
      "Train Epoch: 41 [440/2566 (17%)]\tLoss: 0.006866\n",
      "Train Epoch: 41 [480/2566 (19%)]\tLoss: 0.005785\n",
      "Train Epoch: 41 [520/2566 (20%)]\tLoss: 0.048375\n",
      "Train Epoch: 41 [560/2566 (22%)]\tLoss: 0.001351\n",
      "Train Epoch: 41 [600/2566 (23%)]\tLoss: 0.010652\n",
      "Train Epoch: 41 [640/2566 (25%)]\tLoss: 0.022455\n",
      "Train Epoch: 41 [680/2566 (26%)]\tLoss: 0.373993\n",
      "Train Epoch: 41 [720/2566 (28%)]\tLoss: 0.361252\n",
      "Train Epoch: 41 [760/2566 (30%)]\tLoss: 0.002650\n",
      "Train Epoch: 41 [800/2566 (31%)]\tLoss: 0.005714\n",
      "Train Epoch: 41 [840/2566 (33%)]\tLoss: 0.006016\n",
      "Train Epoch: 41 [880/2566 (34%)]\tLoss: 0.090308\n",
      "Train Epoch: 41 [920/2566 (36%)]\tLoss: 0.001649\n",
      "Train Epoch: 41 [960/2566 (37%)]\tLoss: 0.003889\n",
      "Train Epoch: 41 [1000/2566 (39%)]\tLoss: 0.006922\n",
      "Train Epoch: 41 [1040/2566 (40%)]\tLoss: 0.003910\n",
      "Train Epoch: 41 [1080/2566 (42%)]\tLoss: 0.010989\n",
      "Train Epoch: 41 [1120/2566 (44%)]\tLoss: 0.010730\n",
      "Train Epoch: 41 [1160/2566 (45%)]\tLoss: 0.014804\n",
      "Train Epoch: 41 [1200/2566 (47%)]\tLoss: 0.006915\n",
      "Train Epoch: 41 [1240/2566 (48%)]\tLoss: 0.020340\n",
      "Train Epoch: 41 [1280/2566 (50%)]\tLoss: 0.011445\n",
      "Train Epoch: 41 [1320/2566 (51%)]\tLoss: 0.008045\n",
      "Train Epoch: 41 [1360/2566 (53%)]\tLoss: 0.008421\n",
      "Train Epoch: 41 [1400/2566 (55%)]\tLoss: 0.004926\n",
      "Train Epoch: 41 [1440/2566 (56%)]\tLoss: 0.002799\n",
      "Train Epoch: 41 [1480/2566 (58%)]\tLoss: 0.008510\n",
      "Train Epoch: 41 [1520/2566 (59%)]\tLoss: 0.003429\n",
      "Train Epoch: 41 [1560/2566 (61%)]\tLoss: 0.014514\n",
      "Train Epoch: 41 [1600/2566 (62%)]\tLoss: 0.015568\n",
      "Train Epoch: 41 [1640/2566 (64%)]\tLoss: 0.002781\n",
      "Train Epoch: 41 [1680/2566 (65%)]\tLoss: 0.007046\n",
      "Train Epoch: 41 [1720/2566 (67%)]\tLoss: 0.042831\n",
      "Train Epoch: 41 [1760/2566 (69%)]\tLoss: 0.047523\n",
      "Train Epoch: 41 [1800/2566 (70%)]\tLoss: 0.012701\n",
      "Train Epoch: 41 [1840/2566 (72%)]\tLoss: 0.001803\n",
      "Train Epoch: 41 [1880/2566 (73%)]\tLoss: 0.014552\n",
      "Train Epoch: 41 [1920/2566 (75%)]\tLoss: 0.019734\n",
      "Train Epoch: 41 [1960/2566 (76%)]\tLoss: 0.011285\n",
      "Train Epoch: 41 [2000/2566 (78%)]\tLoss: 0.011743\n",
      "Train Epoch: 41 [2040/2566 (79%)]\tLoss: 0.025048\n",
      "Train Epoch: 41 [2080/2566 (81%)]\tLoss: 0.013978\n",
      "Train Epoch: 41 [2120/2566 (83%)]\tLoss: 0.030574\n",
      "Train Epoch: 41 [2160/2566 (84%)]\tLoss: 0.006973\n",
      "Train Epoch: 41 [2200/2566 (86%)]\tLoss: 0.004146\n",
      "Train Epoch: 41 [2240/2566 (87%)]\tLoss: 0.021699\n",
      "Train Epoch: 41 [2280/2566 (89%)]\tLoss: 0.006075\n",
      "Train Epoch: 41 [2320/2566 (90%)]\tLoss: 0.143568\n",
      "Train Epoch: 41 [2360/2566 (92%)]\tLoss: 0.018311\n",
      "Train Epoch: 41 [2400/2566 (93%)]\tLoss: 0.005610\n",
      "Train Epoch: 41 [2440/2566 (95%)]\tLoss: 0.022248\n",
      "Train Epoch: 41 [2480/2566 (97%)]\tLoss: 0.174452\n",
      "Train Epoch: 41 [2520/2566 (98%)]\tLoss: 0.055301\n",
      "Train Epoch: 41 [2560/2566 (100%)]\tLoss: 0.011182\n",
      "epoch:41,loss:0.044800389815024697\n",
      "Train set: Average loss: 0.0197, Accuracy: 2545/2566 (99%)\n",
      "Val set: Average loss: 0.6899, Accuracy: 257/327 (79%)\n",
      "Train Epoch: 42 [40/2566 (2%)]\tLoss: 0.107849\n",
      "Train Epoch: 42 [80/2566 (3%)]\tLoss: 0.005307\n",
      "Train Epoch: 42 [120/2566 (5%)]\tLoss: 0.002215\n",
      "Train Epoch: 42 [160/2566 (6%)]\tLoss: 0.084376\n",
      "Train Epoch: 42 [200/2566 (8%)]\tLoss: 0.005570\n",
      "Train Epoch: 42 [240/2566 (9%)]\tLoss: 0.013205\n",
      "Train Epoch: 42 [280/2566 (11%)]\tLoss: 0.005417\n",
      "Train Epoch: 42 [320/2566 (12%)]\tLoss: 0.023861\n",
      "Train Epoch: 42 [360/2566 (14%)]\tLoss: 0.010230\n",
      "Train Epoch: 42 [400/2566 (16%)]\tLoss: 0.077551\n",
      "Train Epoch: 42 [440/2566 (17%)]\tLoss: 0.017165\n",
      "Train Epoch: 42 [480/2566 (19%)]\tLoss: 0.009638\n",
      "Train Epoch: 42 [520/2566 (20%)]\tLoss: 0.029713\n",
      "Train Epoch: 42 [560/2566 (22%)]\tLoss: 0.088371\n",
      "Train Epoch: 42 [600/2566 (23%)]\tLoss: 0.004563\n",
      "Train Epoch: 42 [640/2566 (25%)]\tLoss: 0.003676\n",
      "Train Epoch: 42 [680/2566 (26%)]\tLoss: 0.008128\n",
      "Train Epoch: 42 [720/2566 (28%)]\tLoss: 0.010766\n",
      "Train Epoch: 42 [760/2566 (30%)]\tLoss: 0.002135\n",
      "Train Epoch: 42 [800/2566 (31%)]\tLoss: 0.012420\n",
      "Train Epoch: 42 [840/2566 (33%)]\tLoss: 0.362755\n",
      "Train Epoch: 42 [880/2566 (34%)]\tLoss: 0.051219\n",
      "Train Epoch: 42 [920/2566 (36%)]\tLoss: 0.131770\n",
      "Train Epoch: 42 [960/2566 (37%)]\tLoss: 0.001372\n",
      "Train Epoch: 42 [1000/2566 (39%)]\tLoss: 0.001603\n",
      "Train Epoch: 42 [1040/2566 (40%)]\tLoss: 0.044174\n",
      "Train Epoch: 42 [1080/2566 (42%)]\tLoss: 0.001568\n",
      "Train Epoch: 42 [1120/2566 (44%)]\tLoss: 0.071312\n",
      "Train Epoch: 42 [1160/2566 (45%)]\tLoss: 0.006684\n",
      "Train Epoch: 42 [1200/2566 (47%)]\tLoss: 0.244846\n",
      "Train Epoch: 42 [1240/2566 (48%)]\tLoss: 0.005044\n",
      "Train Epoch: 42 [1280/2566 (50%)]\tLoss: 0.003520\n",
      "Train Epoch: 42 [1320/2566 (51%)]\tLoss: 0.002677\n",
      "Train Epoch: 42 [1360/2566 (53%)]\tLoss: 0.114651\n",
      "Train Epoch: 42 [1400/2566 (55%)]\tLoss: 0.007914\n",
      "Train Epoch: 42 [1440/2566 (56%)]\tLoss: 0.007314\n",
      "Train Epoch: 42 [1480/2566 (58%)]\tLoss: 0.052794\n",
      "Train Epoch: 42 [1520/2566 (59%)]\tLoss: 0.034363\n",
      "Train Epoch: 42 [1560/2566 (61%)]\tLoss: 0.006748\n",
      "Train Epoch: 42 [1600/2566 (62%)]\tLoss: 0.004887\n",
      "Train Epoch: 42 [1640/2566 (64%)]\tLoss: 0.266160\n",
      "Train Epoch: 42 [1680/2566 (65%)]\tLoss: 0.012541\n",
      "Train Epoch: 42 [1720/2566 (67%)]\tLoss: 0.002593\n",
      "Train Epoch: 42 [1760/2566 (69%)]\tLoss: 0.003511\n",
      "Train Epoch: 42 [1800/2566 (70%)]\tLoss: 0.003486\n",
      "Train Epoch: 42 [1840/2566 (72%)]\tLoss: 0.004506\n",
      "Train Epoch: 42 [1880/2566 (73%)]\tLoss: 0.014841\n",
      "Train Epoch: 42 [1920/2566 (75%)]\tLoss: 0.344575\n",
      "Train Epoch: 42 [1960/2566 (76%)]\tLoss: 0.002821\n",
      "Train Epoch: 42 [2000/2566 (78%)]\tLoss: 0.013564\n",
      "Train Epoch: 42 [2040/2566 (79%)]\tLoss: 0.010075\n",
      "Train Epoch: 42 [2080/2566 (81%)]\tLoss: 0.016303\n",
      "Train Epoch: 42 [2120/2566 (83%)]\tLoss: 0.010204\n",
      "Train Epoch: 42 [2160/2566 (84%)]\tLoss: 0.008199\n",
      "Train Epoch: 42 [2200/2566 (86%)]\tLoss: 0.001608\n",
      "Train Epoch: 42 [2240/2566 (87%)]\tLoss: 0.226825\n",
      "Train Epoch: 42 [2280/2566 (89%)]\tLoss: 0.004190\n",
      "Train Epoch: 42 [2320/2566 (90%)]\tLoss: 0.008185\n",
      "Train Epoch: 42 [2360/2566 (92%)]\tLoss: 0.170784\n",
      "Train Epoch: 42 [2400/2566 (93%)]\tLoss: 0.004692\n",
      "Train Epoch: 42 [2440/2566 (95%)]\tLoss: 0.035739\n",
      "Train Epoch: 42 [2480/2566 (97%)]\tLoss: 0.027694\n",
      "Train Epoch: 42 [2520/2566 (98%)]\tLoss: 0.000908\n",
      "Train Epoch: 42 [2560/2566 (100%)]\tLoss: 0.328101\n",
      "epoch:42,loss:0.03787391254663137\n",
      "Train set: Average loss: 0.0193, Accuracy: 2544/2566 (99%)\n",
      "Val set: Average loss: 0.6685, Accuracy: 267/327 (82%)\n",
      "Train Epoch: 43 [40/2566 (2%)]\tLoss: 0.001758\n",
      "Train Epoch: 43 [80/2566 (3%)]\tLoss: 0.013268\n",
      "Train Epoch: 43 [120/2566 (5%)]\tLoss: 0.008162\n",
      "Train Epoch: 43 [160/2566 (6%)]\tLoss: 0.005255\n",
      "Train Epoch: 43 [200/2566 (8%)]\tLoss: 0.028654\n",
      "Train Epoch: 43 [240/2566 (9%)]\tLoss: 0.005057\n",
      "Train Epoch: 43 [280/2566 (11%)]\tLoss: 0.065107\n",
      "Train Epoch: 43 [320/2566 (12%)]\tLoss: 0.004016\n",
      "Train Epoch: 43 [360/2566 (14%)]\tLoss: 0.005064\n",
      "Train Epoch: 43 [400/2566 (16%)]\tLoss: 0.005948\n",
      "Train Epoch: 43 [440/2566 (17%)]\tLoss: 0.008512\n",
      "Train Epoch: 43 [480/2566 (19%)]\tLoss: 0.001238\n",
      "Train Epoch: 43 [520/2566 (20%)]\tLoss: 0.004348\n",
      "Train Epoch: 43 [560/2566 (22%)]\tLoss: 0.018565\n",
      "Train Epoch: 43 [600/2566 (23%)]\tLoss: 0.375036\n",
      "Train Epoch: 43 [640/2566 (25%)]\tLoss: 0.008095\n",
      "Train Epoch: 43 [680/2566 (26%)]\tLoss: 0.010091\n",
      "Train Epoch: 43 [720/2566 (28%)]\tLoss: 0.008935\n",
      "Train Epoch: 43 [760/2566 (30%)]\tLoss: 0.285133\n",
      "Train Epoch: 43 [800/2566 (31%)]\tLoss: 0.024578\n",
      "Train Epoch: 43 [840/2566 (33%)]\tLoss: 0.035908\n",
      "Train Epoch: 43 [880/2566 (34%)]\tLoss: 0.005484\n",
      "Train Epoch: 43 [920/2566 (36%)]\tLoss: 0.623291\n",
      "Train Epoch: 43 [960/2566 (37%)]\tLoss: 0.009324\n",
      "Train Epoch: 43 [1000/2566 (39%)]\tLoss: 0.136090\n",
      "Train Epoch: 43 [1040/2566 (40%)]\tLoss: 0.335717\n",
      "Train Epoch: 43 [1080/2566 (42%)]\tLoss: 0.004010\n",
      "Train Epoch: 43 [1120/2566 (44%)]\tLoss: 0.005203\n",
      "Train Epoch: 43 [1160/2566 (45%)]\tLoss: 0.013881\n",
      "Train Epoch: 43 [1200/2566 (47%)]\tLoss: 0.012525\n",
      "Train Epoch: 43 [1240/2566 (48%)]\tLoss: 0.034247\n",
      "Train Epoch: 43 [1280/2566 (50%)]\tLoss: 0.035640\n",
      "Train Epoch: 43 [1320/2566 (51%)]\tLoss: 0.012005\n",
      "Train Epoch: 43 [1360/2566 (53%)]\tLoss: 0.129354\n",
      "Train Epoch: 43 [1400/2566 (55%)]\tLoss: 0.015385\n",
      "Train Epoch: 43 [1440/2566 (56%)]\tLoss: 0.001391\n",
      "Train Epoch: 43 [1480/2566 (58%)]\tLoss: 0.005461\n",
      "Train Epoch: 43 [1520/2566 (59%)]\tLoss: 0.029661\n",
      "Train Epoch: 43 [1560/2566 (61%)]\tLoss: 0.008802\n",
      "Train Epoch: 43 [1600/2566 (62%)]\tLoss: 0.004410\n",
      "Train Epoch: 43 [1640/2566 (64%)]\tLoss: 0.162047\n",
      "Train Epoch: 43 [1680/2566 (65%)]\tLoss: 0.010448\n",
      "Train Epoch: 43 [1720/2566 (67%)]\tLoss: 0.088125\n",
      "Train Epoch: 43 [1760/2566 (69%)]\tLoss: 0.003334\n",
      "Train Epoch: 43 [1800/2566 (70%)]\tLoss: 0.002370\n",
      "Train Epoch: 43 [1840/2566 (72%)]\tLoss: 0.008003\n",
      "Train Epoch: 43 [1880/2566 (73%)]\tLoss: 0.002165\n",
      "Train Epoch: 43 [1920/2566 (75%)]\tLoss: 0.008217\n",
      "Train Epoch: 43 [1960/2566 (76%)]\tLoss: 0.172384\n",
      "Train Epoch: 43 [2000/2566 (78%)]\tLoss: 0.001557\n",
      "Train Epoch: 43 [2040/2566 (79%)]\tLoss: 0.009128\n",
      "Train Epoch: 43 [2080/2566 (81%)]\tLoss: 0.006722\n",
      "Train Epoch: 43 [2120/2566 (83%)]\tLoss: 0.003798\n",
      "Train Epoch: 43 [2160/2566 (84%)]\tLoss: 0.002357\n",
      "Train Epoch: 43 [2200/2566 (86%)]\tLoss: 0.003385\n",
      "Train Epoch: 43 [2240/2566 (87%)]\tLoss: 0.291438\n",
      "Train Epoch: 43 [2280/2566 (89%)]\tLoss: 0.010314\n",
      "Train Epoch: 43 [2320/2566 (90%)]\tLoss: 0.005139\n",
      "Train Epoch: 43 [2360/2566 (92%)]\tLoss: 0.023358\n",
      "Train Epoch: 43 [2400/2566 (93%)]\tLoss: 0.003723\n",
      "Train Epoch: 43 [2440/2566 (95%)]\tLoss: 0.160511\n",
      "Train Epoch: 43 [2480/2566 (97%)]\tLoss: 0.013077\n",
      "Train Epoch: 43 [2520/2566 (98%)]\tLoss: 0.047793\n",
      "Train Epoch: 43 [2560/2566 (100%)]\tLoss: 0.059179\n",
      "epoch:43,loss:0.04549338745469709\n",
      "Train set: Average loss: 0.0156, Accuracy: 2548/2566 (99%)\n",
      "Val set: Average loss: 0.6867, Accuracy: 268/327 (82%)\n",
      "Train Epoch: 44 [40/2566 (2%)]\tLoss: 0.006839\n",
      "Train Epoch: 44 [80/2566 (3%)]\tLoss: 0.016237\n",
      "Train Epoch: 44 [120/2566 (5%)]\tLoss: 0.012559\n",
      "Train Epoch: 44 [160/2566 (6%)]\tLoss: 0.005035\n",
      "Train Epoch: 44 [200/2566 (8%)]\tLoss: 0.021910\n",
      "Train Epoch: 44 [240/2566 (9%)]\tLoss: 0.003210\n",
      "Train Epoch: 44 [280/2566 (11%)]\tLoss: 0.004771\n",
      "Train Epoch: 44 [320/2566 (12%)]\tLoss: 0.002456\n",
      "Train Epoch: 44 [360/2566 (14%)]\tLoss: 0.010448\n",
      "Train Epoch: 44 [400/2566 (16%)]\tLoss: 0.009882\n",
      "Train Epoch: 44 [440/2566 (17%)]\tLoss: 0.001089\n",
      "Train Epoch: 44 [480/2566 (19%)]\tLoss: 0.011152\n",
      "Train Epoch: 44 [520/2566 (20%)]\tLoss: 0.041366\n",
      "Train Epoch: 44 [560/2566 (22%)]\tLoss: 0.001271\n",
      "Train Epoch: 44 [600/2566 (23%)]\tLoss: 0.006236\n",
      "Train Epoch: 44 [640/2566 (25%)]\tLoss: 0.017192\n",
      "Train Epoch: 44 [680/2566 (26%)]\tLoss: 0.015829\n",
      "Train Epoch: 44 [720/2566 (28%)]\tLoss: 0.004492\n",
      "Train Epoch: 44 [760/2566 (30%)]\tLoss: 0.004808\n",
      "Train Epoch: 44 [800/2566 (31%)]\tLoss: 0.007300\n",
      "Train Epoch: 44 [840/2566 (33%)]\tLoss: 0.006059\n",
      "Train Epoch: 44 [880/2566 (34%)]\tLoss: 0.002181\n",
      "Train Epoch: 44 [920/2566 (36%)]\tLoss: 0.004121\n",
      "Train Epoch: 44 [960/2566 (37%)]\tLoss: 0.004274\n",
      "Train Epoch: 44 [1000/2566 (39%)]\tLoss: 0.004320\n",
      "Train Epoch: 44 [1040/2566 (40%)]\tLoss: 0.004034\n",
      "Train Epoch: 44 [1080/2566 (42%)]\tLoss: 0.010171\n",
      "Train Epoch: 44 [1120/2566 (44%)]\tLoss: 0.013928\n",
      "Train Epoch: 44 [1160/2566 (45%)]\tLoss: 0.048025\n",
      "Train Epoch: 44 [1200/2566 (47%)]\tLoss: 0.011551\n",
      "Train Epoch: 44 [1240/2566 (48%)]\tLoss: 0.004038\n",
      "Train Epoch: 44 [1280/2566 (50%)]\tLoss: 0.002267\n",
      "Train Epoch: 44 [1320/2566 (51%)]\tLoss: 0.132779\n",
      "Train Epoch: 44 [1360/2566 (53%)]\tLoss: 0.017556\n",
      "Train Epoch: 44 [1400/2566 (55%)]\tLoss: 0.003911\n",
      "Train Epoch: 44 [1440/2566 (56%)]\tLoss: 0.004996\n",
      "Train Epoch: 44 [1480/2566 (58%)]\tLoss: 0.059527\n",
      "Train Epoch: 44 [1520/2566 (59%)]\tLoss: 0.093613\n",
      "Train Epoch: 44 [1560/2566 (61%)]\tLoss: 0.109159\n",
      "Train Epoch: 44 [1600/2566 (62%)]\tLoss: 0.061820\n",
      "Train Epoch: 44 [1640/2566 (64%)]\tLoss: 0.004794\n",
      "Train Epoch: 44 [1680/2566 (65%)]\tLoss: 0.004041\n",
      "Train Epoch: 44 [1720/2566 (67%)]\tLoss: 0.004261\n",
      "Train Epoch: 44 [1760/2566 (69%)]\tLoss: 0.033101\n",
      "Train Epoch: 44 [1800/2566 (70%)]\tLoss: 0.002719\n",
      "Train Epoch: 44 [1840/2566 (72%)]\tLoss: 0.052998\n",
      "Train Epoch: 44 [1880/2566 (73%)]\tLoss: 0.026748\n",
      "Train Epoch: 44 [1920/2566 (75%)]\tLoss: 0.005538\n",
      "Train Epoch: 44 [1960/2566 (76%)]\tLoss: 0.006554\n",
      "Train Epoch: 44 [2000/2566 (78%)]\tLoss: 0.014609\n",
      "Train Epoch: 44 [2040/2566 (79%)]\tLoss: 0.283019\n",
      "Train Epoch: 44 [2080/2566 (81%)]\tLoss: 0.001831\n",
      "Train Epoch: 44 [2120/2566 (83%)]\tLoss: 0.002101\n",
      "Train Epoch: 44 [2160/2566 (84%)]\tLoss: 0.013293\n",
      "Train Epoch: 44 [2200/2566 (86%)]\tLoss: 0.012424\n",
      "Train Epoch: 44 [2240/2566 (87%)]\tLoss: 0.012057\n",
      "Train Epoch: 44 [2280/2566 (89%)]\tLoss: 0.017438\n",
      "Train Epoch: 44 [2320/2566 (90%)]\tLoss: 0.003340\n",
      "Train Epoch: 44 [2360/2566 (92%)]\tLoss: 0.019371\n",
      "Train Epoch: 44 [2400/2566 (93%)]\tLoss: 0.129568\n",
      "Train Epoch: 44 [2440/2566 (95%)]\tLoss: 0.001993\n",
      "Train Epoch: 44 [2480/2566 (97%)]\tLoss: 0.013791\n",
      "Train Epoch: 44 [2520/2566 (98%)]\tLoss: 0.005054\n",
      "Train Epoch: 44 [2560/2566 (100%)]\tLoss: 0.021174\n",
      "epoch:44,loss:0.03812826854721541\n",
      "Train set: Average loss: 0.0161, Accuracy: 2546/2566 (99%)\n",
      "Val set: Average loss: 0.6778, Accuracy: 264/327 (81%)\n",
      "Train Epoch: 45 [40/2566 (2%)]\tLoss: 0.006185\n",
      "Train Epoch: 45 [80/2566 (3%)]\tLoss: 0.102060\n",
      "Train Epoch: 45 [120/2566 (5%)]\tLoss: 0.002553\n",
      "Train Epoch: 45 [160/2566 (6%)]\tLoss: 0.037283\n",
      "Train Epoch: 45 [200/2566 (8%)]\tLoss: 0.012835\n",
      "Train Epoch: 45 [240/2566 (9%)]\tLoss: 0.010028\n",
      "Train Epoch: 45 [280/2566 (11%)]\tLoss: 0.010655\n",
      "Train Epoch: 45 [320/2566 (12%)]\tLoss: 0.002854\n",
      "Train Epoch: 45 [360/2566 (14%)]\tLoss: 0.003906\n",
      "Train Epoch: 45 [400/2566 (16%)]\tLoss: 0.002975\n",
      "Train Epoch: 45 [440/2566 (17%)]\tLoss: 0.012137\n",
      "Train Epoch: 45 [480/2566 (19%)]\tLoss: 0.001087\n",
      "Train Epoch: 45 [520/2566 (20%)]\tLoss: 0.002477\n",
      "Train Epoch: 45 [560/2566 (22%)]\tLoss: 0.042547\n",
      "Train Epoch: 45 [600/2566 (23%)]\tLoss: 0.003628\n",
      "Train Epoch: 45 [640/2566 (25%)]\tLoss: 0.001070\n",
      "Train Epoch: 45 [680/2566 (26%)]\tLoss: 0.010248\n",
      "Train Epoch: 45 [720/2566 (28%)]\tLoss: 0.005940\n",
      "Train Epoch: 45 [760/2566 (30%)]\tLoss: 0.019219\n",
      "Train Epoch: 45 [800/2566 (31%)]\tLoss: 0.008037\n",
      "Train Epoch: 45 [840/2566 (33%)]\tLoss: 0.003226\n",
      "Train Epoch: 45 [880/2566 (34%)]\tLoss: 0.005003\n",
      "Train Epoch: 45 [920/2566 (36%)]\tLoss: 0.001964\n",
      "Train Epoch: 45 [960/2566 (37%)]\tLoss: 0.003466\n",
      "Train Epoch: 45 [1000/2566 (39%)]\tLoss: 0.011889\n",
      "Train Epoch: 45 [1040/2566 (40%)]\tLoss: 0.003093\n",
      "Train Epoch: 45 [1080/2566 (42%)]\tLoss: 0.014514\n",
      "Train Epoch: 45 [1120/2566 (44%)]\tLoss: 0.003669\n",
      "Train Epoch: 45 [1160/2566 (45%)]\tLoss: 0.001157\n",
      "Train Epoch: 45 [1200/2566 (47%)]\tLoss: 0.034279\n",
      "Train Epoch: 45 [1240/2566 (48%)]\tLoss: 0.019235\n",
      "Train Epoch: 45 [1280/2566 (50%)]\tLoss: 0.005706\n",
      "Train Epoch: 45 [1320/2566 (51%)]\tLoss: 0.356811\n",
      "Train Epoch: 45 [1360/2566 (53%)]\tLoss: 0.002722\n",
      "Train Epoch: 45 [1400/2566 (55%)]\tLoss: 0.004526\n",
      "Train Epoch: 45 [1440/2566 (56%)]\tLoss: 0.011743\n",
      "Train Epoch: 45 [1480/2566 (58%)]\tLoss: 0.116056\n",
      "Train Epoch: 45 [1520/2566 (59%)]\tLoss: 0.004530\n",
      "Train Epoch: 45 [1560/2566 (61%)]\tLoss: 0.003068\n",
      "Train Epoch: 45 [1600/2566 (62%)]\tLoss: 0.015728\n",
      "Train Epoch: 45 [1640/2566 (64%)]\tLoss: 0.017935\n",
      "Train Epoch: 45 [1680/2566 (65%)]\tLoss: 0.001494\n",
      "Train Epoch: 45 [1720/2566 (67%)]\tLoss: 0.004996\n",
      "Train Epoch: 45 [1760/2566 (69%)]\tLoss: 0.002547\n",
      "Train Epoch: 45 [1800/2566 (70%)]\tLoss: 0.235697\n",
      "Train Epoch: 45 [1840/2566 (72%)]\tLoss: 0.033821\n",
      "Train Epoch: 45 [1880/2566 (73%)]\tLoss: 0.022546\n",
      "Train Epoch: 45 [1920/2566 (75%)]\tLoss: 0.001805\n",
      "Train Epoch: 45 [1960/2566 (76%)]\tLoss: 0.007505\n",
      "Train Epoch: 45 [2000/2566 (78%)]\tLoss: 0.003109\n",
      "Train Epoch: 45 [2040/2566 (79%)]\tLoss: 0.004273\n",
      "Train Epoch: 45 [2080/2566 (81%)]\tLoss: 0.002983\n",
      "Train Epoch: 45 [2120/2566 (83%)]\tLoss: 0.001588\n",
      "Train Epoch: 45 [2160/2566 (84%)]\tLoss: 0.104227\n",
      "Train Epoch: 45 [2200/2566 (86%)]\tLoss: 0.007000\n",
      "Train Epoch: 45 [2240/2566 (87%)]\tLoss: 0.003832\n",
      "Train Epoch: 45 [2280/2566 (89%)]\tLoss: 0.004371\n",
      "Train Epoch: 45 [2320/2566 (90%)]\tLoss: 0.001658\n",
      "Train Epoch: 45 [2360/2566 (92%)]\tLoss: 0.003242\n",
      "Train Epoch: 45 [2400/2566 (93%)]\tLoss: 0.011045\n",
      "Train Epoch: 45 [2440/2566 (95%)]\tLoss: 0.027094\n",
      "Train Epoch: 45 [2480/2566 (97%)]\tLoss: 0.004625\n",
      "Train Epoch: 45 [2520/2566 (98%)]\tLoss: 0.001634\n",
      "Train Epoch: 45 [2560/2566 (100%)]\tLoss: 0.001076\n",
      "epoch:45,loss:0.03827167303041001\n",
      "Train set: Average loss: 0.0188, Accuracy: 2543/2566 (99%)\n",
      "Val set: Average loss: 0.6625, Accuracy: 265/327 (81%)\n",
      "Train Epoch: 46 [40/2566 (2%)]\tLoss: 0.093796\n",
      "Train Epoch: 46 [80/2566 (3%)]\tLoss: 0.002567\n",
      "Train Epoch: 46 [120/2566 (5%)]\tLoss: 0.003441\n",
      "Train Epoch: 46 [160/2566 (6%)]\tLoss: 0.631889\n",
      "Train Epoch: 46 [200/2566 (8%)]\tLoss: 0.005757\n",
      "Train Epoch: 46 [240/2566 (9%)]\tLoss: 0.001950\n",
      "Train Epoch: 46 [280/2566 (11%)]\tLoss: 0.064847\n",
      "Train Epoch: 46 [320/2566 (12%)]\tLoss: 0.175145\n",
      "Train Epoch: 46 [360/2566 (14%)]\tLoss: 0.004349\n",
      "Train Epoch: 46 [400/2566 (16%)]\tLoss: 0.020714\n",
      "Train Epoch: 46 [440/2566 (17%)]\tLoss: 0.012700\n",
      "Train Epoch: 46 [480/2566 (19%)]\tLoss: 0.312801\n",
      "Train Epoch: 46 [520/2566 (20%)]\tLoss: 0.002359\n",
      "Train Epoch: 46 [560/2566 (22%)]\tLoss: 0.011659\n",
      "Train Epoch: 46 [600/2566 (23%)]\tLoss: 0.004352\n",
      "Train Epoch: 46 [640/2566 (25%)]\tLoss: 0.002310\n",
      "Train Epoch: 46 [680/2566 (26%)]\tLoss: 0.005969\n",
      "Train Epoch: 46 [720/2566 (28%)]\tLoss: 0.007873\n",
      "Train Epoch: 46 [760/2566 (30%)]\tLoss: 0.004080\n",
      "Train Epoch: 46 [800/2566 (31%)]\tLoss: 0.002076\n",
      "Train Epoch: 46 [840/2566 (33%)]\tLoss: 0.006765\n",
      "Train Epoch: 46 [880/2566 (34%)]\tLoss: 0.034469\n",
      "Train Epoch: 46 [920/2566 (36%)]\tLoss: 0.014482\n",
      "Train Epoch: 46 [960/2566 (37%)]\tLoss: 0.011224\n",
      "Train Epoch: 46 [1000/2566 (39%)]\tLoss: 0.002735\n",
      "Train Epoch: 46 [1040/2566 (40%)]\tLoss: 0.017325\n",
      "Train Epoch: 46 [1080/2566 (42%)]\tLoss: 0.009480\n",
      "Train Epoch: 46 [1120/2566 (44%)]\tLoss: 0.210457\n",
      "Train Epoch: 46 [1160/2566 (45%)]\tLoss: 0.003988\n",
      "Train Epoch: 46 [1200/2566 (47%)]\tLoss: 0.012500\n",
      "Train Epoch: 46 [1240/2566 (48%)]\tLoss: 0.019423\n",
      "Train Epoch: 46 [1280/2566 (50%)]\tLoss: 0.003499\n",
      "Train Epoch: 46 [1320/2566 (51%)]\tLoss: 0.001870\n",
      "Train Epoch: 46 [1360/2566 (53%)]\tLoss: 0.017839\n",
      "Train Epoch: 46 [1400/2566 (55%)]\tLoss: 0.004058\n",
      "Train Epoch: 46 [1440/2566 (56%)]\tLoss: 0.019073\n",
      "Train Epoch: 46 [1480/2566 (58%)]\tLoss: 0.008942\n",
      "Train Epoch: 46 [1520/2566 (59%)]\tLoss: 0.001397\n",
      "Train Epoch: 46 [1560/2566 (61%)]\tLoss: 0.116890\n",
      "Train Epoch: 46 [1600/2566 (62%)]\tLoss: 0.159637\n",
      "Train Epoch: 46 [1640/2566 (64%)]\tLoss: 0.425478\n",
      "Train Epoch: 46 [1680/2566 (65%)]\tLoss: 0.013863\n",
      "Train Epoch: 46 [1720/2566 (67%)]\tLoss: 0.002589\n",
      "Train Epoch: 46 [1760/2566 (69%)]\tLoss: 0.040928\n",
      "Train Epoch: 46 [1800/2566 (70%)]\tLoss: 0.008468\n",
      "Train Epoch: 46 [1840/2566 (72%)]\tLoss: 0.043604\n",
      "Train Epoch: 46 [1880/2566 (73%)]\tLoss: 0.004638\n",
      "Train Epoch: 46 [1920/2566 (75%)]\tLoss: 0.021073\n",
      "Train Epoch: 46 [1960/2566 (76%)]\tLoss: 0.005440\n",
      "Train Epoch: 46 [2000/2566 (78%)]\tLoss: 0.246794\n",
      "Train Epoch: 46 [2040/2566 (79%)]\tLoss: 0.003180\n",
      "Train Epoch: 46 [2080/2566 (81%)]\tLoss: 0.018344\n",
      "Train Epoch: 46 [2120/2566 (83%)]\tLoss: 0.280250\n",
      "Train Epoch: 46 [2160/2566 (84%)]\tLoss: 0.003996\n",
      "Train Epoch: 46 [2200/2566 (86%)]\tLoss: 0.005589\n",
      "Train Epoch: 46 [2240/2566 (87%)]\tLoss: 0.009195\n",
      "Train Epoch: 46 [2280/2566 (89%)]\tLoss: 0.001900\n",
      "Train Epoch: 46 [2320/2566 (90%)]\tLoss: 0.269936\n",
      "Train Epoch: 46 [2360/2566 (92%)]\tLoss: 0.003770\n",
      "Train Epoch: 46 [2400/2566 (93%)]\tLoss: 0.009941\n",
      "Train Epoch: 46 [2440/2566 (95%)]\tLoss: 0.009453\n",
      "Train Epoch: 46 [2480/2566 (97%)]\tLoss: 0.002686\n",
      "Train Epoch: 46 [2520/2566 (98%)]\tLoss: 0.006544\n",
      "Train Epoch: 46 [2560/2566 (100%)]\tLoss: 0.009272\n",
      "epoch:46,loss:0.043684709673102604\n",
      "Train set: Average loss: 0.0166, Accuracy: 2543/2566 (99%)\n",
      "Val set: Average loss: 0.6727, Accuracy: 272/327 (83%)\n",
      "Train Epoch: 47 [40/2566 (2%)]\tLoss: 0.013424\n",
      "Train Epoch: 47 [80/2566 (3%)]\tLoss: 0.002522\n",
      "Train Epoch: 47 [120/2566 (5%)]\tLoss: 0.003855\n",
      "Train Epoch: 47 [160/2566 (6%)]\tLoss: 0.001180\n",
      "Train Epoch: 47 [200/2566 (8%)]\tLoss: 0.006851\n",
      "Train Epoch: 47 [240/2566 (9%)]\tLoss: 0.002963\n",
      "Train Epoch: 47 [280/2566 (11%)]\tLoss: 0.071643\n",
      "Train Epoch: 47 [320/2566 (12%)]\tLoss: 0.041766\n",
      "Train Epoch: 47 [360/2566 (14%)]\tLoss: 0.063324\n",
      "Train Epoch: 47 [400/2566 (16%)]\tLoss: 0.012214\n",
      "Train Epoch: 47 [440/2566 (17%)]\tLoss: 0.006998\n",
      "Train Epoch: 47 [480/2566 (19%)]\tLoss: 0.103351\n",
      "Train Epoch: 47 [520/2566 (20%)]\tLoss: 0.017994\n",
      "Train Epoch: 47 [560/2566 (22%)]\tLoss: 0.027237\n",
      "Train Epoch: 47 [600/2566 (23%)]\tLoss: 0.004570\n",
      "Train Epoch: 47 [640/2566 (25%)]\tLoss: 0.005599\n",
      "Train Epoch: 47 [680/2566 (26%)]\tLoss: 0.147286\n",
      "Train Epoch: 47 [720/2566 (28%)]\tLoss: 0.075378\n",
      "Train Epoch: 47 [760/2566 (30%)]\tLoss: 0.006483\n",
      "Train Epoch: 47 [800/2566 (31%)]\tLoss: 0.001148\n",
      "Train Epoch: 47 [840/2566 (33%)]\tLoss: 0.210192\n",
      "Train Epoch: 47 [880/2566 (34%)]\tLoss: 0.289798\n",
      "Train Epoch: 47 [920/2566 (36%)]\tLoss: 0.172405\n",
      "Train Epoch: 47 [960/2566 (37%)]\tLoss: 0.001746\n",
      "Train Epoch: 47 [1000/2566 (39%)]\tLoss: 0.005931\n",
      "Train Epoch: 47 [1040/2566 (40%)]\tLoss: 0.024184\n",
      "Train Epoch: 47 [1080/2566 (42%)]\tLoss: 0.007027\n",
      "Train Epoch: 47 [1120/2566 (44%)]\tLoss: 0.038175\n",
      "Train Epoch: 47 [1160/2566 (45%)]\tLoss: 0.003134\n",
      "Train Epoch: 47 [1200/2566 (47%)]\tLoss: 0.004187\n",
      "Train Epoch: 47 [1240/2566 (48%)]\tLoss: 0.019797\n",
      "Train Epoch: 47 [1280/2566 (50%)]\tLoss: 0.002727\n",
      "Train Epoch: 47 [1320/2566 (51%)]\tLoss: 0.002443\n",
      "Train Epoch: 47 [1360/2566 (53%)]\tLoss: 0.001300\n",
      "Train Epoch: 47 [1400/2566 (55%)]\tLoss: 0.000547\n",
      "Train Epoch: 47 [1440/2566 (56%)]\tLoss: 0.103041\n",
      "Train Epoch: 47 [1480/2566 (58%)]\tLoss: 0.004591\n",
      "Train Epoch: 47 [1520/2566 (59%)]\tLoss: 0.005384\n",
      "Train Epoch: 47 [1560/2566 (61%)]\tLoss: 0.004968\n",
      "Train Epoch: 47 [1600/2566 (62%)]\tLoss: 0.001566\n",
      "Train Epoch: 47 [1640/2566 (64%)]\tLoss: 0.004907\n",
      "Train Epoch: 47 [1680/2566 (65%)]\tLoss: 0.003961\n",
      "Train Epoch: 47 [1720/2566 (67%)]\tLoss: 0.001677\n",
      "Train Epoch: 47 [1760/2566 (69%)]\tLoss: 0.006177\n",
      "Train Epoch: 47 [1800/2566 (70%)]\tLoss: 0.002213\n",
      "Train Epoch: 47 [1840/2566 (72%)]\tLoss: 0.004863\n",
      "Train Epoch: 47 [1880/2566 (73%)]\tLoss: 0.055848\n",
      "Train Epoch: 47 [1920/2566 (75%)]\tLoss: 0.012128\n",
      "Train Epoch: 47 [1960/2566 (76%)]\tLoss: 0.040284\n",
      "Train Epoch: 47 [2000/2566 (78%)]\tLoss: 0.029173\n",
      "Train Epoch: 47 [2040/2566 (79%)]\tLoss: 0.005689\n",
      "Train Epoch: 47 [2080/2566 (81%)]\tLoss: 0.051329\n",
      "Train Epoch: 47 [2120/2566 (83%)]\tLoss: 0.002637\n",
      "Train Epoch: 47 [2160/2566 (84%)]\tLoss: 0.116699\n",
      "Train Epoch: 47 [2200/2566 (86%)]\tLoss: 0.005345\n",
      "Train Epoch: 47 [2240/2566 (87%)]\tLoss: 0.011160\n",
      "Train Epoch: 47 [2280/2566 (89%)]\tLoss: 0.006744\n",
      "Train Epoch: 47 [2320/2566 (90%)]\tLoss: 0.004480\n",
      "Train Epoch: 47 [2360/2566 (92%)]\tLoss: 0.064502\n",
      "Train Epoch: 47 [2400/2566 (93%)]\tLoss: 0.000919\n",
      "Train Epoch: 47 [2440/2566 (95%)]\tLoss: 0.152888\n",
      "Train Epoch: 47 [2480/2566 (97%)]\tLoss: 0.002662\n",
      "Train Epoch: 47 [2520/2566 (98%)]\tLoss: 0.040776\n",
      "Train Epoch: 47 [2560/2566 (100%)]\tLoss: 0.006294\n",
      "epoch:47,loss:0.037250047666927355\n",
      "Train set: Average loss: 0.0152, Accuracy: 2547/2566 (99%)\n",
      "Val set: Average loss: 0.6520, Accuracy: 267/327 (82%)\n",
      "Train Epoch: 48 [40/2566 (2%)]\tLoss: 0.004608\n",
      "Train Epoch: 48 [80/2566 (3%)]\tLoss: 0.002525\n",
      "Train Epoch: 48 [120/2566 (5%)]\tLoss: 0.012011\n",
      "Train Epoch: 48 [160/2566 (6%)]\tLoss: 0.185052\n",
      "Train Epoch: 48 [200/2566 (8%)]\tLoss: 0.025208\n",
      "Train Epoch: 48 [240/2566 (9%)]\tLoss: 0.041131\n",
      "Train Epoch: 48 [280/2566 (11%)]\tLoss: 0.003649\n",
      "Train Epoch: 48 [320/2566 (12%)]\tLoss: 0.027580\n",
      "Train Epoch: 48 [360/2566 (14%)]\tLoss: 0.044445\n",
      "Train Epoch: 48 [400/2566 (16%)]\tLoss: 0.008752\n",
      "Train Epoch: 48 [440/2566 (17%)]\tLoss: 0.001897\n",
      "Train Epoch: 48 [480/2566 (19%)]\tLoss: 0.006275\n",
      "Train Epoch: 48 [520/2566 (20%)]\tLoss: 0.019104\n",
      "Train Epoch: 48 [560/2566 (22%)]\tLoss: 0.011004\n",
      "Train Epoch: 48 [600/2566 (23%)]\tLoss: 0.013564\n",
      "Train Epoch: 48 [640/2566 (25%)]\tLoss: 0.006651\n",
      "Train Epoch: 48 [680/2566 (26%)]\tLoss: 0.004382\n",
      "Train Epoch: 48 [720/2566 (28%)]\tLoss: 0.000985\n",
      "Train Epoch: 48 [760/2566 (30%)]\tLoss: 0.003390\n",
      "Train Epoch: 48 [800/2566 (31%)]\tLoss: 0.110957\n",
      "Train Epoch: 48 [840/2566 (33%)]\tLoss: 0.002606\n",
      "Train Epoch: 48 [880/2566 (34%)]\tLoss: 0.007298\n",
      "Train Epoch: 48 [920/2566 (36%)]\tLoss: 0.010197\n",
      "Train Epoch: 48 [960/2566 (37%)]\tLoss: 0.010344\n",
      "Train Epoch: 48 [1000/2566 (39%)]\tLoss: 0.004811\n",
      "Train Epoch: 48 [1040/2566 (40%)]\tLoss: 0.004495\n",
      "Train Epoch: 48 [1080/2566 (42%)]\tLoss: 0.003646\n",
      "Train Epoch: 48 [1120/2566 (44%)]\tLoss: 0.018626\n",
      "Train Epoch: 48 [1160/2566 (45%)]\tLoss: 0.010161\n",
      "Train Epoch: 48 [1200/2566 (47%)]\tLoss: 0.006921\n",
      "Train Epoch: 48 [1240/2566 (48%)]\tLoss: 0.002883\n",
      "Train Epoch: 48 [1280/2566 (50%)]\tLoss: 0.004979\n",
      "Train Epoch: 48 [1320/2566 (51%)]\tLoss: 0.003634\n",
      "Train Epoch: 48 [1360/2566 (53%)]\tLoss: 0.002191\n",
      "Train Epoch: 48 [1400/2566 (55%)]\tLoss: 0.007671\n",
      "Train Epoch: 48 [1440/2566 (56%)]\tLoss: 0.030915\n",
      "Train Epoch: 48 [1480/2566 (58%)]\tLoss: 0.011896\n",
      "Train Epoch: 48 [1520/2566 (59%)]\tLoss: 0.002716\n",
      "Train Epoch: 48 [1560/2566 (61%)]\tLoss: 0.032269\n",
      "Train Epoch: 48 [1600/2566 (62%)]\tLoss: 0.095583\n",
      "Train Epoch: 48 [1640/2566 (64%)]\tLoss: 0.016501\n",
      "Train Epoch: 48 [1680/2566 (65%)]\tLoss: 0.466774\n",
      "Train Epoch: 48 [1720/2566 (67%)]\tLoss: 0.003141\n",
      "Train Epoch: 48 [1760/2566 (69%)]\tLoss: 0.044610\n",
      "Train Epoch: 48 [1800/2566 (70%)]\tLoss: 0.004417\n",
      "Train Epoch: 48 [1840/2566 (72%)]\tLoss: 0.169727\n",
      "Train Epoch: 48 [1880/2566 (73%)]\tLoss: 0.034037\n",
      "Train Epoch: 48 [1920/2566 (75%)]\tLoss: 0.018518\n",
      "Train Epoch: 48 [1960/2566 (76%)]\tLoss: 0.060426\n",
      "Train Epoch: 48 [2000/2566 (78%)]\tLoss: 0.003096\n",
      "Train Epoch: 48 [2040/2566 (79%)]\tLoss: 0.001361\n",
      "Train Epoch: 48 [2080/2566 (81%)]\tLoss: 0.055512\n",
      "Train Epoch: 48 [2120/2566 (83%)]\tLoss: 0.001721\n",
      "Train Epoch: 48 [2160/2566 (84%)]\tLoss: 0.002827\n",
      "Train Epoch: 48 [2200/2566 (86%)]\tLoss: 0.005000\n",
      "Train Epoch: 48 [2240/2566 (87%)]\tLoss: 0.003856\n",
      "Train Epoch: 48 [2280/2566 (89%)]\tLoss: 0.021780\n",
      "Train Epoch: 48 [2320/2566 (90%)]\tLoss: 0.153940\n",
      "Train Epoch: 48 [2360/2566 (92%)]\tLoss: 0.000917\n",
      "Train Epoch: 48 [2400/2566 (93%)]\tLoss: 0.003920\n",
      "Train Epoch: 48 [2440/2566 (95%)]\tLoss: 0.002358\n",
      "Train Epoch: 48 [2480/2566 (97%)]\tLoss: 0.475030\n",
      "Train Epoch: 48 [2520/2566 (98%)]\tLoss: 0.126434\n",
      "Train Epoch: 48 [2560/2566 (100%)]\tLoss: 0.010883\n",
      "epoch:48,loss:0.03772764225911807\n",
      "Train set: Average loss: 0.0178, Accuracy: 2540/2566 (99%)\n",
      "Val set: Average loss: 0.6729, Accuracy: 264/327 (81%)\n",
      "Train Epoch: 49 [40/2566 (2%)]\tLoss: 0.027840\n",
      "Train Epoch: 49 [80/2566 (3%)]\tLoss: 0.013452\n",
      "Train Epoch: 49 [120/2566 (5%)]\tLoss: 0.007031\n",
      "Train Epoch: 49 [160/2566 (6%)]\tLoss: 0.003718\n",
      "Train Epoch: 49 [200/2566 (8%)]\tLoss: 0.002860\n",
      "Train Epoch: 49 [240/2566 (9%)]\tLoss: 0.000651\n",
      "Train Epoch: 49 [280/2566 (11%)]\tLoss: 0.066493\n",
      "Train Epoch: 49 [320/2566 (12%)]\tLoss: 0.016131\n",
      "Train Epoch: 49 [360/2566 (14%)]\tLoss: 0.085101\n",
      "Train Epoch: 49 [400/2566 (16%)]\tLoss: 0.000936\n",
      "Train Epoch: 49 [440/2566 (17%)]\tLoss: 0.003831\n",
      "Train Epoch: 49 [480/2566 (19%)]\tLoss: 0.003982\n",
      "Train Epoch: 49 [520/2566 (20%)]\tLoss: 0.005853\n",
      "Train Epoch: 49 [560/2566 (22%)]\tLoss: 0.002205\n",
      "Train Epoch: 49 [600/2566 (23%)]\tLoss: 0.031849\n",
      "Train Epoch: 49 [640/2566 (25%)]\tLoss: 0.002262\n",
      "Train Epoch: 49 [680/2566 (26%)]\tLoss: 0.006927\n",
      "Train Epoch: 49 [720/2566 (28%)]\tLoss: 0.021984\n",
      "Train Epoch: 49 [760/2566 (30%)]\tLoss: 0.001480\n",
      "Train Epoch: 49 [800/2566 (31%)]\tLoss: 0.339454\n",
      "Train Epoch: 49 [840/2566 (33%)]\tLoss: 0.066266\n",
      "Train Epoch: 49 [880/2566 (34%)]\tLoss: 0.075057\n",
      "Train Epoch: 49 [920/2566 (36%)]\tLoss: 0.002716\n",
      "Train Epoch: 49 [960/2566 (37%)]\tLoss: 0.005721\n",
      "Train Epoch: 49 [1000/2566 (39%)]\tLoss: 0.054458\n",
      "Train Epoch: 49 [1040/2566 (40%)]\tLoss: 0.004073\n",
      "Train Epoch: 49 [1080/2566 (42%)]\tLoss: 0.006030\n",
      "Train Epoch: 49 [1120/2566 (44%)]\tLoss: 0.244029\n",
      "Train Epoch: 49 [1160/2566 (45%)]\tLoss: 0.070669\n",
      "Train Epoch: 49 [1200/2566 (47%)]\tLoss: 0.011682\n",
      "Train Epoch: 49 [1240/2566 (48%)]\tLoss: 0.031279\n",
      "Train Epoch: 49 [1280/2566 (50%)]\tLoss: 0.264386\n",
      "Train Epoch: 49 [1320/2566 (51%)]\tLoss: 0.016169\n",
      "Train Epoch: 49 [1360/2566 (53%)]\tLoss: 0.005418\n",
      "Train Epoch: 49 [1400/2566 (55%)]\tLoss: 0.015280\n",
      "Train Epoch: 49 [1440/2566 (56%)]\tLoss: 0.003791\n",
      "Train Epoch: 49 [1480/2566 (58%)]\tLoss: 0.006315\n",
      "Train Epoch: 49 [1520/2566 (59%)]\tLoss: 0.015325\n",
      "Train Epoch: 49 [1560/2566 (61%)]\tLoss: 0.015507\n",
      "Train Epoch: 49 [1600/2566 (62%)]\tLoss: 0.011856\n",
      "Train Epoch: 49 [1640/2566 (64%)]\tLoss: 0.005244\n",
      "Train Epoch: 49 [1680/2566 (65%)]\tLoss: 0.003469\n",
      "Train Epoch: 49 [1720/2566 (67%)]\tLoss: 0.011458\n",
      "Train Epoch: 49 [1760/2566 (69%)]\tLoss: 0.029791\n",
      "Train Epoch: 49 [1800/2566 (70%)]\tLoss: 0.008772\n",
      "Train Epoch: 49 [1840/2566 (72%)]\tLoss: 0.003286\n",
      "Train Epoch: 49 [1880/2566 (73%)]\tLoss: 0.006799\n",
      "Train Epoch: 49 [1920/2566 (75%)]\tLoss: 0.237176\n",
      "Train Epoch: 49 [1960/2566 (76%)]\tLoss: 0.201044\n",
      "Train Epoch: 49 [2000/2566 (78%)]\tLoss: 0.002029\n",
      "Train Epoch: 49 [2040/2566 (79%)]\tLoss: 0.006201\n",
      "Train Epoch: 49 [2080/2566 (81%)]\tLoss: 0.002694\n",
      "Train Epoch: 49 [2120/2566 (83%)]\tLoss: 0.008084\n",
      "Train Epoch: 49 [2160/2566 (84%)]\tLoss: 0.021242\n",
      "Train Epoch: 49 [2200/2566 (86%)]\tLoss: 0.003720\n",
      "Train Epoch: 49 [2240/2566 (87%)]\tLoss: 0.189532\n",
      "Train Epoch: 49 [2280/2566 (89%)]\tLoss: 0.004927\n",
      "Train Epoch: 49 [2320/2566 (90%)]\tLoss: 0.018689\n",
      "Train Epoch: 49 [2360/2566 (92%)]\tLoss: 0.013785\n",
      "Train Epoch: 49 [2400/2566 (93%)]\tLoss: 0.003713\n",
      "Train Epoch: 49 [2440/2566 (95%)]\tLoss: 0.007425\n",
      "Train Epoch: 49 [2480/2566 (97%)]\tLoss: 0.003219\n",
      "Train Epoch: 49 [2520/2566 (98%)]\tLoss: 0.003941\n",
      "Train Epoch: 49 [2560/2566 (100%)]\tLoss: 0.017360\n",
      "epoch:49,loss:0.03266031498715392\n",
      "Train set: Average loss: 0.0138, Accuracy: 2549/2566 (99%)\n",
      "Val set: Average loss: 0.7075, Accuracy: 268/327 (82%)\n",
      "Train Epoch: 50 [40/2566 (2%)]\tLoss: 0.011632\n",
      "Train Epoch: 50 [80/2566 (3%)]\tLoss: 0.010205\n",
      "Train Epoch: 50 [120/2566 (5%)]\tLoss: 0.003496\n",
      "Train Epoch: 50 [160/2566 (6%)]\tLoss: 0.001344\n",
      "Train Epoch: 50 [200/2566 (8%)]\tLoss: 0.005273\n",
      "Train Epoch: 50 [240/2566 (9%)]\tLoss: 0.002798\n",
      "Train Epoch: 50 [280/2566 (11%)]\tLoss: 0.004492\n",
      "Train Epoch: 50 [320/2566 (12%)]\tLoss: 0.001987\n",
      "Train Epoch: 50 [360/2566 (14%)]\tLoss: 0.014913\n",
      "Train Epoch: 50 [400/2566 (16%)]\tLoss: 0.001169\n",
      "Train Epoch: 50 [440/2566 (17%)]\tLoss: 0.059375\n",
      "Train Epoch: 50 [480/2566 (19%)]\tLoss: 0.028792\n",
      "Train Epoch: 50 [520/2566 (20%)]\tLoss: 0.080026\n",
      "Train Epoch: 50 [560/2566 (22%)]\tLoss: 0.000973\n",
      "Train Epoch: 50 [600/2566 (23%)]\tLoss: 0.014356\n",
      "Train Epoch: 50 [640/2566 (25%)]\tLoss: 0.022285\n",
      "Train Epoch: 50 [680/2566 (26%)]\tLoss: 0.002610\n",
      "Train Epoch: 50 [720/2566 (28%)]\tLoss: 0.014808\n",
      "Train Epoch: 50 [760/2566 (30%)]\tLoss: 0.005065\n",
      "Train Epoch: 50 [800/2566 (31%)]\tLoss: 0.197554\n",
      "Train Epoch: 50 [840/2566 (33%)]\tLoss: 0.033865\n",
      "Train Epoch: 50 [880/2566 (34%)]\tLoss: 0.009106\n",
      "Train Epoch: 50 [920/2566 (36%)]\tLoss: 0.007716\n",
      "Train Epoch: 50 [960/2566 (37%)]\tLoss: 0.002846\n",
      "Train Epoch: 50 [1000/2566 (39%)]\tLoss: 0.000632\n",
      "Train Epoch: 50 [1040/2566 (40%)]\tLoss: 0.092279\n",
      "Train Epoch: 50 [1080/2566 (42%)]\tLoss: 0.004831\n",
      "Train Epoch: 50 [1120/2566 (44%)]\tLoss: 0.090787\n",
      "Train Epoch: 50 [1160/2566 (45%)]\tLoss: 0.124299\n",
      "Train Epoch: 50 [1200/2566 (47%)]\tLoss: 0.001104\n",
      "Train Epoch: 50 [1240/2566 (48%)]\tLoss: 0.422359\n",
      "Train Epoch: 50 [1280/2566 (50%)]\tLoss: 0.003917\n",
      "Train Epoch: 50 [1320/2566 (51%)]\tLoss: 0.035611\n",
      "Train Epoch: 50 [1360/2566 (53%)]\tLoss: 0.000450\n",
      "Train Epoch: 50 [1400/2566 (55%)]\tLoss: 0.002433\n",
      "Train Epoch: 50 [1440/2566 (56%)]\tLoss: 0.005042\n",
      "Train Epoch: 50 [1480/2566 (58%)]\tLoss: 0.003214\n",
      "Train Epoch: 50 [1520/2566 (59%)]\tLoss: 0.001228\n",
      "Train Epoch: 50 [1560/2566 (61%)]\tLoss: 0.006467\n",
      "Train Epoch: 50 [1600/2566 (62%)]\tLoss: 0.032653\n",
      "Train Epoch: 50 [1640/2566 (64%)]\tLoss: 0.015661\n",
      "Train Epoch: 50 [1680/2566 (65%)]\tLoss: 0.021022\n",
      "Train Epoch: 50 [1720/2566 (67%)]\tLoss: 0.549782\n",
      "Train Epoch: 50 [1760/2566 (69%)]\tLoss: 0.017031\n",
      "Train Epoch: 50 [1800/2566 (70%)]\tLoss: 0.015348\n",
      "Train Epoch: 50 [1840/2566 (72%)]\tLoss: 0.003407\n",
      "Train Epoch: 50 [1880/2566 (73%)]\tLoss: 0.004922\n",
      "Train Epoch: 50 [1920/2566 (75%)]\tLoss: 0.004460\n",
      "Train Epoch: 50 [1960/2566 (76%)]\tLoss: 0.036967\n",
      "Train Epoch: 50 [2000/2566 (78%)]\tLoss: 0.001885\n",
      "Train Epoch: 50 [2040/2566 (79%)]\tLoss: 0.014775\n",
      "Train Epoch: 50 [2080/2566 (81%)]\tLoss: 0.029121\n",
      "Train Epoch: 50 [2120/2566 (83%)]\tLoss: 0.004137\n",
      "Train Epoch: 50 [2160/2566 (84%)]\tLoss: 0.101990\n",
      "Train Epoch: 50 [2200/2566 (86%)]\tLoss: 0.004834\n",
      "Train Epoch: 50 [2240/2566 (87%)]\tLoss: 0.003316\n",
      "Train Epoch: 50 [2280/2566 (89%)]\tLoss: 0.001879\n",
      "Train Epoch: 50 [2320/2566 (90%)]\tLoss: 0.021139\n",
      "Train Epoch: 50 [2360/2566 (92%)]\tLoss: 0.016543\n",
      "Train Epoch: 50 [2400/2566 (93%)]\tLoss: 0.358626\n",
      "Train Epoch: 50 [2440/2566 (95%)]\tLoss: 0.000889\n",
      "Train Epoch: 50 [2480/2566 (97%)]\tLoss: 0.003719\n",
      "Train Epoch: 50 [2520/2566 (98%)]\tLoss: 0.023425\n",
      "Train Epoch: 50 [2560/2566 (100%)]\tLoss: 0.005960\n",
      "epoch:50,loss:0.03948189681569967\n",
      "Train set: Average loss: 0.0145, Accuracy: 2543/2566 (99%)\n",
      "Val set: Average loss: 0.6523, Accuracy: 266/327 (81%)\n",
      "training_time:1354.4803323745728\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    val(model, DEVICE, train_loader, 'train')\n",
    "    val(model, DEVICE, test_loader, 'val')\n",
    "torch.save(model, 'model_last.pth')\n",
    "np.savetxt('logs.txt', logs, fmt='%s')\n",
    "end_time = time()\n",
    "print(f'training_time:{end_time-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2c2ef7-5190-4440-a58d-190576812005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'logs.txt'\n",
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "\n",
    "for line in lines:\n",
    "    if 'Val set' in line:\n",
    "        line = line.split(',')\n",
    "        val_acc.append(float(line[-1].split('(')[-1].split('%')[0]))\n",
    "        val_loss.append(float(line[0].split(':')[-1]))\n",
    "    elif 'Train set' in line:\n",
    "        line = line.split(',')\n",
    "        train_acc.append(float(line[-1].split('(')[-1].split('%')[0]))\n",
    "        train_loss.append(float(line[0].split(':')[-1]))\n",
    "        \n",
    "x = np.arange(1, len(val_acc)+1)\n",
    "\n",
    "plt.plot(x, train_acc, label='train accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.plot(x, val_acc, label='val accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.title('accuracy curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0,101)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, train_loss, label='train loss')\n",
    "plt.legend(loc='best')\n",
    "plt.plot(x, val_loss, label='val loss')\n",
    "plt.legend(loc='best')\n",
    "plt.title('loss curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78462ab5-7baa-4b8a-9950-be5e43e56288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率：0.8134556574923547\n",
      "混淆矩阵: \n",
      "[[ 18  10   4   1   0]\n",
      " [ 11  66   3   2   7]\n",
      " [  1   0 161   0   0]\n",
      " [  1   8   0  15   2]\n",
      " [  0   8   0   3   6]]\n",
      "每一类的precision、recall和f1-score: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mild\n",
      "       0.58      0.55      0.56        33\n",
      "      Moderate\n",
      "       0.72      0.74      0.73        89\n",
      "         No_DR\n",
      "       0.96      0.99      0.98       162\n",
      "Proliferate_DR\n",
      "       0.71      0.58      0.64        26\n",
      "        Severe\n",
      "       0.40      0.35      0.38        17\n",
      "\n",
      "       accuracy                           0.81       327\n",
      "      macro avg       0.67      0.64      0.66       327\n",
      "   weighted avg       0.81      0.81      0.81       327\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 测试\n",
    "with open('datasets/classes.txt', 'r') as f:\n",
    "    classesname = tuple(f.readlines())\n",
    "model = torch.load('model_last.pth', map_location=DEVICE.type)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total_num = len(test_loader.dataset)\n",
    "labels = []\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data).to(DEVICE), Variable(target).to(DEVICE)\n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        labels.append(target.view(-1))\n",
    "        preds.append(pred.view(-1))\n",
    "        correct += torch.sum(pred == target)\n",
    "    correct = correct.data.item()\n",
    "    acc = correct / total_num\n",
    "    print('Accuracy：{}'.format(acc))\n",
    "    labels = torch.cat(labels)\n",
    "    preds = torch.cat(preds)\n",
    "    if 'cuda' in DEVICE.type:\n",
    "        preds = np.array(preds.cpu())\n",
    "        labels = np.array(labels.cpu())\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "\n",
    "    print(\"confusion_matrix: \")\n",
    "    print(cm)\n",
    "    print(\"For each category:precision、recall和f1-score: \")\n",
    "    print(classification_report(labels, preds, target_names=classesname))\n",
    "\n",
    "    plt.rcParams.update({'font.size': 7})\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classesname)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d9730-1bae-4586-b5e1-5155cddd4bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
