{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65629145-cb8e-40ae-8306-e04b7414869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import some libraries\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from time import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c468349-f543-41ae-8d7d-56e7c34782c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define hyperparameters\n",
    "global logs, best_acc\n",
    "logs = []\n",
    "best_acc = 0 \n",
    "modellr = 1e-5\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 50\n",
    "number_class = 5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07437da4-eaf7-4323-aae2-0944cec0b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide training, validation, and testing sets by 70%, 15%, and 15%\n",
    "random.seed(66)\n",
    "\n",
    "def moveFile(input_path, rate, output_path):\n",
    "    pathDir = os.listdir(input_path)   #Retrieve the original path of the image\n",
    "    filenumber = len(pathDir)   #Number of original files\n",
    "    picknumber = int(filenumber * rate)  ##Take a certain number of images from the folder according to the rate ratio\n",
    "    sample = random.sample(pathDir, picknumber)  ##Randomly select sample images with a number of picknumbers\n",
    "    for file_name in sample:\n",
    "        shutil.move(input_path +'/'+ file_name, output_path + '/' + file_name)\n",
    "\n",
    "\n",
    "root = 'datasets'\n",
    "categories = os.listdir(root+'/train')\n",
    "np.savetxt(root+'/classes.txt', categories, fmt='%s')\n",
    "for m in categories:\n",
    "    #The input path is/train/0 in the root directory, and/train/1 in the root directory\n",
    "    input_path = root + '/train/' + str(m)\n",
    "    output_path1 = root + '/val/' + str(m)\n",
    "    output_path2 = root + '/test/' + str(m)\n",
    "    # Verify if the output path exists, if not, create it\n",
    "    isExists = os.path.exists(output_path1)\n",
    "    if not isExists:\n",
    "        os.makedirs(output_path1)\n",
    "        moveFile(input_path, 0.3, output_path1)\n",
    "    isExists = os.path.exists(output_path2)\n",
    "    if not isExists:\n",
    "        os.makedirs(output_path2)\n",
    "        moveFile(output_path1, 0.3, output_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d377b007-b2b3-4f73-bd19-cc53f35b86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data augmentation\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.RandomHorizontalFlip(),  ##Random horizontal flip\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1/255, 1/255, 1/255])])\n",
    "transform_val = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1/255, 1/255, 1/255])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca2a1f6-9322-44f0-91b7-3efa16dfdf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load training, validation, and test sets\n",
    "dataset_train = datasets.ImageFolder('datasets/train', transform)\n",
    "dataset_val = datasets.ImageFolder('datasets/val', transform_val)\n",
    "dataset_test = datasets.ImageFolder('datasets/test', transform_val)\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5261401f-ec6a-4460-bad2-396f33a4e3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/shufflenetv2_x1-5666bf0f80.pth\" to /root/.cache/torch/hub/checkpoints/shufflenetv2_x1-5666bf0f80.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80a4d3b7d7da4783a4ea10680699a9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/8.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#in torchvision call shufflenet_v2_x1_0 pre-train model\n",
    "model = torchvision.models.shufflenet_v2_x1_0(pretrained=True)\n",
    "#Modify the number of categories in the last classification layer\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 5)\n",
    "model.to(DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=modellr)\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    modellrnew = modellr * (0.1 ** (epoch // 50))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = modellrnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b1882c4-bb7d-46f0-86ff-85ffc14d36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    total_num = len(train_loader.dataset)\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print_loss = loss.data.item()\n",
    "        sum_loss += print_loss\n",
    "        if (batch_idx + 1) % 5 == 0:\n",
    "            log = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                (batch_idx + 1) * len(data),\n",
    "                len(train_loader.dataset),\n",
    "                100. * (batch_idx + 1) / len(train_loader), loss.item())\n",
    "            print(log)\n",
    "            logs.append(log)\n",
    "    ave_loss = sum_loss / len(train_loader)\n",
    "    log = 'epoch:{},loss:{}'.format(epoch, ave_loss)\n",
    "    print(log)\n",
    "    logs.append(log)\n",
    "\n",
    "def val(model, device, test_loader, phase):\n",
    "    global best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total_num = len(test_loader.dataset)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = Variable(data).to(device), Variable(target).to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            correct += torch.sum(pred == target)\n",
    "            print_loss = loss.data.item()\n",
    "            test_loss += print_loss\n",
    "        correct = correct.data.item()\n",
    "        acc = correct / total_num\n",
    "        avgloss = test_loss / len(test_loader)\n",
    "        if phase == 'train':\n",
    "            log = 'Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                avgloss,\n",
    "                correct,\n",
    "                len(test_loader.dataset),\n",
    "                100 * acc)\n",
    "        else:\n",
    "            log = 'Val set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "                avgloss,\n",
    "                correct,\n",
    "                len(test_loader.dataset),\n",
    "                100 * acc)\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model, 'model_best.pth')\n",
    "        print(log)\n",
    "        logs.append(log)\n",
    "        np.savetxt('logs.txt', logs, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5425ae24-1b10-4000-8c2f-8861d2ae039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [40/2566 (2%)]\tLoss: 1.607784\n",
      "Train Epoch: 1 [80/2566 (3%)]\tLoss: 1.618817\n",
      "Train Epoch: 1 [120/2566 (5%)]\tLoss: 1.613651\n",
      "Train Epoch: 1 [160/2566 (6%)]\tLoss: 1.607015\n",
      "Train Epoch: 1 [200/2566 (8%)]\tLoss: 1.617628\n",
      "Train Epoch: 1 [240/2566 (9%)]\tLoss: 1.596429\n",
      "Train Epoch: 1 [280/2566 (11%)]\tLoss: 1.609415\n",
      "Train Epoch: 1 [320/2566 (12%)]\tLoss: 1.596458\n",
      "Train Epoch: 1 [360/2566 (14%)]\tLoss: 1.595651\n",
      "Train Epoch: 1 [400/2566 (16%)]\tLoss: 1.612174\n",
      "Train Epoch: 1 [440/2566 (17%)]\tLoss: 1.599338\n",
      "Train Epoch: 1 [480/2566 (19%)]\tLoss: 1.604906\n",
      "Train Epoch: 1 [520/2566 (20%)]\tLoss: 1.611243\n",
      "Train Epoch: 1 [560/2566 (22%)]\tLoss: 1.598338\n",
      "Train Epoch: 1 [600/2566 (23%)]\tLoss: 1.607820\n",
      "Train Epoch: 1 [640/2566 (25%)]\tLoss: 1.597404\n",
      "Train Epoch: 1 [680/2566 (26%)]\tLoss: 1.607873\n",
      "Train Epoch: 1 [720/2566 (28%)]\tLoss: 1.594646\n",
      "Train Epoch: 1 [760/2566 (30%)]\tLoss: 1.594456\n",
      "Train Epoch: 1 [800/2566 (31%)]\tLoss: 1.597230\n",
      "Train Epoch: 1 [840/2566 (33%)]\tLoss: 1.597301\n",
      "Train Epoch: 1 [880/2566 (34%)]\tLoss: 1.595969\n",
      "Train Epoch: 1 [920/2566 (36%)]\tLoss: 1.594988\n",
      "Train Epoch: 1 [960/2566 (37%)]\tLoss: 1.583632\n",
      "Train Epoch: 1 [1000/2566 (39%)]\tLoss: 1.592259\n",
      "Train Epoch: 1 [1040/2566 (40%)]\tLoss: 1.583247\n",
      "Train Epoch: 1 [1080/2566 (42%)]\tLoss: 1.602417\n",
      "Train Epoch: 1 [1120/2566 (44%)]\tLoss: 1.580055\n",
      "Train Epoch: 1 [1160/2566 (45%)]\tLoss: 1.588322\n",
      "Train Epoch: 1 [1200/2566 (47%)]\tLoss: 1.595683\n",
      "Train Epoch: 1 [1240/2566 (48%)]\tLoss: 1.576077\n",
      "Train Epoch: 1 [1280/2566 (50%)]\tLoss: 1.568646\n",
      "Train Epoch: 1 [1320/2566 (51%)]\tLoss: 1.581068\n",
      "Train Epoch: 1 [1360/2566 (53%)]\tLoss: 1.592776\n",
      "Train Epoch: 1 [1400/2566 (55%)]\tLoss: 1.592004\n",
      "Train Epoch: 1 [1440/2566 (56%)]\tLoss: 1.579197\n",
      "Train Epoch: 1 [1480/2566 (58%)]\tLoss: 1.558994\n",
      "Train Epoch: 1 [1520/2566 (59%)]\tLoss: 1.593420\n",
      "Train Epoch: 1 [1560/2566 (61%)]\tLoss: 1.586529\n",
      "Train Epoch: 1 [1600/2566 (62%)]\tLoss: 1.586643\n",
      "Train Epoch: 1 [1640/2566 (64%)]\tLoss: 1.569238\n",
      "Train Epoch: 1 [1680/2566 (65%)]\tLoss: 1.553652\n",
      "Train Epoch: 1 [1720/2566 (67%)]\tLoss: 1.572278\n",
      "Train Epoch: 1 [1760/2566 (69%)]\tLoss: 1.581792\n",
      "Train Epoch: 1 [1800/2566 (70%)]\tLoss: 1.555292\n",
      "Train Epoch: 1 [1840/2566 (72%)]\tLoss: 1.555893\n",
      "Train Epoch: 1 [1880/2566 (73%)]\tLoss: 1.600368\n",
      "Train Epoch: 1 [1920/2566 (75%)]\tLoss: 1.573584\n",
      "Train Epoch: 1 [1960/2566 (76%)]\tLoss: 1.552791\n",
      "Train Epoch: 1 [2000/2566 (78%)]\tLoss: 1.559246\n",
      "Train Epoch: 1 [2040/2566 (79%)]\tLoss: 1.559934\n",
      "Train Epoch: 1 [2080/2566 (81%)]\tLoss: 1.559260\n",
      "Train Epoch: 1 [2120/2566 (83%)]\tLoss: 1.607688\n",
      "Train Epoch: 1 [2160/2566 (84%)]\tLoss: 1.551015\n",
      "Train Epoch: 1 [2200/2566 (86%)]\tLoss: 1.539136\n",
      "Train Epoch: 1 [2240/2566 (87%)]\tLoss: 1.558125\n",
      "Train Epoch: 1 [2280/2566 (89%)]\tLoss: 1.612281\n",
      "Train Epoch: 1 [2320/2566 (90%)]\tLoss: 1.546278\n",
      "Train Epoch: 1 [2360/2566 (92%)]\tLoss: 1.531591\n",
      "Train Epoch: 1 [2400/2566 (93%)]\tLoss: 1.547631\n",
      "Train Epoch: 1 [2440/2566 (95%)]\tLoss: 1.554067\n",
      "Train Epoch: 1 [2480/2566 (97%)]\tLoss: 1.577221\n",
      "Train Epoch: 1 [2520/2566 (98%)]\tLoss: 1.559732\n",
      "Train Epoch: 1 [2560/2566 (100%)]\tLoss: 1.544706\n",
      "epoch:1,loss:1.5834404140989358\n",
      "Train set: Average loss: 1.5382, Accuracy: 1765/2566 (69%)\n",
      "Val set: Average loss: 1.5395, Accuracy: 219/327 (67%)\n",
      "Train Epoch: 2 [40/2566 (2%)]\tLoss: 1.533302\n",
      "Train Epoch: 2 [80/2566 (3%)]\tLoss: 1.548285\n",
      "Train Epoch: 2 [120/2566 (5%)]\tLoss: 1.551177\n",
      "Train Epoch: 2 [160/2566 (6%)]\tLoss: 1.553042\n",
      "Train Epoch: 2 [200/2566 (8%)]\tLoss: 1.506505\n",
      "Train Epoch: 2 [240/2566 (9%)]\tLoss: 1.574739\n",
      "Train Epoch: 2 [280/2566 (11%)]\tLoss: 1.526555\n",
      "Train Epoch: 2 [320/2566 (12%)]\tLoss: 1.623236\n",
      "Train Epoch: 2 [360/2566 (14%)]\tLoss: 1.513301\n",
      "Train Epoch: 2 [400/2566 (16%)]\tLoss: 1.514675\n",
      "Train Epoch: 2 [440/2566 (17%)]\tLoss: 1.533412\n",
      "Train Epoch: 2 [480/2566 (19%)]\tLoss: 1.532736\n",
      "Train Epoch: 2 [520/2566 (20%)]\tLoss: 1.532482\n",
      "Train Epoch: 2 [560/2566 (22%)]\tLoss: 1.590260\n",
      "Train Epoch: 2 [600/2566 (23%)]\tLoss: 1.506907\n",
      "Train Epoch: 2 [640/2566 (25%)]\tLoss: 1.517282\n",
      "Train Epoch: 2 [680/2566 (26%)]\tLoss: 1.545823\n",
      "Train Epoch: 2 [720/2566 (28%)]\tLoss: 1.530339\n",
      "Train Epoch: 2 [760/2566 (30%)]\tLoss: 1.488858\n",
      "Train Epoch: 2 [800/2566 (31%)]\tLoss: 1.521032\n",
      "Train Epoch: 2 [840/2566 (33%)]\tLoss: 1.521734\n",
      "Train Epoch: 2 [880/2566 (34%)]\tLoss: 1.508843\n",
      "Train Epoch: 2 [920/2566 (36%)]\tLoss: 1.511202\n",
      "Train Epoch: 2 [960/2566 (37%)]\tLoss: 1.484479\n",
      "Train Epoch: 2 [1000/2566 (39%)]\tLoss: 1.479929\n",
      "Train Epoch: 2 [1040/2566 (40%)]\tLoss: 1.498279\n",
      "Train Epoch: 2 [1080/2566 (42%)]\tLoss: 1.468809\n",
      "Train Epoch: 2 [1120/2566 (44%)]\tLoss: 1.501963\n",
      "Train Epoch: 2 [1160/2566 (45%)]\tLoss: 1.478305\n",
      "Train Epoch: 2 [1200/2566 (47%)]\tLoss: 1.469273\n",
      "Train Epoch: 2 [1240/2566 (48%)]\tLoss: 1.463259\n",
      "Train Epoch: 2 [1280/2566 (50%)]\tLoss: 1.500733\n",
      "Train Epoch: 2 [1320/2566 (51%)]\tLoss: 1.482554\n",
      "Train Epoch: 2 [1360/2566 (53%)]\tLoss: 1.476957\n",
      "Train Epoch: 2 [1400/2566 (55%)]\tLoss: 1.465332\n",
      "Train Epoch: 2 [1440/2566 (56%)]\tLoss: 1.441764\n",
      "Train Epoch: 2 [1480/2566 (58%)]\tLoss: 1.425496\n",
      "Train Epoch: 2 [1520/2566 (59%)]\tLoss: 1.435533\n",
      "Train Epoch: 2 [1560/2566 (61%)]\tLoss: 1.462164\n",
      "Train Epoch: 2 [1600/2566 (62%)]\tLoss: 1.508387\n",
      "Train Epoch: 2 [1640/2566 (64%)]\tLoss: 1.487644\n",
      "Train Epoch: 2 [1680/2566 (65%)]\tLoss: 1.439368\n",
      "Train Epoch: 2 [1720/2566 (67%)]\tLoss: 1.432876\n",
      "Train Epoch: 2 [1760/2566 (69%)]\tLoss: 1.422731\n",
      "Train Epoch: 2 [1800/2566 (70%)]\tLoss: 1.451394\n",
      "Train Epoch: 2 [1840/2566 (72%)]\tLoss: 1.426296\n",
      "Train Epoch: 2 [1880/2566 (73%)]\tLoss: 1.423351\n",
      "Train Epoch: 2 [1920/2566 (75%)]\tLoss: 1.444265\n",
      "Train Epoch: 2 [1960/2566 (76%)]\tLoss: 1.421362\n",
      "Train Epoch: 2 [2000/2566 (78%)]\tLoss: 1.417605\n",
      "Train Epoch: 2 [2040/2566 (79%)]\tLoss: 1.464417\n",
      "Train Epoch: 2 [2080/2566 (81%)]\tLoss: 1.472303\n",
      "Train Epoch: 2 [2120/2566 (83%)]\tLoss: 1.397264\n",
      "Train Epoch: 2 [2160/2566 (84%)]\tLoss: 1.411272\n",
      "Train Epoch: 2 [2200/2566 (86%)]\tLoss: 1.400200\n",
      "Train Epoch: 2 [2240/2566 (87%)]\tLoss: 1.427978\n",
      "Train Epoch: 2 [2280/2566 (89%)]\tLoss: 1.560986\n",
      "Train Epoch: 2 [2320/2566 (90%)]\tLoss: 1.411746\n",
      "Train Epoch: 2 [2360/2566 (92%)]\tLoss: 1.398571\n",
      "Train Epoch: 2 [2400/2566 (93%)]\tLoss: 1.408702\n",
      "Train Epoch: 2 [2440/2566 (95%)]\tLoss: 1.418763\n",
      "Train Epoch: 2 [2480/2566 (97%)]\tLoss: 1.378224\n",
      "Train Epoch: 2 [2520/2566 (98%)]\tLoss: 1.480428\n",
      "Train Epoch: 2 [2560/2566 (100%)]\tLoss: 1.416399\n",
      "epoch:2,loss:1.479833276472359\n",
      "Train set: Average loss: 1.3674, Accuracy: 1814/2566 (71%)\n",
      "Val set: Average loss: 1.3739, Accuracy: 232/327 (71%)\n",
      "Train Epoch: 3 [40/2566 (2%)]\tLoss: 1.523321\n",
      "Train Epoch: 3 [80/2566 (3%)]\tLoss: 1.478497\n",
      "Train Epoch: 3 [120/2566 (5%)]\tLoss: 1.392144\n",
      "Train Epoch: 3 [160/2566 (6%)]\tLoss: 1.428553\n",
      "Train Epoch: 3 [200/2566 (8%)]\tLoss: 1.347462\n",
      "Train Epoch: 3 [240/2566 (9%)]\tLoss: 1.385956\n",
      "Train Epoch: 3 [280/2566 (11%)]\tLoss: 1.371489\n",
      "Train Epoch: 3 [320/2566 (12%)]\tLoss: 1.591193\n",
      "Train Epoch: 3 [360/2566 (14%)]\tLoss: 1.365307\n",
      "Train Epoch: 3 [400/2566 (16%)]\tLoss: 1.395370\n",
      "Train Epoch: 3 [440/2566 (17%)]\tLoss: 1.383844\n",
      "Train Epoch: 3 [480/2566 (19%)]\tLoss: 1.356572\n",
      "Train Epoch: 3 [520/2566 (20%)]\tLoss: 1.426989\n",
      "Train Epoch: 3 [560/2566 (22%)]\tLoss: 1.373146\n",
      "Train Epoch: 3 [600/2566 (23%)]\tLoss: 1.389612\n",
      "Train Epoch: 3 [640/2566 (25%)]\tLoss: 1.363874\n",
      "Train Epoch: 3 [680/2566 (26%)]\tLoss: 1.394332\n",
      "Train Epoch: 3 [720/2566 (28%)]\tLoss: 1.325470\n",
      "Train Epoch: 3 [760/2566 (30%)]\tLoss: 1.341193\n",
      "Train Epoch: 3 [800/2566 (31%)]\tLoss: 1.398225\n",
      "Train Epoch: 3 [840/2566 (33%)]\tLoss: 1.308232\n",
      "Train Epoch: 3 [880/2566 (34%)]\tLoss: 1.335251\n",
      "Train Epoch: 3 [920/2566 (36%)]\tLoss: 1.294664\n",
      "Train Epoch: 3 [960/2566 (37%)]\tLoss: 1.412374\n",
      "Train Epoch: 3 [1000/2566 (39%)]\tLoss: 1.345766\n",
      "Train Epoch: 3 [1040/2566 (40%)]\tLoss: 1.326534\n",
      "Train Epoch: 3 [1080/2566 (42%)]\tLoss: 1.288783\n",
      "Train Epoch: 3 [1120/2566 (44%)]\tLoss: 1.319981\n",
      "Train Epoch: 3 [1160/2566 (45%)]\tLoss: 1.438047\n",
      "Train Epoch: 3 [1200/2566 (47%)]\tLoss: 1.322853\n",
      "Train Epoch: 3 [1240/2566 (48%)]\tLoss: 1.279820\n",
      "Train Epoch: 3 [1280/2566 (50%)]\tLoss: 1.494890\n",
      "Train Epoch: 3 [1320/2566 (51%)]\tLoss: 1.364693\n",
      "Train Epoch: 3 [1360/2566 (53%)]\tLoss: 1.395643\n",
      "Train Epoch: 3 [1400/2566 (55%)]\tLoss: 1.363851\n",
      "Train Epoch: 3 [1440/2566 (56%)]\tLoss: 1.305117\n",
      "Train Epoch: 3 [1480/2566 (58%)]\tLoss: 1.312999\n",
      "Train Epoch: 3 [1520/2566 (59%)]\tLoss: 1.308569\n",
      "Train Epoch: 3 [1560/2566 (61%)]\tLoss: 1.339375\n",
      "Train Epoch: 3 [1600/2566 (62%)]\tLoss: 1.284640\n",
      "Train Epoch: 3 [1640/2566 (64%)]\tLoss: 1.282186\n",
      "Train Epoch: 3 [1680/2566 (65%)]\tLoss: 1.325331\n",
      "Train Epoch: 3 [1720/2566 (67%)]\tLoss: 1.321310\n",
      "Train Epoch: 3 [1760/2566 (69%)]\tLoss: 1.392239\n",
      "Train Epoch: 3 [1800/2566 (70%)]\tLoss: 1.258816\n",
      "Train Epoch: 3 [1840/2566 (72%)]\tLoss: 1.296292\n",
      "Train Epoch: 3 [1880/2566 (73%)]\tLoss: 1.240030\n",
      "Train Epoch: 3 [1920/2566 (75%)]\tLoss: 1.258086\n",
      "Train Epoch: 3 [1960/2566 (76%)]\tLoss: 1.255845\n",
      "Train Epoch: 3 [2000/2566 (78%)]\tLoss: 1.257848\n",
      "Train Epoch: 3 [2040/2566 (79%)]\tLoss: 1.234569\n",
      "Train Epoch: 3 [2080/2566 (81%)]\tLoss: 1.273149\n",
      "Train Epoch: 3 [2120/2566 (83%)]\tLoss: 1.213568\n",
      "Train Epoch: 3 [2160/2566 (84%)]\tLoss: 1.254936\n",
      "Train Epoch: 3 [2200/2566 (86%)]\tLoss: 1.245684\n",
      "Train Epoch: 3 [2240/2566 (87%)]\tLoss: 1.254666\n",
      "Train Epoch: 3 [2280/2566 (89%)]\tLoss: 1.234725\n",
      "Train Epoch: 3 [2320/2566 (90%)]\tLoss: 1.232857\n",
      "Train Epoch: 3 [2360/2566 (92%)]\tLoss: 1.243655\n",
      "Train Epoch: 3 [2400/2566 (93%)]\tLoss: 1.213107\n",
      "Train Epoch: 3 [2440/2566 (95%)]\tLoss: 1.248650\n",
      "Train Epoch: 3 [2480/2566 (97%)]\tLoss: 1.217517\n",
      "Train Epoch: 3 [2520/2566 (98%)]\tLoss: 1.221535\n",
      "Train Epoch: 3 [2560/2566 (100%)]\tLoss: 1.188682\n",
      "epoch:3,loss:1.3277915489636478\n",
      "Train set: Average loss: 1.2288, Accuracy: 1834/2566 (71%)\n",
      "Val set: Average loss: 1.2391, Accuracy: 238/327 (73%)\n",
      "Train Epoch: 4 [40/2566 (2%)]\tLoss: 1.208628\n",
      "Train Epoch: 4 [80/2566 (3%)]\tLoss: 1.207168\n",
      "Train Epoch: 4 [120/2566 (5%)]\tLoss: 1.208375\n",
      "Train Epoch: 4 [160/2566 (6%)]\tLoss: 1.178478\n",
      "Train Epoch: 4 [200/2566 (8%)]\tLoss: 1.220403\n",
      "Train Epoch: 4 [240/2566 (9%)]\tLoss: 1.204078\n",
      "Train Epoch: 4 [280/2566 (11%)]\tLoss: 1.206152\n",
      "Train Epoch: 4 [320/2566 (12%)]\tLoss: 1.289373\n",
      "Train Epoch: 4 [360/2566 (14%)]\tLoss: 1.234813\n",
      "Train Epoch: 4 [400/2566 (16%)]\tLoss: 1.200509\n",
      "Train Epoch: 4 [440/2566 (17%)]\tLoss: 1.471663\n",
      "Train Epoch: 4 [480/2566 (19%)]\tLoss: 1.211004\n",
      "Train Epoch: 4 [520/2566 (20%)]\tLoss: 1.154747\n",
      "Train Epoch: 4 [560/2566 (22%)]\tLoss: 1.278031\n",
      "Train Epoch: 4 [600/2566 (23%)]\tLoss: 1.156864\n",
      "Train Epoch: 4 [640/2566 (25%)]\tLoss: 1.209042\n",
      "Train Epoch: 4 [680/2566 (26%)]\tLoss: 1.231086\n",
      "Train Epoch: 4 [720/2566 (28%)]\tLoss: 1.221002\n",
      "Train Epoch: 4 [760/2566 (30%)]\tLoss: 1.183332\n",
      "Train Epoch: 4 [800/2566 (31%)]\tLoss: 1.173008\n",
      "Train Epoch: 4 [840/2566 (33%)]\tLoss: 1.148357\n",
      "Train Epoch: 4 [880/2566 (34%)]\tLoss: 1.141134\n",
      "Train Epoch: 4 [920/2566 (36%)]\tLoss: 1.121930\n",
      "Train Epoch: 4 [960/2566 (37%)]\tLoss: 1.165740\n",
      "Train Epoch: 4 [1000/2566 (39%)]\tLoss: 1.224526\n",
      "Train Epoch: 4 [1040/2566 (40%)]\tLoss: 1.146354\n",
      "Train Epoch: 4 [1080/2566 (42%)]\tLoss: 1.139358\n",
      "Train Epoch: 4 [1120/2566 (44%)]\tLoss: 1.645175\n",
      "Train Epoch: 4 [1160/2566 (45%)]\tLoss: 1.237334\n",
      "Train Epoch: 4 [1200/2566 (47%)]\tLoss: 1.159938\n",
      "Train Epoch: 4 [1240/2566 (48%)]\tLoss: 1.177663\n",
      "Train Epoch: 4 [1280/2566 (50%)]\tLoss: 1.144622\n",
      "Train Epoch: 4 [1320/2566 (51%)]\tLoss: 1.196367\n",
      "Train Epoch: 4 [1360/2566 (53%)]\tLoss: 1.166884\n",
      "Train Epoch: 4 [1400/2566 (55%)]\tLoss: 1.187950\n",
      "Train Epoch: 4 [1440/2566 (56%)]\tLoss: 1.153757\n",
      "Train Epoch: 4 [1480/2566 (58%)]\tLoss: 1.191681\n",
      "Train Epoch: 4 [1520/2566 (59%)]\tLoss: 1.713575\n",
      "Train Epoch: 4 [1560/2566 (61%)]\tLoss: 1.240626\n",
      "Train Epoch: 4 [1600/2566 (62%)]\tLoss: 1.155531\n",
      "Train Epoch: 4 [1640/2566 (64%)]\tLoss: 1.138698\n",
      "Train Epoch: 4 [1680/2566 (65%)]\tLoss: 1.222022\n",
      "Train Epoch: 4 [1720/2566 (67%)]\tLoss: 1.104374\n",
      "Train Epoch: 4 [1760/2566 (69%)]\tLoss: 1.135360\n",
      "Train Epoch: 4 [1800/2566 (70%)]\tLoss: 1.085864\n",
      "Train Epoch: 4 [1840/2566 (72%)]\tLoss: 1.112502\n",
      "Train Epoch: 4 [1880/2566 (73%)]\tLoss: 1.421529\n",
      "Train Epoch: 4 [1920/2566 (75%)]\tLoss: 1.093843\n",
      "Train Epoch: 4 [1960/2566 (76%)]\tLoss: 1.114512\n",
      "Train Epoch: 4 [2000/2566 (78%)]\tLoss: 1.145107\n",
      "Train Epoch: 4 [2040/2566 (79%)]\tLoss: 1.117147\n",
      "Train Epoch: 4 [2080/2566 (81%)]\tLoss: 1.095674\n",
      "Train Epoch: 4 [2120/2566 (83%)]\tLoss: 1.093343\n",
      "Train Epoch: 4 [2160/2566 (84%)]\tLoss: 1.100309\n",
      "Train Epoch: 4 [2200/2566 (86%)]\tLoss: 1.226086\n",
      "Train Epoch: 4 [2240/2566 (87%)]\tLoss: 1.281504\n",
      "Train Epoch: 4 [2280/2566 (89%)]\tLoss: 1.095244\n",
      "Train Epoch: 4 [2320/2566 (90%)]\tLoss: 1.092853\n",
      "Train Epoch: 4 [2360/2566 (92%)]\tLoss: 1.147464\n",
      "Train Epoch: 4 [2400/2566 (93%)]\tLoss: 1.122801\n",
      "Train Epoch: 4 [2440/2566 (95%)]\tLoss: 1.132673\n",
      "Train Epoch: 4 [2480/2566 (97%)]\tLoss: 1.083956\n",
      "Train Epoch: 4 [2520/2566 (98%)]\tLoss: 1.115605\n",
      "Train Epoch: 4 [2560/2566 (100%)]\tLoss: 1.220241\n",
      "epoch:4,loss:1.2131144837055623\n",
      "Train set: Average loss: 1.1044, Accuracy: 1854/2566 (72%)\n",
      "Val set: Average loss: 1.1144, Accuracy: 241/327 (74%)\n",
      "Train Epoch: 5 [40/2566 (2%)]\tLoss: 1.036903\n",
      "Train Epoch: 5 [80/2566 (3%)]\tLoss: 1.812546\n",
      "Train Epoch: 5 [120/2566 (5%)]\tLoss: 1.080594\n",
      "Train Epoch: 5 [160/2566 (6%)]\tLoss: 1.092414\n",
      "Train Epoch: 5 [200/2566 (8%)]\tLoss: 1.077063\n",
      "Train Epoch: 5 [240/2566 (9%)]\tLoss: 1.118903\n",
      "Train Epoch: 5 [280/2566 (11%)]\tLoss: 1.135458\n",
      "Train Epoch: 5 [320/2566 (12%)]\tLoss: 1.207142\n",
      "Train Epoch: 5 [360/2566 (14%)]\tLoss: 1.087810\n",
      "Train Epoch: 5 [400/2566 (16%)]\tLoss: 1.511448\n",
      "Train Epoch: 5 [440/2566 (17%)]\tLoss: 1.155145\n",
      "Train Epoch: 5 [480/2566 (19%)]\tLoss: 1.101169\n",
      "Train Epoch: 5 [520/2566 (20%)]\tLoss: 1.069469\n",
      "Train Epoch: 5 [560/2566 (22%)]\tLoss: 1.008580\n",
      "Train Epoch: 5 [600/2566 (23%)]\tLoss: 1.117155\n",
      "Train Epoch: 5 [640/2566 (25%)]\tLoss: 1.048936\n",
      "Train Epoch: 5 [680/2566 (26%)]\tLoss: 1.097485\n",
      "Train Epoch: 5 [720/2566 (28%)]\tLoss: 1.104775\n",
      "Train Epoch: 5 [760/2566 (30%)]\tLoss: 1.084357\n",
      "Train Epoch: 5 [800/2566 (31%)]\tLoss: 1.255687\n",
      "Train Epoch: 5 [840/2566 (33%)]\tLoss: 1.112240\n",
      "Train Epoch: 5 [880/2566 (34%)]\tLoss: 1.137481\n",
      "Train Epoch: 5 [920/2566 (36%)]\tLoss: 1.065081\n",
      "Train Epoch: 5 [960/2566 (37%)]\tLoss: 1.050058\n",
      "Train Epoch: 5 [1000/2566 (39%)]\tLoss: 1.272122\n",
      "Train Epoch: 5 [1040/2566 (40%)]\tLoss: 1.092358\n",
      "Train Epoch: 5 [1080/2566 (42%)]\tLoss: 1.039433\n",
      "Train Epoch: 5 [1120/2566 (44%)]\tLoss: 1.042317\n",
      "Train Epoch: 5 [1160/2566 (45%)]\tLoss: 1.034105\n",
      "Train Epoch: 5 [1200/2566 (47%)]\tLoss: 1.016418\n",
      "Train Epoch: 5 [1240/2566 (48%)]\tLoss: 1.138435\n",
      "Train Epoch: 5 [1280/2566 (50%)]\tLoss: 1.118096\n",
      "Train Epoch: 5 [1320/2566 (51%)]\tLoss: 1.214128\n",
      "Train Epoch: 5 [1360/2566 (53%)]\tLoss: 1.142739\n",
      "Train Epoch: 5 [1400/2566 (55%)]\tLoss: 1.091985\n",
      "Train Epoch: 5 [1440/2566 (56%)]\tLoss: 1.029729\n",
      "Train Epoch: 5 [1480/2566 (58%)]\tLoss: 1.159383\n",
      "Train Epoch: 5 [1520/2566 (59%)]\tLoss: 1.340795\n",
      "Train Epoch: 5 [1560/2566 (61%)]\tLoss: 1.064820\n",
      "Train Epoch: 5 [1600/2566 (62%)]\tLoss: 1.013878\n",
      "Train Epoch: 5 [1640/2566 (64%)]\tLoss: 1.264666\n",
      "Train Epoch: 5 [1680/2566 (65%)]\tLoss: 1.012930\n",
      "Train Epoch: 5 [1720/2566 (67%)]\tLoss: 0.993929\n",
      "Train Epoch: 5 [1760/2566 (69%)]\tLoss: 1.374478\n",
      "Train Epoch: 5 [1800/2566 (70%)]\tLoss: 1.125722\n",
      "Train Epoch: 5 [1840/2566 (72%)]\tLoss: 1.385877\n",
      "Train Epoch: 5 [1880/2566 (73%)]\tLoss: 1.030943\n",
      "Train Epoch: 5 [1920/2566 (75%)]\tLoss: 1.007613\n",
      "Train Epoch: 5 [1960/2566 (76%)]\tLoss: 1.046786\n",
      "Train Epoch: 5 [2000/2566 (78%)]\tLoss: 0.983617\n",
      "Train Epoch: 5 [2040/2566 (79%)]\tLoss: 0.941413\n",
      "Train Epoch: 5 [2080/2566 (81%)]\tLoss: 1.162443\n",
      "Train Epoch: 5 [2120/2566 (83%)]\tLoss: 0.972809\n",
      "Train Epoch: 5 [2160/2566 (84%)]\tLoss: 1.222859\n",
      "Train Epoch: 5 [2200/2566 (86%)]\tLoss: 1.088371\n",
      "Train Epoch: 5 [2240/2566 (87%)]\tLoss: 1.275471\n",
      "Train Epoch: 5 [2280/2566 (89%)]\tLoss: 0.947678\n",
      "Train Epoch: 5 [2320/2566 (90%)]\tLoss: 0.909347\n",
      "Train Epoch: 5 [2360/2566 (92%)]\tLoss: 1.240836\n",
      "Train Epoch: 5 [2400/2566 (93%)]\tLoss: 0.934344\n",
      "Train Epoch: 5 [2440/2566 (95%)]\tLoss: 1.208787\n",
      "Train Epoch: 5 [2480/2566 (97%)]\tLoss: 1.044769\n",
      "Train Epoch: 5 [2520/2566 (98%)]\tLoss: 1.293115\n",
      "Train Epoch: 5 [2560/2566 (100%)]\tLoss: 1.021263\n",
      "epoch:5,loss:1.1106900678616818\n",
      "Train set: Average loss: 1.0239, Accuracy: 1862/2566 (73%)\n",
      "Val set: Average loss: 1.0275, Accuracy: 241/327 (74%)\n",
      "Train Epoch: 6 [40/2566 (2%)]\tLoss: 0.971863\n",
      "Train Epoch: 6 [80/2566 (3%)]\tLoss: 1.247266\n",
      "Train Epoch: 6 [120/2566 (5%)]\tLoss: 1.352913\n",
      "Train Epoch: 6 [160/2566 (6%)]\tLoss: 1.116953\n",
      "Train Epoch: 6 [200/2566 (8%)]\tLoss: 1.210290\n",
      "Train Epoch: 6 [240/2566 (9%)]\tLoss: 1.003400\n",
      "Train Epoch: 6 [280/2566 (11%)]\tLoss: 1.202754\n",
      "Train Epoch: 6 [320/2566 (12%)]\tLoss: 1.079286\n",
      "Train Epoch: 6 [360/2566 (14%)]\tLoss: 0.949950\n",
      "Train Epoch: 6 [400/2566 (16%)]\tLoss: 1.376130\n",
      "Train Epoch: 6 [440/2566 (17%)]\tLoss: 1.055326\n",
      "Train Epoch: 6 [480/2566 (19%)]\tLoss: 1.046511\n",
      "Train Epoch: 6 [520/2566 (20%)]\tLoss: 1.311643\n",
      "Train Epoch: 6 [560/2566 (22%)]\tLoss: 1.025740\n",
      "Train Epoch: 6 [600/2566 (23%)]\tLoss: 0.936931\n",
      "Train Epoch: 6 [640/2566 (25%)]\tLoss: 0.934959\n",
      "Train Epoch: 6 [680/2566 (26%)]\tLoss: 1.233393\n",
      "Train Epoch: 6 [720/2566 (28%)]\tLoss: 1.058348\n",
      "Train Epoch: 6 [760/2566 (30%)]\tLoss: 1.193436\n",
      "Train Epoch: 6 [800/2566 (31%)]\tLoss: 1.333443\n",
      "Train Epoch: 6 [840/2566 (33%)]\tLoss: 1.258566\n",
      "Train Epoch: 6 [880/2566 (34%)]\tLoss: 1.077739\n",
      "Train Epoch: 6 [920/2566 (36%)]\tLoss: 0.988087\n",
      "Train Epoch: 6 [960/2566 (37%)]\tLoss: 0.913530\n",
      "Train Epoch: 6 [1000/2566 (39%)]\tLoss: 0.957021\n",
      "Train Epoch: 6 [1040/2566 (40%)]\tLoss: 0.962643\n",
      "Train Epoch: 6 [1080/2566 (42%)]\tLoss: 1.001092\n",
      "Train Epoch: 6 [1120/2566 (44%)]\tLoss: 1.007066\n",
      "Train Epoch: 6 [1160/2566 (45%)]\tLoss: 0.999882\n",
      "Train Epoch: 6 [1200/2566 (47%)]\tLoss: 1.130203\n",
      "Train Epoch: 6 [1240/2566 (48%)]\tLoss: 0.920095\n",
      "Train Epoch: 6 [1280/2566 (50%)]\tLoss: 1.008832\n",
      "Train Epoch: 6 [1320/2566 (51%)]\tLoss: 0.891413\n",
      "Train Epoch: 6 [1360/2566 (53%)]\tLoss: 0.957379\n",
      "Train Epoch: 6 [1400/2566 (55%)]\tLoss: 0.842954\n",
      "Train Epoch: 6 [1440/2566 (56%)]\tLoss: 0.918041\n",
      "Train Epoch: 6 [1480/2566 (58%)]\tLoss: 1.083393\n",
      "Train Epoch: 6 [1520/2566 (59%)]\tLoss: 1.100303\n",
      "Train Epoch: 6 [1560/2566 (61%)]\tLoss: 1.409029\n",
      "Train Epoch: 6 [1600/2566 (62%)]\tLoss: 0.881150\n",
      "Train Epoch: 6 [1640/2566 (64%)]\tLoss: 0.995970\n",
      "Train Epoch: 6 [1680/2566 (65%)]\tLoss: 1.197199\n",
      "Train Epoch: 6 [1720/2566 (67%)]\tLoss: 0.978742\n",
      "Train Epoch: 6 [1760/2566 (69%)]\tLoss: 1.212295\n",
      "Train Epoch: 6 [1800/2566 (70%)]\tLoss: 0.920765\n",
      "Train Epoch: 6 [1840/2566 (72%)]\tLoss: 0.900642\n",
      "Train Epoch: 6 [1880/2566 (73%)]\tLoss: 1.017751\n",
      "Train Epoch: 6 [1920/2566 (75%)]\tLoss: 0.977921\n",
      "Train Epoch: 6 [1960/2566 (76%)]\tLoss: 1.160782\n",
      "Train Epoch: 6 [2000/2566 (78%)]\tLoss: 0.860716\n",
      "Train Epoch: 6 [2040/2566 (79%)]\tLoss: 1.376952\n",
      "Train Epoch: 6 [2080/2566 (81%)]\tLoss: 0.884907\n",
      "Train Epoch: 6 [2120/2566 (83%)]\tLoss: 1.150808\n",
      "Train Epoch: 6 [2160/2566 (84%)]\tLoss: 0.984597\n",
      "Train Epoch: 6 [2200/2566 (86%)]\tLoss: 0.973811\n",
      "Train Epoch: 6 [2240/2566 (87%)]\tLoss: 0.882994\n",
      "Train Epoch: 6 [2280/2566 (89%)]\tLoss: 1.158301\n",
      "Train Epoch: 6 [2320/2566 (90%)]\tLoss: 1.010279\n",
      "Train Epoch: 6 [2360/2566 (92%)]\tLoss: 1.252117\n",
      "Train Epoch: 6 [2400/2566 (93%)]\tLoss: 0.965176\n",
      "Train Epoch: 6 [2440/2566 (95%)]\tLoss: 0.888362\n",
      "Train Epoch: 6 [2480/2566 (97%)]\tLoss: 0.855787\n",
      "Train Epoch: 6 [2520/2566 (98%)]\tLoss: 1.090649\n",
      "Train Epoch: 6 [2560/2566 (100%)]\tLoss: 0.825928\n",
      "epoch:6,loss:1.0483616779897815\n",
      "Train set: Average loss: 0.9736, Accuracy: 1859/2566 (72%)\n",
      "Val set: Average loss: 0.9698, Accuracy: 240/327 (73%)\n",
      "Train Epoch: 7 [40/2566 (2%)]\tLoss: 0.996369\n",
      "Train Epoch: 7 [80/2566 (3%)]\tLoss: 0.814261\n",
      "Train Epoch: 7 [120/2566 (5%)]\tLoss: 0.781507\n",
      "Train Epoch: 7 [160/2566 (6%)]\tLoss: 1.129305\n",
      "Train Epoch: 7 [200/2566 (8%)]\tLoss: 0.864461\n",
      "Train Epoch: 7 [240/2566 (9%)]\tLoss: 0.825468\n",
      "Train Epoch: 7 [280/2566 (11%)]\tLoss: 0.762460\n",
      "Train Epoch: 7 [320/2566 (12%)]\tLoss: 1.428256\n",
      "Train Epoch: 7 [360/2566 (14%)]\tLoss: 1.023039\n",
      "Train Epoch: 7 [400/2566 (16%)]\tLoss: 1.245038\n",
      "Train Epoch: 7 [440/2566 (17%)]\tLoss: 0.829142\n",
      "Train Epoch: 7 [480/2566 (19%)]\tLoss: 1.007339\n",
      "Train Epoch: 7 [520/2566 (20%)]\tLoss: 0.862503\n",
      "Train Epoch: 7 [560/2566 (22%)]\tLoss: 0.881687\n",
      "Train Epoch: 7 [600/2566 (23%)]\tLoss: 0.855005\n",
      "Train Epoch: 7 [640/2566 (25%)]\tLoss: 0.884489\n",
      "Train Epoch: 7 [680/2566 (26%)]\tLoss: 1.496181\n",
      "Train Epoch: 7 [720/2566 (28%)]\tLoss: 1.003343\n",
      "Train Epoch: 7 [760/2566 (30%)]\tLoss: 1.025712\n",
      "Train Epoch: 7 [800/2566 (31%)]\tLoss: 1.209485\n",
      "Train Epoch: 7 [840/2566 (33%)]\tLoss: 1.114169\n",
      "Train Epoch: 7 [880/2566 (34%)]\tLoss: 1.029272\n",
      "Train Epoch: 7 [920/2566 (36%)]\tLoss: 1.033897\n",
      "Train Epoch: 7 [960/2566 (37%)]\tLoss: 1.493651\n",
      "Train Epoch: 7 [1000/2566 (39%)]\tLoss: 0.920440\n",
      "Train Epoch: 7 [1040/2566 (40%)]\tLoss: 1.966778\n",
      "Train Epoch: 7 [1080/2566 (42%)]\tLoss: 1.109448\n",
      "Train Epoch: 7 [1120/2566 (44%)]\tLoss: 0.788721\n",
      "Train Epoch: 7 [1160/2566 (45%)]\tLoss: 0.850684\n",
      "Train Epoch: 7 [1200/2566 (47%)]\tLoss: 1.187822\n",
      "Train Epoch: 7 [1240/2566 (48%)]\tLoss: 1.009658\n",
      "Train Epoch: 7 [1280/2566 (50%)]\tLoss: 0.837681\n",
      "Train Epoch: 7 [1320/2566 (51%)]\tLoss: 1.433129\n",
      "Train Epoch: 7 [1360/2566 (53%)]\tLoss: 0.965421\n",
      "Train Epoch: 7 [1400/2566 (55%)]\tLoss: 0.897184\n",
      "Train Epoch: 7 [1440/2566 (56%)]\tLoss: 1.006675\n",
      "Train Epoch: 7 [1480/2566 (58%)]\tLoss: 0.963486\n",
      "Train Epoch: 7 [1520/2566 (59%)]\tLoss: 0.962693\n",
      "Train Epoch: 7 [1560/2566 (61%)]\tLoss: 0.705881\n",
      "Train Epoch: 7 [1600/2566 (62%)]\tLoss: 0.811252\n",
      "Train Epoch: 7 [1640/2566 (64%)]\tLoss: 1.092638\n",
      "Train Epoch: 7 [1680/2566 (65%)]\tLoss: 0.855513\n",
      "Train Epoch: 7 [1720/2566 (67%)]\tLoss: 0.836968\n",
      "Train Epoch: 7 [1760/2566 (69%)]\tLoss: 0.831564\n",
      "Train Epoch: 7 [1800/2566 (70%)]\tLoss: 1.380120\n",
      "Train Epoch: 7 [1840/2566 (72%)]\tLoss: 0.738676\n",
      "Train Epoch: 7 [1880/2566 (73%)]\tLoss: 1.236807\n",
      "Train Epoch: 7 [1920/2566 (75%)]\tLoss: 1.159259\n",
      "Train Epoch: 7 [1960/2566 (76%)]\tLoss: 0.925334\n",
      "Train Epoch: 7 [2000/2566 (78%)]\tLoss: 0.833757\n",
      "Train Epoch: 7 [2040/2566 (79%)]\tLoss: 0.874340\n",
      "Train Epoch: 7 [2080/2566 (81%)]\tLoss: 0.865952\n",
      "Train Epoch: 7 [2120/2566 (83%)]\tLoss: 0.847372\n",
      "Train Epoch: 7 [2160/2566 (84%)]\tLoss: 0.894579\n",
      "Train Epoch: 7 [2200/2566 (86%)]\tLoss: 1.018832\n",
      "Train Epoch: 7 [2240/2566 (87%)]\tLoss: 0.995110\n",
      "Train Epoch: 7 [2280/2566 (89%)]\tLoss: 1.691541\n",
      "Train Epoch: 7 [2320/2566 (90%)]\tLoss: 0.886572\n",
      "Train Epoch: 7 [2360/2566 (92%)]\tLoss: 0.981233\n",
      "Train Epoch: 7 [2400/2566 (93%)]\tLoss: 0.705338\n",
      "Train Epoch: 7 [2440/2566 (95%)]\tLoss: 0.775804\n",
      "Train Epoch: 7 [2480/2566 (97%)]\tLoss: 1.068896\n",
      "Train Epoch: 7 [2520/2566 (98%)]\tLoss: 0.834886\n",
      "Train Epoch: 7 [2560/2566 (100%)]\tLoss: 0.830366\n",
      "epoch:7,loss:0.9949741885298138\n",
      "Train set: Average loss: 0.8877, Accuracy: 1862/2566 (73%)\n",
      "Val set: Average loss: 0.8852, Accuracy: 240/327 (73%)\n",
      "Train Epoch: 8 [40/2566 (2%)]\tLoss: 0.756438\n",
      "Train Epoch: 8 [80/2566 (3%)]\tLoss: 0.675205\n",
      "Train Epoch: 8 [120/2566 (5%)]\tLoss: 0.869529\n",
      "Train Epoch: 8 [160/2566 (6%)]\tLoss: 1.164854\n",
      "Train Epoch: 8 [200/2566 (8%)]\tLoss: 0.763775\n",
      "Train Epoch: 8 [240/2566 (9%)]\tLoss: 1.225890\n",
      "Train Epoch: 8 [280/2566 (11%)]\tLoss: 1.314963\n",
      "Train Epoch: 8 [320/2566 (12%)]\tLoss: 0.780244\n",
      "Train Epoch: 8 [360/2566 (14%)]\tLoss: 0.655886\n",
      "Train Epoch: 8 [400/2566 (16%)]\tLoss: 0.741476\n",
      "Train Epoch: 8 [440/2566 (17%)]\tLoss: 0.881238\n",
      "Train Epoch: 8 [480/2566 (19%)]\tLoss: 1.207303\n",
      "Train Epoch: 8 [520/2566 (20%)]\tLoss: 1.048580\n",
      "Train Epoch: 8 [560/2566 (22%)]\tLoss: 0.992163\n",
      "Train Epoch: 8 [600/2566 (23%)]\tLoss: 0.786557\n",
      "Train Epoch: 8 [640/2566 (25%)]\tLoss: 0.973077\n",
      "Train Epoch: 8 [680/2566 (26%)]\tLoss: 1.061228\n",
      "Train Epoch: 8 [720/2566 (28%)]\tLoss: 1.060281\n",
      "Train Epoch: 8 [760/2566 (30%)]\tLoss: 1.100542\n",
      "Train Epoch: 8 [800/2566 (31%)]\tLoss: 0.886634\n",
      "Train Epoch: 8 [840/2566 (33%)]\tLoss: 1.028087\n",
      "Train Epoch: 8 [880/2566 (34%)]\tLoss: 0.986179\n",
      "Train Epoch: 8 [920/2566 (36%)]\tLoss: 0.929110\n",
      "Train Epoch: 8 [960/2566 (37%)]\tLoss: 0.680253\n",
      "Train Epoch: 8 [1000/2566 (39%)]\tLoss: 0.685993\n",
      "Train Epoch: 8 [1040/2566 (40%)]\tLoss: 0.971124\n",
      "Train Epoch: 8 [1080/2566 (42%)]\tLoss: 0.804856\n",
      "Train Epoch: 8 [1120/2566 (44%)]\tLoss: 0.722099\n",
      "Train Epoch: 8 [1160/2566 (45%)]\tLoss: 1.317343\n",
      "Train Epoch: 8 [1200/2566 (47%)]\tLoss: 1.012153\n",
      "Train Epoch: 8 [1240/2566 (48%)]\tLoss: 0.761191\n",
      "Train Epoch: 8 [1280/2566 (50%)]\tLoss: 0.854358\n",
      "Train Epoch: 8 [1320/2566 (51%)]\tLoss: 0.713131\n",
      "Train Epoch: 8 [1360/2566 (53%)]\tLoss: 1.542130\n",
      "Train Epoch: 8 [1400/2566 (55%)]\tLoss: 1.067583\n",
      "Train Epoch: 8 [1440/2566 (56%)]\tLoss: 0.850439\n",
      "Train Epoch: 8 [1480/2566 (58%)]\tLoss: 0.778247\n",
      "Train Epoch: 8 [1520/2566 (59%)]\tLoss: 1.092234\n",
      "Train Epoch: 8 [1560/2566 (61%)]\tLoss: 0.725275\n",
      "Train Epoch: 8 [1600/2566 (62%)]\tLoss: 0.844405\n",
      "Train Epoch: 8 [1640/2566 (64%)]\tLoss: 0.736423\n",
      "Train Epoch: 8 [1680/2566 (65%)]\tLoss: 0.852649\n",
      "Train Epoch: 8 [1720/2566 (67%)]\tLoss: 0.923843\n",
      "Train Epoch: 8 [1760/2566 (69%)]\tLoss: 0.730192\n",
      "Train Epoch: 8 [1800/2566 (70%)]\tLoss: 0.739344\n",
      "Train Epoch: 8 [1840/2566 (72%)]\tLoss: 0.967233\n",
      "Train Epoch: 8 [1880/2566 (73%)]\tLoss: 0.924780\n",
      "Train Epoch: 8 [1920/2566 (75%)]\tLoss: 0.670476\n",
      "Train Epoch: 8 [1960/2566 (76%)]\tLoss: 0.766637\n",
      "Train Epoch: 8 [2000/2566 (78%)]\tLoss: 0.681147\n",
      "Train Epoch: 8 [2040/2566 (79%)]\tLoss: 1.604170\n",
      "Train Epoch: 8 [2080/2566 (81%)]\tLoss: 0.619966\n",
      "Train Epoch: 8 [2120/2566 (83%)]\tLoss: 0.908217\n",
      "Train Epoch: 8 [2160/2566 (84%)]\tLoss: 1.167083\n",
      "Train Epoch: 8 [2200/2566 (86%)]\tLoss: 1.291196\n",
      "Train Epoch: 8 [2240/2566 (87%)]\tLoss: 0.908915\n",
      "Train Epoch: 8 [2280/2566 (89%)]\tLoss: 1.137255\n",
      "Train Epoch: 8 [2320/2566 (90%)]\tLoss: 0.848419\n",
      "Train Epoch: 8 [2360/2566 (92%)]\tLoss: 0.935053\n",
      "Train Epoch: 8 [2400/2566 (93%)]\tLoss: 0.709238\n",
      "Train Epoch: 8 [2440/2566 (95%)]\tLoss: 1.056658\n",
      "Train Epoch: 8 [2480/2566 (97%)]\tLoss: 0.871466\n",
      "Train Epoch: 8 [2520/2566 (98%)]\tLoss: 0.708149\n",
      "Train Epoch: 8 [2560/2566 (100%)]\tLoss: 1.235297\n",
      "epoch:8,loss:0.9274602989170039\n",
      "Train set: Average loss: 0.8363, Accuracy: 1868/2566 (73%)\n",
      "Val set: Average loss: 0.8322, Accuracy: 241/327 (74%)\n",
      "Train Epoch: 9 [40/2566 (2%)]\tLoss: 0.737489\n",
      "Train Epoch: 9 [80/2566 (3%)]\tLoss: 0.868179\n",
      "Train Epoch: 9 [120/2566 (5%)]\tLoss: 0.737109\n",
      "Train Epoch: 9 [160/2566 (6%)]\tLoss: 0.718042\n",
      "Train Epoch: 9 [200/2566 (8%)]\tLoss: 0.777226\n",
      "Train Epoch: 9 [240/2566 (9%)]\tLoss: 1.004173\n",
      "Train Epoch: 9 [280/2566 (11%)]\tLoss: 1.086990\n",
      "Train Epoch: 9 [320/2566 (12%)]\tLoss: 0.720724\n",
      "Train Epoch: 9 [360/2566 (14%)]\tLoss: 0.879577\n",
      "Train Epoch: 9 [400/2566 (16%)]\tLoss: 0.772281\n",
      "Train Epoch: 9 [440/2566 (17%)]\tLoss: 0.779425\n",
      "Train Epoch: 9 [480/2566 (19%)]\tLoss: 0.833517\n",
      "Train Epoch: 9 [520/2566 (20%)]\tLoss: 0.880477\n",
      "Train Epoch: 9 [560/2566 (22%)]\tLoss: 0.891547\n",
      "Train Epoch: 9 [600/2566 (23%)]\tLoss: 0.941642\n",
      "Train Epoch: 9 [640/2566 (25%)]\tLoss: 0.950974\n",
      "Train Epoch: 9 [680/2566 (26%)]\tLoss: 0.799856\n",
      "Train Epoch: 9 [720/2566 (28%)]\tLoss: 0.809071\n",
      "Train Epoch: 9 [760/2566 (30%)]\tLoss: 0.958023\n",
      "Train Epoch: 9 [800/2566 (31%)]\tLoss: 1.197426\n",
      "Train Epoch: 9 [840/2566 (33%)]\tLoss: 0.786209\n",
      "Train Epoch: 9 [880/2566 (34%)]\tLoss: 0.705392\n",
      "Train Epoch: 9 [920/2566 (36%)]\tLoss: 0.850416\n",
      "Train Epoch: 9 [960/2566 (37%)]\tLoss: 1.020893\n",
      "Train Epoch: 9 [1000/2566 (39%)]\tLoss: 1.025784\n",
      "Train Epoch: 9 [1040/2566 (40%)]\tLoss: 0.942222\n",
      "Train Epoch: 9 [1080/2566 (42%)]\tLoss: 1.135210\n",
      "Train Epoch: 9 [1120/2566 (44%)]\tLoss: 1.016681\n",
      "Train Epoch: 9 [1160/2566 (45%)]\tLoss: 0.852584\n",
      "Train Epoch: 9 [1200/2566 (47%)]\tLoss: 0.950920\n",
      "Train Epoch: 9 [1240/2566 (48%)]\tLoss: 0.934525\n",
      "Train Epoch: 9 [1280/2566 (50%)]\tLoss: 0.933389\n",
      "Train Epoch: 9 [1320/2566 (51%)]\tLoss: 0.720320\n",
      "Train Epoch: 9 [1360/2566 (53%)]\tLoss: 0.703809\n",
      "Train Epoch: 9 [1400/2566 (55%)]\tLoss: 0.765239\n",
      "Train Epoch: 9 [1440/2566 (56%)]\tLoss: 0.833992\n",
      "Train Epoch: 9 [1480/2566 (58%)]\tLoss: 1.128626\n",
      "Train Epoch: 9 [1520/2566 (59%)]\tLoss: 1.019424\n",
      "Train Epoch: 9 [1560/2566 (61%)]\tLoss: 0.812625\n",
      "Train Epoch: 9 [1600/2566 (62%)]\tLoss: 0.940185\n",
      "Train Epoch: 9 [1640/2566 (64%)]\tLoss: 1.344790\n",
      "Train Epoch: 9 [1680/2566 (65%)]\tLoss: 0.668402\n",
      "Train Epoch: 9 [1720/2566 (67%)]\tLoss: 1.641000\n",
      "Train Epoch: 9 [1760/2566 (69%)]\tLoss: 0.631290\n",
      "Train Epoch: 9 [1800/2566 (70%)]\tLoss: 0.821903\n",
      "Train Epoch: 9 [1840/2566 (72%)]\tLoss: 0.770692\n",
      "Train Epoch: 9 [1880/2566 (73%)]\tLoss: 0.578212\n",
      "Train Epoch: 9 [1920/2566 (75%)]\tLoss: 0.958158\n",
      "Train Epoch: 9 [1960/2566 (76%)]\tLoss: 0.667765\n",
      "Train Epoch: 9 [2000/2566 (78%)]\tLoss: 0.899569\n",
      "Train Epoch: 9 [2040/2566 (79%)]\tLoss: 0.636541\n",
      "Train Epoch: 9 [2080/2566 (81%)]\tLoss: 1.010202\n",
      "Train Epoch: 9 [2120/2566 (83%)]\tLoss: 0.613260\n",
      "Train Epoch: 9 [2160/2566 (84%)]\tLoss: 0.668873\n",
      "Train Epoch: 9 [2200/2566 (86%)]\tLoss: 0.635521\n",
      "Train Epoch: 9 [2240/2566 (87%)]\tLoss: 0.786864\n",
      "Train Epoch: 9 [2280/2566 (89%)]\tLoss: 0.589934\n",
      "Train Epoch: 9 [2320/2566 (90%)]\tLoss: 0.815963\n",
      "Train Epoch: 9 [2360/2566 (92%)]\tLoss: 1.048202\n",
      "Train Epoch: 9 [2400/2566 (93%)]\tLoss: 0.694898\n",
      "Train Epoch: 9 [2440/2566 (95%)]\tLoss: 1.416954\n",
      "Train Epoch: 9 [2480/2566 (97%)]\tLoss: 0.564537\n",
      "Train Epoch: 9 [2520/2566 (98%)]\tLoss: 1.073026\n",
      "Train Epoch: 9 [2560/2566 (100%)]\tLoss: 1.005154\n",
      "epoch:9,loss:0.9169876475200475\n",
      "Train set: Average loss: 0.8109, Accuracy: 1859/2566 (72%)\n",
      "Val set: Average loss: 0.8027, Accuracy: 242/327 (74%)\n",
      "Train Epoch: 10 [40/2566 (2%)]\tLoss: 0.631783\n",
      "Train Epoch: 10 [80/2566 (3%)]\tLoss: 0.863065\n",
      "Train Epoch: 10 [120/2566 (5%)]\tLoss: 1.156000\n",
      "Train Epoch: 10 [160/2566 (6%)]\tLoss: 1.004428\n",
      "Train Epoch: 10 [200/2566 (8%)]\tLoss: 1.103032\n",
      "Train Epoch: 10 [240/2566 (9%)]\tLoss: 0.890238\n",
      "Train Epoch: 10 [280/2566 (11%)]\tLoss: 0.993898\n",
      "Train Epoch: 10 [320/2566 (12%)]\tLoss: 0.746106\n",
      "Train Epoch: 10 [360/2566 (14%)]\tLoss: 1.066782\n",
      "Train Epoch: 10 [400/2566 (16%)]\tLoss: 1.056234\n",
      "Train Epoch: 10 [440/2566 (17%)]\tLoss: 0.996731\n",
      "Train Epoch: 10 [480/2566 (19%)]\tLoss: 0.926614\n",
      "Train Epoch: 10 [520/2566 (20%)]\tLoss: 0.665360\n",
      "Train Epoch: 10 [560/2566 (22%)]\tLoss: 0.783147\n",
      "Train Epoch: 10 [600/2566 (23%)]\tLoss: 1.045265\n",
      "Train Epoch: 10 [640/2566 (25%)]\tLoss: 1.770917\n",
      "Train Epoch: 10 [680/2566 (26%)]\tLoss: 0.535110\n",
      "Train Epoch: 10 [720/2566 (28%)]\tLoss: 0.621304\n",
      "Train Epoch: 10 [760/2566 (30%)]\tLoss: 0.649050\n",
      "Train Epoch: 10 [800/2566 (31%)]\tLoss: 0.983947\n",
      "Train Epoch: 10 [840/2566 (33%)]\tLoss: 0.778988\n",
      "Train Epoch: 10 [880/2566 (34%)]\tLoss: 0.751375\n",
      "Train Epoch: 10 [920/2566 (36%)]\tLoss: 0.606784\n",
      "Train Epoch: 10 [960/2566 (37%)]\tLoss: 0.696895\n",
      "Train Epoch: 10 [1000/2566 (39%)]\tLoss: 0.586059\n",
      "Train Epoch: 10 [1040/2566 (40%)]\tLoss: 0.783061\n",
      "Train Epoch: 10 [1080/2566 (42%)]\tLoss: 1.025787\n",
      "Train Epoch: 10 [1120/2566 (44%)]\tLoss: 0.644631\n",
      "Train Epoch: 10 [1160/2566 (45%)]\tLoss: 1.066675\n",
      "Train Epoch: 10 [1200/2566 (47%)]\tLoss: 0.862540\n",
      "Train Epoch: 10 [1240/2566 (48%)]\tLoss: 0.614416\n",
      "Train Epoch: 10 [1280/2566 (50%)]\tLoss: 0.820605\n",
      "Train Epoch: 10 [1320/2566 (51%)]\tLoss: 0.778222\n",
      "Train Epoch: 10 [1360/2566 (53%)]\tLoss: 0.725674\n",
      "Train Epoch: 10 [1400/2566 (55%)]\tLoss: 0.856257\n",
      "Train Epoch: 10 [1440/2566 (56%)]\tLoss: 1.094371\n",
      "Train Epoch: 10 [1480/2566 (58%)]\tLoss: 0.702467\n",
      "Train Epoch: 10 [1520/2566 (59%)]\tLoss: 0.983419\n",
      "Train Epoch: 10 [1560/2566 (61%)]\tLoss: 0.948140\n",
      "Train Epoch: 10 [1600/2566 (62%)]\tLoss: 0.662927\n",
      "Train Epoch: 10 [1640/2566 (64%)]\tLoss: 0.808460\n",
      "Train Epoch: 10 [1680/2566 (65%)]\tLoss: 0.864008\n",
      "Train Epoch: 10 [1720/2566 (67%)]\tLoss: 0.799015\n",
      "Train Epoch: 10 [1760/2566 (69%)]\tLoss: 0.563036\n",
      "Train Epoch: 10 [1800/2566 (70%)]\tLoss: 1.003323\n",
      "Train Epoch: 10 [1840/2566 (72%)]\tLoss: 0.749231\n",
      "Train Epoch: 10 [1880/2566 (73%)]\tLoss: 0.567969\n",
      "Train Epoch: 10 [1920/2566 (75%)]\tLoss: 0.792878\n",
      "Train Epoch: 10 [1960/2566 (76%)]\tLoss: 0.619057\n",
      "Train Epoch: 10 [2000/2566 (78%)]\tLoss: 0.648043\n",
      "Train Epoch: 10 [2040/2566 (79%)]\tLoss: 0.918538\n",
      "Train Epoch: 10 [2080/2566 (81%)]\tLoss: 0.795853\n",
      "Train Epoch: 10 [2120/2566 (83%)]\tLoss: 0.661891\n",
      "Train Epoch: 10 [2160/2566 (84%)]\tLoss: 0.639013\n",
      "Train Epoch: 10 [2200/2566 (86%)]\tLoss: 0.757154\n",
      "Train Epoch: 10 [2240/2566 (87%)]\tLoss: 0.848949\n",
      "Train Epoch: 10 [2280/2566 (89%)]\tLoss: 0.490430\n",
      "Train Epoch: 10 [2320/2566 (90%)]\tLoss: 0.801979\n",
      "Train Epoch: 10 [2360/2566 (92%)]\tLoss: 0.535735\n",
      "Train Epoch: 10 [2400/2566 (93%)]\tLoss: 0.588691\n",
      "Train Epoch: 10 [2440/2566 (95%)]\tLoss: 1.056887\n",
      "Train Epoch: 10 [2480/2566 (97%)]\tLoss: 0.927486\n",
      "Train Epoch: 10 [2520/2566 (98%)]\tLoss: 1.110890\n",
      "Train Epoch: 10 [2560/2566 (100%)]\tLoss: 0.728952\n",
      "epoch:10,loss:0.8603176494068074\n",
      "Train set: Average loss: 0.7746, Accuracy: 1878/2566 (73%)\n",
      "Val set: Average loss: 0.7719, Accuracy: 243/327 (74%)\n",
      "Train Epoch: 11 [40/2566 (2%)]\tLoss: 0.752481\n",
      "Train Epoch: 11 [80/2566 (3%)]\tLoss: 1.018035\n",
      "Train Epoch: 11 [120/2566 (5%)]\tLoss: 0.845355\n",
      "Train Epoch: 11 [160/2566 (6%)]\tLoss: 0.713512\n",
      "Train Epoch: 11 [200/2566 (8%)]\tLoss: 0.690365\n",
      "Train Epoch: 11 [240/2566 (9%)]\tLoss: 0.831374\n",
      "Train Epoch: 11 [280/2566 (11%)]\tLoss: 0.830434\n",
      "Train Epoch: 11 [320/2566 (12%)]\tLoss: 0.893941\n",
      "Train Epoch: 11 [360/2566 (14%)]\tLoss: 2.307866\n",
      "Train Epoch: 11 [400/2566 (16%)]\tLoss: 0.498630\n",
      "Train Epoch: 11 [440/2566 (17%)]\tLoss: 0.835836\n",
      "Train Epoch: 11 [480/2566 (19%)]\tLoss: 1.052591\n",
      "Train Epoch: 11 [520/2566 (20%)]\tLoss: 1.043113\n",
      "Train Epoch: 11 [560/2566 (22%)]\tLoss: 0.779427\n",
      "Train Epoch: 11 [600/2566 (23%)]\tLoss: 1.054463\n",
      "Train Epoch: 11 [640/2566 (25%)]\tLoss: 0.994517\n",
      "Train Epoch: 11 [680/2566 (26%)]\tLoss: 0.879734\n",
      "Train Epoch: 11 [720/2566 (28%)]\tLoss: 0.857286\n",
      "Train Epoch: 11 [760/2566 (30%)]\tLoss: 1.145033\n",
      "Train Epoch: 11 [800/2566 (31%)]\tLoss: 0.752471\n",
      "Train Epoch: 11 [840/2566 (33%)]\tLoss: 0.588642\n",
      "Train Epoch: 11 [880/2566 (34%)]\tLoss: 1.175327\n",
      "Train Epoch: 11 [920/2566 (36%)]\tLoss: 0.715251\n",
      "Train Epoch: 11 [960/2566 (37%)]\tLoss: 0.723011\n",
      "Train Epoch: 11 [1000/2566 (39%)]\tLoss: 0.745137\n",
      "Train Epoch: 11 [1040/2566 (40%)]\tLoss: 0.941210\n",
      "Train Epoch: 11 [1080/2566 (42%)]\tLoss: 0.428325\n",
      "Train Epoch: 11 [1120/2566 (44%)]\tLoss: 0.944893\n",
      "Train Epoch: 11 [1160/2566 (45%)]\tLoss: 0.869906\n",
      "Train Epoch: 11 [1200/2566 (47%)]\tLoss: 0.702313\n",
      "Train Epoch: 11 [1240/2566 (48%)]\tLoss: 0.751753\n",
      "Train Epoch: 11 [1280/2566 (50%)]\tLoss: 1.407846\n",
      "Train Epoch: 11 [1320/2566 (51%)]\tLoss: 0.714705\n",
      "Train Epoch: 11 [1360/2566 (53%)]\tLoss: 0.842995\n",
      "Train Epoch: 11 [1400/2566 (55%)]\tLoss: 0.851203\n",
      "Train Epoch: 11 [1440/2566 (56%)]\tLoss: 0.485277\n",
      "Train Epoch: 11 [1480/2566 (58%)]\tLoss: 0.806224\n",
      "Train Epoch: 11 [1520/2566 (59%)]\tLoss: 0.610795\n",
      "Train Epoch: 11 [1560/2566 (61%)]\tLoss: 1.007064\n",
      "Train Epoch: 11 [1600/2566 (62%)]\tLoss: 0.546691\n",
      "Train Epoch: 11 [1640/2566 (64%)]\tLoss: 0.605466\n",
      "Train Epoch: 11 [1680/2566 (65%)]\tLoss: 0.860456\n",
      "Train Epoch: 11 [1720/2566 (67%)]\tLoss: 0.957466\n",
      "Train Epoch: 11 [1760/2566 (69%)]\tLoss: 0.968590\n",
      "Train Epoch: 11 [1800/2566 (70%)]\tLoss: 0.833092\n",
      "Train Epoch: 11 [1840/2566 (72%)]\tLoss: 1.224508\n",
      "Train Epoch: 11 [1880/2566 (73%)]\tLoss: 0.528568\n",
      "Train Epoch: 11 [1920/2566 (75%)]\tLoss: 0.514558\n",
      "Train Epoch: 11 [1960/2566 (76%)]\tLoss: 0.714986\n",
      "Train Epoch: 11 [2000/2566 (78%)]\tLoss: 0.745481\n",
      "Train Epoch: 11 [2040/2566 (79%)]\tLoss: 1.006768\n",
      "Train Epoch: 11 [2080/2566 (81%)]\tLoss: 0.440240\n",
      "Train Epoch: 11 [2120/2566 (83%)]\tLoss: 1.094513\n",
      "Train Epoch: 11 [2160/2566 (84%)]\tLoss: 1.051022\n",
      "Train Epoch: 11 [2200/2566 (86%)]\tLoss: 0.775584\n",
      "Train Epoch: 11 [2240/2566 (87%)]\tLoss: 1.149928\n",
      "Train Epoch: 11 [2280/2566 (89%)]\tLoss: 0.629819\n",
      "Train Epoch: 11 [2320/2566 (90%)]\tLoss: 0.679213\n",
      "Train Epoch: 11 [2360/2566 (92%)]\tLoss: 1.360631\n",
      "Train Epoch: 11 [2400/2566 (93%)]\tLoss: 0.965386\n",
      "Train Epoch: 11 [2440/2566 (95%)]\tLoss: 0.525373\n",
      "Train Epoch: 11 [2480/2566 (97%)]\tLoss: 1.358267\n",
      "Train Epoch: 11 [2520/2566 (98%)]\tLoss: 0.548552\n",
      "Train Epoch: 11 [2560/2566 (100%)]\tLoss: 0.787118\n",
      "epoch:11,loss:0.8397495215555589\n",
      "Train set: Average loss: 0.7547, Accuracy: 1879/2566 (73%)\n",
      "Val set: Average loss: 0.7486, Accuracy: 243/327 (74%)\n",
      "Train Epoch: 12 [40/2566 (2%)]\tLoss: 1.067039\n",
      "Train Epoch: 12 [80/2566 (3%)]\tLoss: 1.126939\n",
      "Train Epoch: 12 [120/2566 (5%)]\tLoss: 0.758588\n",
      "Train Epoch: 12 [160/2566 (6%)]\tLoss: 0.754997\n",
      "Train Epoch: 12 [200/2566 (8%)]\tLoss: 0.514283\n",
      "Train Epoch: 12 [240/2566 (9%)]\tLoss: 0.979402\n",
      "Train Epoch: 12 [280/2566 (11%)]\tLoss: 0.592739\n",
      "Train Epoch: 12 [320/2566 (12%)]\tLoss: 0.720223\n",
      "Train Epoch: 12 [360/2566 (14%)]\tLoss: 1.016163\n",
      "Train Epoch: 12 [400/2566 (16%)]\tLoss: 0.962863\n",
      "Train Epoch: 12 [440/2566 (17%)]\tLoss: 0.748817\n",
      "Train Epoch: 12 [480/2566 (19%)]\tLoss: 0.652826\n",
      "Train Epoch: 12 [520/2566 (20%)]\tLoss: 1.149149\n",
      "Train Epoch: 12 [560/2566 (22%)]\tLoss: 1.074518\n",
      "Train Epoch: 12 [600/2566 (23%)]\tLoss: 0.841915\n",
      "Train Epoch: 12 [640/2566 (25%)]\tLoss: 1.219700\n",
      "Train Epoch: 12 [680/2566 (26%)]\tLoss: 0.749969\n",
      "Train Epoch: 12 [720/2566 (28%)]\tLoss: 0.754371\n",
      "Train Epoch: 12 [760/2566 (30%)]\tLoss: 0.899260\n",
      "Train Epoch: 12 [800/2566 (31%)]\tLoss: 0.714861\n",
      "Train Epoch: 12 [840/2566 (33%)]\tLoss: 0.760467\n",
      "Train Epoch: 12 [880/2566 (34%)]\tLoss: 1.175104\n",
      "Train Epoch: 12 [920/2566 (36%)]\tLoss: 1.133540\n",
      "Train Epoch: 12 [960/2566 (37%)]\tLoss: 0.753609\n",
      "Train Epoch: 12 [1000/2566 (39%)]\tLoss: 0.861238\n",
      "Train Epoch: 12 [1040/2566 (40%)]\tLoss: 0.709025\n",
      "Train Epoch: 12 [1080/2566 (42%)]\tLoss: 1.456939\n",
      "Train Epoch: 12 [1120/2566 (44%)]\tLoss: 0.822958\n",
      "Train Epoch: 12 [1160/2566 (45%)]\tLoss: 0.647359\n",
      "Train Epoch: 12 [1200/2566 (47%)]\tLoss: 0.695600\n",
      "Train Epoch: 12 [1240/2566 (48%)]\tLoss: 1.048152\n",
      "Train Epoch: 12 [1280/2566 (50%)]\tLoss: 0.841081\n",
      "Train Epoch: 12 [1320/2566 (51%)]\tLoss: 1.001155\n",
      "Train Epoch: 12 [1360/2566 (53%)]\tLoss: 0.531076\n",
      "Train Epoch: 12 [1400/2566 (55%)]\tLoss: 1.623496\n",
      "Train Epoch: 12 [1440/2566 (56%)]\tLoss: 0.603288\n",
      "Train Epoch: 12 [1480/2566 (58%)]\tLoss: 1.260954\n",
      "Train Epoch: 12 [1520/2566 (59%)]\tLoss: 0.680539\n",
      "Train Epoch: 12 [1560/2566 (61%)]\tLoss: 1.101283\n",
      "Train Epoch: 12 [1600/2566 (62%)]\tLoss: 0.481912\n",
      "Train Epoch: 12 [1640/2566 (64%)]\tLoss: 0.699918\n",
      "Train Epoch: 12 [1680/2566 (65%)]\tLoss: 0.622375\n",
      "Train Epoch: 12 [1720/2566 (67%)]\tLoss: 1.603244\n",
      "Train Epoch: 12 [1760/2566 (69%)]\tLoss: 0.958494\n",
      "Train Epoch: 12 [1800/2566 (70%)]\tLoss: 1.007538\n",
      "Train Epoch: 12 [1840/2566 (72%)]\tLoss: 1.434591\n",
      "Train Epoch: 12 [1880/2566 (73%)]\tLoss: 0.768342\n",
      "Train Epoch: 12 [1920/2566 (75%)]\tLoss: 0.524779\n",
      "Train Epoch: 12 [1960/2566 (76%)]\tLoss: 0.616293\n",
      "Train Epoch: 12 [2000/2566 (78%)]\tLoss: 0.868203\n",
      "Train Epoch: 12 [2040/2566 (79%)]\tLoss: 0.580036\n",
      "Train Epoch: 12 [2080/2566 (81%)]\tLoss: 0.665639\n",
      "Train Epoch: 12 [2120/2566 (83%)]\tLoss: 1.337532\n",
      "Train Epoch: 12 [2160/2566 (84%)]\tLoss: 0.954612\n",
      "Train Epoch: 12 [2200/2566 (86%)]\tLoss: 0.649619\n",
      "Train Epoch: 12 [2240/2566 (87%)]\tLoss: 0.864914\n",
      "Train Epoch: 12 [2280/2566 (89%)]\tLoss: 0.846645\n",
      "Train Epoch: 12 [2320/2566 (90%)]\tLoss: 1.040586\n",
      "Train Epoch: 12 [2360/2566 (92%)]\tLoss: 0.535345\n",
      "Train Epoch: 12 [2400/2566 (93%)]\tLoss: 0.784147\n",
      "Train Epoch: 12 [2440/2566 (95%)]\tLoss: 0.538879\n",
      "Train Epoch: 12 [2480/2566 (97%)]\tLoss: 0.754809\n",
      "Train Epoch: 12 [2520/2566 (98%)]\tLoss: 0.763745\n",
      "Train Epoch: 12 [2560/2566 (100%)]\tLoss: 0.635809\n",
      "epoch:12,loss:0.8152508316938751\n",
      "Train set: Average loss: 0.7479, Accuracy: 1899/2566 (74%)\n",
      "Val set: Average loss: 0.7437, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 13 [40/2566 (2%)]\tLoss: 0.989986\n",
      "Train Epoch: 13 [80/2566 (3%)]\tLoss: 0.593070\n",
      "Train Epoch: 13 [120/2566 (5%)]\tLoss: 1.169395\n",
      "Train Epoch: 13 [160/2566 (6%)]\tLoss: 0.928599\n",
      "Train Epoch: 13 [200/2566 (8%)]\tLoss: 0.892227\n",
      "Train Epoch: 13 [240/2566 (9%)]\tLoss: 0.369733\n",
      "Train Epoch: 13 [280/2566 (11%)]\tLoss: 0.770734\n",
      "Train Epoch: 13 [320/2566 (12%)]\tLoss: 0.935110\n",
      "Train Epoch: 13 [360/2566 (14%)]\tLoss: 0.772124\n",
      "Train Epoch: 13 [400/2566 (16%)]\tLoss: 0.825723\n",
      "Train Epoch: 13 [440/2566 (17%)]\tLoss: 0.625433\n",
      "Train Epoch: 13 [480/2566 (19%)]\tLoss: 0.435150\n",
      "Train Epoch: 13 [520/2566 (20%)]\tLoss: 0.918840\n",
      "Train Epoch: 13 [560/2566 (22%)]\tLoss: 0.724532\n",
      "Train Epoch: 13 [600/2566 (23%)]\tLoss: 0.538605\n",
      "Train Epoch: 13 [640/2566 (25%)]\tLoss: 0.618404\n",
      "Train Epoch: 13 [680/2566 (26%)]\tLoss: 1.577484\n",
      "Train Epoch: 13 [720/2566 (28%)]\tLoss: 0.826210\n",
      "Train Epoch: 13 [760/2566 (30%)]\tLoss: 0.677352\n",
      "Train Epoch: 13 [800/2566 (31%)]\tLoss: 0.591366\n",
      "Train Epoch: 13 [840/2566 (33%)]\tLoss: 1.474215\n",
      "Train Epoch: 13 [880/2566 (34%)]\tLoss: 0.817441\n",
      "Train Epoch: 13 [920/2566 (36%)]\tLoss: 0.647235\n",
      "Train Epoch: 13 [960/2566 (37%)]\tLoss: 0.768614\n",
      "Train Epoch: 13 [1000/2566 (39%)]\tLoss: 0.743337\n",
      "Train Epoch: 13 [1040/2566 (40%)]\tLoss: 0.797346\n",
      "Train Epoch: 13 [1080/2566 (42%)]\tLoss: 0.605711\n",
      "Train Epoch: 13 [1120/2566 (44%)]\tLoss: 0.857442\n",
      "Train Epoch: 13 [1160/2566 (45%)]\tLoss: 0.638813\n",
      "Train Epoch: 13 [1200/2566 (47%)]\tLoss: 1.050255\n",
      "Train Epoch: 13 [1240/2566 (48%)]\tLoss: 0.519725\n",
      "Train Epoch: 13 [1280/2566 (50%)]\tLoss: 0.483911\n",
      "Train Epoch: 13 [1320/2566 (51%)]\tLoss: 0.634797\n",
      "Train Epoch: 13 [1360/2566 (53%)]\tLoss: 0.458623\n",
      "Train Epoch: 13 [1400/2566 (55%)]\tLoss: 0.823847\n",
      "Train Epoch: 13 [1440/2566 (56%)]\tLoss: 0.733912\n",
      "Train Epoch: 13 [1480/2566 (58%)]\tLoss: 0.947534\n",
      "Train Epoch: 13 [1520/2566 (59%)]\tLoss: 0.553544\n",
      "Train Epoch: 13 [1560/2566 (61%)]\tLoss: 0.664442\n",
      "Train Epoch: 13 [1600/2566 (62%)]\tLoss: 0.473015\n",
      "Train Epoch: 13 [1640/2566 (64%)]\tLoss: 1.122207\n",
      "Train Epoch: 13 [1680/2566 (65%)]\tLoss: 0.843612\n",
      "Train Epoch: 13 [1720/2566 (67%)]\tLoss: 0.826522\n",
      "Train Epoch: 13 [1760/2566 (69%)]\tLoss: 0.616274\n",
      "Train Epoch: 13 [1800/2566 (70%)]\tLoss: 0.760243\n",
      "Train Epoch: 13 [1840/2566 (72%)]\tLoss: 0.599477\n",
      "Train Epoch: 13 [1880/2566 (73%)]\tLoss: 0.512630\n",
      "Train Epoch: 13 [1920/2566 (75%)]\tLoss: 1.471361\n",
      "Train Epoch: 13 [1960/2566 (76%)]\tLoss: 0.784097\n",
      "Train Epoch: 13 [2000/2566 (78%)]\tLoss: 0.673064\n",
      "Train Epoch: 13 [2040/2566 (79%)]\tLoss: 0.958105\n",
      "Train Epoch: 13 [2080/2566 (81%)]\tLoss: 1.009649\n",
      "Train Epoch: 13 [2120/2566 (83%)]\tLoss: 1.471205\n",
      "Train Epoch: 13 [2160/2566 (84%)]\tLoss: 0.949556\n",
      "Train Epoch: 13 [2200/2566 (86%)]\tLoss: 0.537879\n",
      "Train Epoch: 13 [2240/2566 (87%)]\tLoss: 0.591022\n",
      "Train Epoch: 13 [2280/2566 (89%)]\tLoss: 0.427574\n",
      "Train Epoch: 13 [2320/2566 (90%)]\tLoss: 0.789508\n",
      "Train Epoch: 13 [2360/2566 (92%)]\tLoss: 0.694016\n",
      "Train Epoch: 13 [2400/2566 (93%)]\tLoss: 0.479547\n",
      "Train Epoch: 13 [2440/2566 (95%)]\tLoss: 0.979952\n",
      "Train Epoch: 13 [2480/2566 (97%)]\tLoss: 0.638358\n",
      "Train Epoch: 13 [2520/2566 (98%)]\tLoss: 0.856846\n",
      "Train Epoch: 13 [2560/2566 (100%)]\tLoss: 0.556889\n",
      "epoch:13,loss:0.8034064092925776\n",
      "Train set: Average loss: 0.7157, Accuracy: 1899/2566 (74%)\n",
      "Val set: Average loss: 0.7180, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 14 [40/2566 (2%)]\tLoss: 0.756838\n",
      "Train Epoch: 14 [80/2566 (3%)]\tLoss: 0.944109\n",
      "Train Epoch: 14 [120/2566 (5%)]\tLoss: 0.657260\n",
      "Train Epoch: 14 [160/2566 (6%)]\tLoss: 0.938136\n",
      "Train Epoch: 14 [200/2566 (8%)]\tLoss: 0.548713\n",
      "Train Epoch: 14 [240/2566 (9%)]\tLoss: 0.931264\n",
      "Train Epoch: 14 [280/2566 (11%)]\tLoss: 0.642434\n",
      "Train Epoch: 14 [320/2566 (12%)]\tLoss: 0.496129\n",
      "Train Epoch: 14 [360/2566 (14%)]\tLoss: 0.762048\n",
      "Train Epoch: 14 [400/2566 (16%)]\tLoss: 0.681950\n",
      "Train Epoch: 14 [440/2566 (17%)]\tLoss: 0.807217\n",
      "Train Epoch: 14 [480/2566 (19%)]\tLoss: 0.755181\n",
      "Train Epoch: 14 [520/2566 (20%)]\tLoss: 0.385778\n",
      "Train Epoch: 14 [560/2566 (22%)]\tLoss: 0.614988\n",
      "Train Epoch: 14 [600/2566 (23%)]\tLoss: 0.968445\n",
      "Train Epoch: 14 [640/2566 (25%)]\tLoss: 0.637624\n",
      "Train Epoch: 14 [680/2566 (26%)]\tLoss: 0.953802\n",
      "Train Epoch: 14 [720/2566 (28%)]\tLoss: 0.935345\n",
      "Train Epoch: 14 [760/2566 (30%)]\tLoss: 1.109917\n",
      "Train Epoch: 14 [800/2566 (31%)]\tLoss: 0.663104\n",
      "Train Epoch: 14 [840/2566 (33%)]\tLoss: 0.477547\n",
      "Train Epoch: 14 [880/2566 (34%)]\tLoss: 0.656707\n",
      "Train Epoch: 14 [920/2566 (36%)]\tLoss: 0.561948\n",
      "Train Epoch: 14 [960/2566 (37%)]\tLoss: 0.533290\n",
      "Train Epoch: 14 [1000/2566 (39%)]\tLoss: 0.687369\n",
      "Train Epoch: 14 [1040/2566 (40%)]\tLoss: 0.798587\n",
      "Train Epoch: 14 [1080/2566 (42%)]\tLoss: 1.563246\n",
      "Train Epoch: 14 [1120/2566 (44%)]\tLoss: 0.763650\n",
      "Train Epoch: 14 [1160/2566 (45%)]\tLoss: 0.739054\n",
      "Train Epoch: 14 [1200/2566 (47%)]\tLoss: 1.432750\n",
      "Train Epoch: 14 [1240/2566 (48%)]\tLoss: 0.620101\n",
      "Train Epoch: 14 [1280/2566 (50%)]\tLoss: 0.801003\n",
      "Train Epoch: 14 [1320/2566 (51%)]\tLoss: 1.305329\n",
      "Train Epoch: 14 [1360/2566 (53%)]\tLoss: 1.738351\n",
      "Train Epoch: 14 [1400/2566 (55%)]\tLoss: 0.922244\n",
      "Train Epoch: 14 [1440/2566 (56%)]\tLoss: 0.398214\n",
      "Train Epoch: 14 [1480/2566 (58%)]\tLoss: 0.718471\n",
      "Train Epoch: 14 [1520/2566 (59%)]\tLoss: 1.090891\n",
      "Train Epoch: 14 [1560/2566 (61%)]\tLoss: 0.503268\n",
      "Train Epoch: 14 [1600/2566 (62%)]\tLoss: 0.697820\n",
      "Train Epoch: 14 [1640/2566 (64%)]\tLoss: 0.588812\n",
      "Train Epoch: 14 [1680/2566 (65%)]\tLoss: 0.795880\n",
      "Train Epoch: 14 [1720/2566 (67%)]\tLoss: 0.783708\n",
      "Train Epoch: 14 [1760/2566 (69%)]\tLoss: 0.670274\n",
      "Train Epoch: 14 [1800/2566 (70%)]\tLoss: 0.612814\n",
      "Train Epoch: 14 [1840/2566 (72%)]\tLoss: 0.330918\n",
      "Train Epoch: 14 [1880/2566 (73%)]\tLoss: 0.673800\n",
      "Train Epoch: 14 [1920/2566 (75%)]\tLoss: 0.493885\n",
      "Train Epoch: 14 [1960/2566 (76%)]\tLoss: 0.930756\n",
      "Train Epoch: 14 [2000/2566 (78%)]\tLoss: 0.597645\n",
      "Train Epoch: 14 [2040/2566 (79%)]\tLoss: 0.459911\n",
      "Train Epoch: 14 [2080/2566 (81%)]\tLoss: 0.807190\n",
      "Train Epoch: 14 [2120/2566 (83%)]\tLoss: 0.632198\n",
      "Train Epoch: 14 [2160/2566 (84%)]\tLoss: 0.767295\n",
      "Train Epoch: 14 [2200/2566 (86%)]\tLoss: 0.799575\n",
      "Train Epoch: 14 [2240/2566 (87%)]\tLoss: 0.686261\n",
      "Train Epoch: 14 [2280/2566 (89%)]\tLoss: 0.758492\n",
      "Train Epoch: 14 [2320/2566 (90%)]\tLoss: 1.024550\n",
      "Train Epoch: 14 [2360/2566 (92%)]\tLoss: 0.839291\n",
      "Train Epoch: 14 [2400/2566 (93%)]\tLoss: 1.555931\n",
      "Train Epoch: 14 [2440/2566 (95%)]\tLoss: 1.195712\n",
      "Train Epoch: 14 [2480/2566 (97%)]\tLoss: 0.849962\n",
      "Train Epoch: 14 [2520/2566 (98%)]\tLoss: 0.663343\n",
      "Train Epoch: 14 [2560/2566 (100%)]\tLoss: 0.981709\n",
      "epoch:14,loss:0.802664833276814\n",
      "Train set: Average loss: 0.7063, Accuracy: 1903/2566 (74%)\n",
      "Val set: Average loss: 0.7162, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 15 [40/2566 (2%)]\tLoss: 1.072410\n",
      "Train Epoch: 15 [80/2566 (3%)]\tLoss: 1.230408\n",
      "Train Epoch: 15 [120/2566 (5%)]\tLoss: 0.757962\n",
      "Train Epoch: 15 [160/2566 (6%)]\tLoss: 0.940724\n",
      "Train Epoch: 15 [200/2566 (8%)]\tLoss: 0.800454\n",
      "Train Epoch: 15 [240/2566 (9%)]\tLoss: 0.779820\n",
      "Train Epoch: 15 [280/2566 (11%)]\tLoss: 0.587689\n",
      "Train Epoch: 15 [320/2566 (12%)]\tLoss: 0.951368\n",
      "Train Epoch: 15 [360/2566 (14%)]\tLoss: 0.668781\n",
      "Train Epoch: 15 [400/2566 (16%)]\tLoss: 0.521006\n",
      "Train Epoch: 15 [440/2566 (17%)]\tLoss: 0.853071\n",
      "Train Epoch: 15 [480/2566 (19%)]\tLoss: 0.827578\n",
      "Train Epoch: 15 [520/2566 (20%)]\tLoss: 0.639136\n",
      "Train Epoch: 15 [560/2566 (22%)]\tLoss: 0.656944\n",
      "Train Epoch: 15 [600/2566 (23%)]\tLoss: 0.496776\n",
      "Train Epoch: 15 [640/2566 (25%)]\tLoss: 0.388714\n",
      "Train Epoch: 15 [680/2566 (26%)]\tLoss: 1.011504\n",
      "Train Epoch: 15 [720/2566 (28%)]\tLoss: 1.241840\n",
      "Train Epoch: 15 [760/2566 (30%)]\tLoss: 1.075726\n",
      "Train Epoch: 15 [800/2566 (31%)]\tLoss: 0.617018\n",
      "Train Epoch: 15 [840/2566 (33%)]\tLoss: 0.474620\n",
      "Train Epoch: 15 [880/2566 (34%)]\tLoss: 0.897717\n",
      "Train Epoch: 15 [920/2566 (36%)]\tLoss: 0.837227\n",
      "Train Epoch: 15 [960/2566 (37%)]\tLoss: 0.692096\n",
      "Train Epoch: 15 [1000/2566 (39%)]\tLoss: 0.659671\n",
      "Train Epoch: 15 [1040/2566 (40%)]\tLoss: 0.857181\n",
      "Train Epoch: 15 [1080/2566 (42%)]\tLoss: 0.768351\n",
      "Train Epoch: 15 [1120/2566 (44%)]\tLoss: 0.677449\n",
      "Train Epoch: 15 [1160/2566 (45%)]\tLoss: 0.756334\n",
      "Train Epoch: 15 [1200/2566 (47%)]\tLoss: 0.944892\n",
      "Train Epoch: 15 [1240/2566 (48%)]\tLoss: 0.727754\n",
      "Train Epoch: 15 [1280/2566 (50%)]\tLoss: 0.944307\n",
      "Train Epoch: 15 [1320/2566 (51%)]\tLoss: 0.605290\n",
      "Train Epoch: 15 [1360/2566 (53%)]\tLoss: 0.465788\n",
      "Train Epoch: 15 [1400/2566 (55%)]\tLoss: 0.639626\n",
      "Train Epoch: 15 [1440/2566 (56%)]\tLoss: 0.624588\n",
      "Train Epoch: 15 [1480/2566 (58%)]\tLoss: 0.773626\n",
      "Train Epoch: 15 [1520/2566 (59%)]\tLoss: 0.928599\n",
      "Train Epoch: 15 [1560/2566 (61%)]\tLoss: 0.819518\n",
      "Train Epoch: 15 [1600/2566 (62%)]\tLoss: 1.733173\n",
      "Train Epoch: 15 [1640/2566 (64%)]\tLoss: 0.686654\n",
      "Train Epoch: 15 [1680/2566 (65%)]\tLoss: 0.680840\n",
      "Train Epoch: 15 [1720/2566 (67%)]\tLoss: 1.132733\n",
      "Train Epoch: 15 [1760/2566 (69%)]\tLoss: 0.453223\n",
      "Train Epoch: 15 [1800/2566 (70%)]\tLoss: 0.695623\n",
      "Train Epoch: 15 [1840/2566 (72%)]\tLoss: 0.709892\n",
      "Train Epoch: 15 [1880/2566 (73%)]\tLoss: 0.484032\n",
      "Train Epoch: 15 [1920/2566 (75%)]\tLoss: 0.742189\n",
      "Train Epoch: 15 [1960/2566 (76%)]\tLoss: 0.338777\n",
      "Train Epoch: 15 [2000/2566 (78%)]\tLoss: 0.587086\n",
      "Train Epoch: 15 [2040/2566 (79%)]\tLoss: 0.885383\n",
      "Train Epoch: 15 [2080/2566 (81%)]\tLoss: 0.662673\n",
      "Train Epoch: 15 [2120/2566 (83%)]\tLoss: 0.465861\n",
      "Train Epoch: 15 [2160/2566 (84%)]\tLoss: 0.652755\n",
      "Train Epoch: 15 [2200/2566 (86%)]\tLoss: 1.150377\n",
      "Train Epoch: 15 [2240/2566 (87%)]\tLoss: 0.512363\n",
      "Train Epoch: 15 [2280/2566 (89%)]\tLoss: 1.057664\n",
      "Train Epoch: 15 [2320/2566 (90%)]\tLoss: 0.588716\n",
      "Train Epoch: 15 [2360/2566 (92%)]\tLoss: 0.767100\n",
      "Train Epoch: 15 [2400/2566 (93%)]\tLoss: 0.813855\n",
      "Train Epoch: 15 [2440/2566 (95%)]\tLoss: 0.625524\n",
      "Train Epoch: 15 [2480/2566 (97%)]\tLoss: 0.655472\n",
      "Train Epoch: 15 [2520/2566 (98%)]\tLoss: 0.518865\n",
      "Train Epoch: 15 [2560/2566 (100%)]\tLoss: 0.665832\n",
      "epoch:15,loss:0.7700279195360676\n",
      "Train set: Average loss: 0.6851, Accuracy: 1905/2566 (74%)\n",
      "Val set: Average loss: 0.6974, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 16 [40/2566 (2%)]\tLoss: 1.209230\n",
      "Train Epoch: 16 [80/2566 (3%)]\tLoss: 0.699333\n",
      "Train Epoch: 16 [120/2566 (5%)]\tLoss: 1.070496\n",
      "Train Epoch: 16 [160/2566 (6%)]\tLoss: 1.122668\n",
      "Train Epoch: 16 [200/2566 (8%)]\tLoss: 0.852303\n",
      "Train Epoch: 16 [240/2566 (9%)]\tLoss: 1.135350\n",
      "Train Epoch: 16 [280/2566 (11%)]\tLoss: 0.800005\n",
      "Train Epoch: 16 [320/2566 (12%)]\tLoss: 0.758437\n",
      "Train Epoch: 16 [360/2566 (14%)]\tLoss: 0.723089\n",
      "Train Epoch: 16 [400/2566 (16%)]\tLoss: 0.617799\n",
      "Train Epoch: 16 [440/2566 (17%)]\tLoss: 0.774680\n",
      "Train Epoch: 16 [480/2566 (19%)]\tLoss: 0.982710\n",
      "Train Epoch: 16 [520/2566 (20%)]\tLoss: 1.548581\n",
      "Train Epoch: 16 [560/2566 (22%)]\tLoss: 1.023430\n",
      "Train Epoch: 16 [600/2566 (23%)]\tLoss: 1.169755\n",
      "Train Epoch: 16 [640/2566 (25%)]\tLoss: 0.629574\n",
      "Train Epoch: 16 [680/2566 (26%)]\tLoss: 0.514474\n",
      "Train Epoch: 16 [720/2566 (28%)]\tLoss: 0.791133\n",
      "Train Epoch: 16 [760/2566 (30%)]\tLoss: 0.622463\n",
      "Train Epoch: 16 [800/2566 (31%)]\tLoss: 1.440190\n",
      "Train Epoch: 16 [840/2566 (33%)]\tLoss: 0.585510\n",
      "Train Epoch: 16 [880/2566 (34%)]\tLoss: 0.784976\n",
      "Train Epoch: 16 [920/2566 (36%)]\tLoss: 1.065627\n",
      "Train Epoch: 16 [960/2566 (37%)]\tLoss: 0.415813\n",
      "Train Epoch: 16 [1000/2566 (39%)]\tLoss: 0.958395\n",
      "Train Epoch: 16 [1040/2566 (40%)]\tLoss: 0.887159\n",
      "Train Epoch: 16 [1080/2566 (42%)]\tLoss: 0.432611\n",
      "Train Epoch: 16 [1120/2566 (44%)]\tLoss: 0.864192\n",
      "Train Epoch: 16 [1160/2566 (45%)]\tLoss: 0.787727\n",
      "Train Epoch: 16 [1200/2566 (47%)]\tLoss: 0.506413\n",
      "Train Epoch: 16 [1240/2566 (48%)]\tLoss: 0.991266\n",
      "Train Epoch: 16 [1280/2566 (50%)]\tLoss: 0.309196\n",
      "Train Epoch: 16 [1320/2566 (51%)]\tLoss: 1.082178\n",
      "Train Epoch: 16 [1360/2566 (53%)]\tLoss: 0.593302\n",
      "Train Epoch: 16 [1400/2566 (55%)]\tLoss: 1.020268\n",
      "Train Epoch: 16 [1440/2566 (56%)]\tLoss: 0.512793\n",
      "Train Epoch: 16 [1480/2566 (58%)]\tLoss: 0.843339\n",
      "Train Epoch: 16 [1520/2566 (59%)]\tLoss: 0.526397\n",
      "Train Epoch: 16 [1560/2566 (61%)]\tLoss: 1.717958\n",
      "Train Epoch: 16 [1600/2566 (62%)]\tLoss: 0.628401\n",
      "Train Epoch: 16 [1640/2566 (64%)]\tLoss: 0.666463\n",
      "Train Epoch: 16 [1680/2566 (65%)]\tLoss: 0.566395\n",
      "Train Epoch: 16 [1720/2566 (67%)]\tLoss: 0.936839\n",
      "Train Epoch: 16 [1760/2566 (69%)]\tLoss: 0.466381\n",
      "Train Epoch: 16 [1800/2566 (70%)]\tLoss: 0.671833\n",
      "Train Epoch: 16 [1840/2566 (72%)]\tLoss: 1.131265\n",
      "Train Epoch: 16 [1880/2566 (73%)]\tLoss: 0.342315\n",
      "Train Epoch: 16 [1920/2566 (75%)]\tLoss: 0.815319\n",
      "Train Epoch: 16 [1960/2566 (76%)]\tLoss: 0.759929\n",
      "Train Epoch: 16 [2000/2566 (78%)]\tLoss: 0.924379\n",
      "Train Epoch: 16 [2040/2566 (79%)]\tLoss: 0.710855\n",
      "Train Epoch: 16 [2080/2566 (81%)]\tLoss: 0.909674\n",
      "Train Epoch: 16 [2120/2566 (83%)]\tLoss: 0.582641\n",
      "Train Epoch: 16 [2160/2566 (84%)]\tLoss: 0.789926\n",
      "Train Epoch: 16 [2200/2566 (86%)]\tLoss: 0.638282\n",
      "Train Epoch: 16 [2240/2566 (87%)]\tLoss: 0.739910\n",
      "Train Epoch: 16 [2280/2566 (89%)]\tLoss: 1.362192\n",
      "Train Epoch: 16 [2320/2566 (90%)]\tLoss: 1.056462\n",
      "Train Epoch: 16 [2360/2566 (92%)]\tLoss: 0.855612\n",
      "Train Epoch: 16 [2400/2566 (93%)]\tLoss: 0.613083\n",
      "Train Epoch: 16 [2440/2566 (95%)]\tLoss: 1.018284\n",
      "Train Epoch: 16 [2480/2566 (97%)]\tLoss: 0.421290\n",
      "Train Epoch: 16 [2520/2566 (98%)]\tLoss: 0.777892\n",
      "Train Epoch: 16 [2560/2566 (100%)]\tLoss: 0.995914\n",
      "epoch:16,loss:0.7670194687687348\n",
      "Train set: Average loss: 0.6749, Accuracy: 1906/2566 (74%)\n",
      "Val set: Average loss: 0.6867, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 17 [40/2566 (2%)]\tLoss: 0.503260\n",
      "Train Epoch: 17 [80/2566 (3%)]\tLoss: 1.151557\n",
      "Train Epoch: 17 [120/2566 (5%)]\tLoss: 1.585698\n",
      "Train Epoch: 17 [160/2566 (6%)]\tLoss: 0.629763\n",
      "Train Epoch: 17 [200/2566 (8%)]\tLoss: 0.444820\n",
      "Train Epoch: 17 [240/2566 (9%)]\tLoss: 0.899338\n",
      "Train Epoch: 17 [280/2566 (11%)]\tLoss: 0.540408\n",
      "Train Epoch: 17 [320/2566 (12%)]\tLoss: 1.172946\n",
      "Train Epoch: 17 [360/2566 (14%)]\tLoss: 1.364768\n",
      "Train Epoch: 17 [400/2566 (16%)]\tLoss: 0.370677\n",
      "Train Epoch: 17 [440/2566 (17%)]\tLoss: 1.305290\n",
      "Train Epoch: 17 [480/2566 (19%)]\tLoss: 0.718329\n",
      "Train Epoch: 17 [520/2566 (20%)]\tLoss: 0.518920\n",
      "Train Epoch: 17 [560/2566 (22%)]\tLoss: 0.998278\n",
      "Train Epoch: 17 [600/2566 (23%)]\tLoss: 0.747057\n",
      "Train Epoch: 17 [640/2566 (25%)]\tLoss: 1.018273\n",
      "Train Epoch: 17 [680/2566 (26%)]\tLoss: 0.782424\n",
      "Train Epoch: 17 [720/2566 (28%)]\tLoss: 0.580633\n",
      "Train Epoch: 17 [760/2566 (30%)]\tLoss: 0.459992\n",
      "Train Epoch: 17 [800/2566 (31%)]\tLoss: 0.473531\n",
      "Train Epoch: 17 [840/2566 (33%)]\tLoss: 1.151191\n",
      "Train Epoch: 17 [880/2566 (34%)]\tLoss: 0.462479\n",
      "Train Epoch: 17 [920/2566 (36%)]\tLoss: 0.684661\n",
      "Train Epoch: 17 [960/2566 (37%)]\tLoss: 1.017314\n",
      "Train Epoch: 17 [1000/2566 (39%)]\tLoss: 1.033438\n",
      "Train Epoch: 17 [1040/2566 (40%)]\tLoss: 0.377390\n",
      "Train Epoch: 17 [1080/2566 (42%)]\tLoss: 0.601271\n",
      "Train Epoch: 17 [1120/2566 (44%)]\tLoss: 0.462257\n",
      "Train Epoch: 17 [1160/2566 (45%)]\tLoss: 0.856278\n",
      "Train Epoch: 17 [1200/2566 (47%)]\tLoss: 0.558962\n",
      "Train Epoch: 17 [1240/2566 (48%)]\tLoss: 0.698943\n",
      "Train Epoch: 17 [1280/2566 (50%)]\tLoss: 0.861995\n",
      "Train Epoch: 17 [1320/2566 (51%)]\tLoss: 0.316191\n",
      "Train Epoch: 17 [1360/2566 (53%)]\tLoss: 0.586882\n",
      "Train Epoch: 17 [1400/2566 (55%)]\tLoss: 1.253329\n",
      "Train Epoch: 17 [1440/2566 (56%)]\tLoss: 1.400969\n",
      "Train Epoch: 17 [1480/2566 (58%)]\tLoss: 0.968276\n",
      "Train Epoch: 17 [1520/2566 (59%)]\tLoss: 0.772041\n",
      "Train Epoch: 17 [1560/2566 (61%)]\tLoss: 0.593925\n",
      "Train Epoch: 17 [1600/2566 (62%)]\tLoss: 0.658822\n",
      "Train Epoch: 17 [1640/2566 (64%)]\tLoss: 0.651355\n",
      "Train Epoch: 17 [1680/2566 (65%)]\tLoss: 0.414736\n",
      "Train Epoch: 17 [1720/2566 (67%)]\tLoss: 0.810276\n",
      "Train Epoch: 17 [1760/2566 (69%)]\tLoss: 0.869238\n",
      "Train Epoch: 17 [1800/2566 (70%)]\tLoss: 1.173178\n",
      "Train Epoch: 17 [1840/2566 (72%)]\tLoss: 0.649431\n",
      "Train Epoch: 17 [1880/2566 (73%)]\tLoss: 0.868936\n",
      "Train Epoch: 17 [1920/2566 (75%)]\tLoss: 0.648309\n",
      "Train Epoch: 17 [1960/2566 (76%)]\tLoss: 0.830799\n",
      "Train Epoch: 17 [2000/2566 (78%)]\tLoss: 0.414951\n",
      "Train Epoch: 17 [2040/2566 (79%)]\tLoss: 0.751725\n",
      "Train Epoch: 17 [2080/2566 (81%)]\tLoss: 0.939645\n",
      "Train Epoch: 17 [2120/2566 (83%)]\tLoss: 0.745445\n",
      "Train Epoch: 17 [2160/2566 (84%)]\tLoss: 0.852120\n",
      "Train Epoch: 17 [2200/2566 (86%)]\tLoss: 1.077776\n",
      "Train Epoch: 17 [2240/2566 (87%)]\tLoss: 0.638633\n",
      "Train Epoch: 17 [2280/2566 (89%)]\tLoss: 0.929723\n",
      "Train Epoch: 17 [2320/2566 (90%)]\tLoss: 0.858595\n",
      "Train Epoch: 17 [2360/2566 (92%)]\tLoss: 0.589647\n",
      "Train Epoch: 17 [2400/2566 (93%)]\tLoss: 0.959811\n",
      "Train Epoch: 17 [2440/2566 (95%)]\tLoss: 0.575560\n",
      "Train Epoch: 17 [2480/2566 (97%)]\tLoss: 0.895646\n",
      "Train Epoch: 17 [2520/2566 (98%)]\tLoss: 0.939589\n",
      "Train Epoch: 17 [2560/2566 (100%)]\tLoss: 0.451691\n",
      "epoch:17,loss:0.748430158118964\n",
      "Train set: Average loss: 0.6681, Accuracy: 1908/2566 (74%)\n",
      "Val set: Average loss: 0.6848, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 18 [40/2566 (2%)]\tLoss: 1.011992\n",
      "Train Epoch: 18 [80/2566 (3%)]\tLoss: 0.477396\n",
      "Train Epoch: 18 [120/2566 (5%)]\tLoss: 0.415246\n",
      "Train Epoch: 18 [160/2566 (6%)]\tLoss: 0.253694\n",
      "Train Epoch: 18 [200/2566 (8%)]\tLoss: 0.430117\n",
      "Train Epoch: 18 [240/2566 (9%)]\tLoss: 0.788678\n",
      "Train Epoch: 18 [280/2566 (11%)]\tLoss: 0.370887\n",
      "Train Epoch: 18 [320/2566 (12%)]\tLoss: 0.608227\n",
      "Train Epoch: 18 [360/2566 (14%)]\tLoss: 0.712056\n",
      "Train Epoch: 18 [400/2566 (16%)]\tLoss: 0.427018\n",
      "Train Epoch: 18 [440/2566 (17%)]\tLoss: 0.856667\n",
      "Train Epoch: 18 [480/2566 (19%)]\tLoss: 0.794809\n",
      "Train Epoch: 18 [520/2566 (20%)]\tLoss: 0.547303\n",
      "Train Epoch: 18 [560/2566 (22%)]\tLoss: 0.605169\n",
      "Train Epoch: 18 [600/2566 (23%)]\tLoss: 0.356057\n",
      "Train Epoch: 18 [640/2566 (25%)]\tLoss: 0.841864\n",
      "Train Epoch: 18 [680/2566 (26%)]\tLoss: 0.532707\n",
      "Train Epoch: 18 [720/2566 (28%)]\tLoss: 0.917807\n",
      "Train Epoch: 18 [760/2566 (30%)]\tLoss: 1.115715\n",
      "Train Epoch: 18 [800/2566 (31%)]\tLoss: 0.358391\n",
      "Train Epoch: 18 [840/2566 (33%)]\tLoss: 0.798595\n",
      "Train Epoch: 18 [880/2566 (34%)]\tLoss: 0.560019\n",
      "Train Epoch: 18 [920/2566 (36%)]\tLoss: 0.835610\n",
      "Train Epoch: 18 [960/2566 (37%)]\tLoss: 0.578741\n",
      "Train Epoch: 18 [1000/2566 (39%)]\tLoss: 0.546300\n",
      "Train Epoch: 18 [1040/2566 (40%)]\tLoss: 0.736096\n",
      "Train Epoch: 18 [1080/2566 (42%)]\tLoss: 0.369612\n",
      "Train Epoch: 18 [1120/2566 (44%)]\tLoss: 0.483453\n",
      "Train Epoch: 18 [1160/2566 (45%)]\tLoss: 0.626822\n",
      "Train Epoch: 18 [1200/2566 (47%)]\tLoss: 0.412650\n",
      "Train Epoch: 18 [1240/2566 (48%)]\tLoss: 0.735890\n",
      "Train Epoch: 18 [1280/2566 (50%)]\tLoss: 0.891017\n",
      "Train Epoch: 18 [1320/2566 (51%)]\tLoss: 0.229352\n",
      "Train Epoch: 18 [1360/2566 (53%)]\tLoss: 0.834762\n",
      "Train Epoch: 18 [1400/2566 (55%)]\tLoss: 0.828080\n",
      "Train Epoch: 18 [1440/2566 (56%)]\tLoss: 0.680653\n",
      "Train Epoch: 18 [1480/2566 (58%)]\tLoss: 0.956701\n",
      "Train Epoch: 18 [1520/2566 (59%)]\tLoss: 1.077607\n",
      "Train Epoch: 18 [1560/2566 (61%)]\tLoss: 1.347587\n",
      "Train Epoch: 18 [1600/2566 (62%)]\tLoss: 0.522748\n",
      "Train Epoch: 18 [1640/2566 (64%)]\tLoss: 0.964457\n",
      "Train Epoch: 18 [1680/2566 (65%)]\tLoss: 0.803857\n",
      "Train Epoch: 18 [1720/2566 (67%)]\tLoss: 0.265037\n",
      "Train Epoch: 18 [1760/2566 (69%)]\tLoss: 0.761175\n",
      "Train Epoch: 18 [1800/2566 (70%)]\tLoss: 0.631498\n",
      "Train Epoch: 18 [1840/2566 (72%)]\tLoss: 0.712537\n",
      "Train Epoch: 18 [1880/2566 (73%)]\tLoss: 0.746591\n",
      "Train Epoch: 18 [1920/2566 (75%)]\tLoss: 0.824146\n",
      "Train Epoch: 18 [1960/2566 (76%)]\tLoss: 1.242652\n",
      "Train Epoch: 18 [2000/2566 (78%)]\tLoss: 1.012327\n",
      "Train Epoch: 18 [2040/2566 (79%)]\tLoss: 1.818394\n",
      "Train Epoch: 18 [2080/2566 (81%)]\tLoss: 0.608873\n",
      "Train Epoch: 18 [2120/2566 (83%)]\tLoss: 1.178454\n",
      "Train Epoch: 18 [2160/2566 (84%)]\tLoss: 0.567132\n",
      "Train Epoch: 18 [2200/2566 (86%)]\tLoss: 0.811787\n",
      "Train Epoch: 18 [2240/2566 (87%)]\tLoss: 0.310940\n",
      "Train Epoch: 18 [2280/2566 (89%)]\tLoss: 0.930299\n",
      "Train Epoch: 18 [2320/2566 (90%)]\tLoss: 0.602916\n",
      "Train Epoch: 18 [2360/2566 (92%)]\tLoss: 0.698918\n",
      "Train Epoch: 18 [2400/2566 (93%)]\tLoss: 0.582548\n",
      "Train Epoch: 18 [2440/2566 (95%)]\tLoss: 0.550501\n",
      "Train Epoch: 18 [2480/2566 (97%)]\tLoss: 0.284724\n",
      "Train Epoch: 18 [2520/2566 (98%)]\tLoss: 0.625916\n",
      "Train Epoch: 18 [2560/2566 (100%)]\tLoss: 1.379650\n",
      "epoch:18,loss:0.7495857227907002\n",
      "Train set: Average loss: 0.6568, Accuracy: 1914/2566 (75%)\n",
      "Val set: Average loss: 0.6768, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 19 [40/2566 (2%)]\tLoss: 2.376691\n",
      "Train Epoch: 19 [80/2566 (3%)]\tLoss: 0.606678\n",
      "Train Epoch: 19 [120/2566 (5%)]\tLoss: 0.276978\n",
      "Train Epoch: 19 [160/2566 (6%)]\tLoss: 1.250871\n",
      "Train Epoch: 19 [200/2566 (8%)]\tLoss: 0.695834\n",
      "Train Epoch: 19 [240/2566 (9%)]\tLoss: 0.818215\n",
      "Train Epoch: 19 [280/2566 (11%)]\tLoss: 0.825840\n",
      "Train Epoch: 19 [320/2566 (12%)]\tLoss: 0.713735\n",
      "Train Epoch: 19 [360/2566 (14%)]\tLoss: 0.909902\n",
      "Train Epoch: 19 [400/2566 (16%)]\tLoss: 1.013447\n",
      "Train Epoch: 19 [440/2566 (17%)]\tLoss: 0.977326\n",
      "Train Epoch: 19 [480/2566 (19%)]\tLoss: 0.645786\n",
      "Train Epoch: 19 [520/2566 (20%)]\tLoss: 1.042439\n",
      "Train Epoch: 19 [560/2566 (22%)]\tLoss: 1.663048\n",
      "Train Epoch: 19 [600/2566 (23%)]\tLoss: 0.304262\n",
      "Train Epoch: 19 [640/2566 (25%)]\tLoss: 0.646305\n",
      "Train Epoch: 19 [680/2566 (26%)]\tLoss: 0.456288\n",
      "Train Epoch: 19 [720/2566 (28%)]\tLoss: 1.023381\n",
      "Train Epoch: 19 [760/2566 (30%)]\tLoss: 1.058426\n",
      "Train Epoch: 19 [800/2566 (31%)]\tLoss: 0.446377\n",
      "Train Epoch: 19 [840/2566 (33%)]\tLoss: 0.290633\n",
      "Train Epoch: 19 [880/2566 (34%)]\tLoss: 0.970967\n",
      "Train Epoch: 19 [920/2566 (36%)]\tLoss: 0.375288\n",
      "Train Epoch: 19 [960/2566 (37%)]\tLoss: 0.679584\n",
      "Train Epoch: 19 [1000/2566 (39%)]\tLoss: 0.409007\n",
      "Train Epoch: 19 [1040/2566 (40%)]\tLoss: 0.232997\n",
      "Train Epoch: 19 [1080/2566 (42%)]\tLoss: 0.910556\n",
      "Train Epoch: 19 [1120/2566 (44%)]\tLoss: 0.540580\n",
      "Train Epoch: 19 [1160/2566 (45%)]\tLoss: 0.375261\n",
      "Train Epoch: 19 [1200/2566 (47%)]\tLoss: 0.718704\n",
      "Train Epoch: 19 [1240/2566 (48%)]\tLoss: 0.687397\n",
      "Train Epoch: 19 [1280/2566 (50%)]\tLoss: 0.651701\n",
      "Train Epoch: 19 [1320/2566 (51%)]\tLoss: 1.034789\n",
      "Train Epoch: 19 [1360/2566 (53%)]\tLoss: 1.113378\n",
      "Train Epoch: 19 [1400/2566 (55%)]\tLoss: 0.386216\n",
      "Train Epoch: 19 [1440/2566 (56%)]\tLoss: 1.410800\n",
      "Train Epoch: 19 [1480/2566 (58%)]\tLoss: 0.689009\n",
      "Train Epoch: 19 [1520/2566 (59%)]\tLoss: 1.002149\n",
      "Train Epoch: 19 [1560/2566 (61%)]\tLoss: 0.822472\n",
      "Train Epoch: 19 [1600/2566 (62%)]\tLoss: 0.937974\n",
      "Train Epoch: 19 [1640/2566 (64%)]\tLoss: 0.498101\n",
      "Train Epoch: 19 [1680/2566 (65%)]\tLoss: 0.603428\n",
      "Train Epoch: 19 [1720/2566 (67%)]\tLoss: 0.453333\n",
      "Train Epoch: 19 [1760/2566 (69%)]\tLoss: 0.935139\n",
      "Train Epoch: 19 [1800/2566 (70%)]\tLoss: 0.581854\n",
      "Train Epoch: 19 [1840/2566 (72%)]\tLoss: 0.355635\n",
      "Train Epoch: 19 [1880/2566 (73%)]\tLoss: 0.338073\n",
      "Train Epoch: 19 [1920/2566 (75%)]\tLoss: 0.576680\n",
      "Train Epoch: 19 [1960/2566 (76%)]\tLoss: 0.599957\n",
      "Train Epoch: 19 [2000/2566 (78%)]\tLoss: 0.722397\n",
      "Train Epoch: 19 [2040/2566 (79%)]\tLoss: 0.773340\n",
      "Train Epoch: 19 [2080/2566 (81%)]\tLoss: 0.606732\n",
      "Train Epoch: 19 [2120/2566 (83%)]\tLoss: 0.461839\n",
      "Train Epoch: 19 [2160/2566 (84%)]\tLoss: 0.720695\n",
      "Train Epoch: 19 [2200/2566 (86%)]\tLoss: 0.370452\n",
      "Train Epoch: 19 [2240/2566 (87%)]\tLoss: 0.808466\n",
      "Train Epoch: 19 [2280/2566 (89%)]\tLoss: 0.464094\n",
      "Train Epoch: 19 [2320/2566 (90%)]\tLoss: 0.933589\n",
      "Train Epoch: 19 [2360/2566 (92%)]\tLoss: 0.575880\n",
      "Train Epoch: 19 [2400/2566 (93%)]\tLoss: 0.652826\n",
      "Train Epoch: 19 [2440/2566 (95%)]\tLoss: 0.606697\n",
      "Train Epoch: 19 [2480/2566 (97%)]\tLoss: 0.656594\n",
      "Train Epoch: 19 [2520/2566 (98%)]\tLoss: 0.923621\n",
      "Train Epoch: 19 [2560/2566 (100%)]\tLoss: 0.327825\n",
      "epoch:19,loss:0.7395093097957867\n",
      "Train set: Average loss: 0.6572, Accuracy: 1908/2566 (74%)\n",
      "Val set: Average loss: 0.6775, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 20 [40/2566 (2%)]\tLoss: 0.384283\n",
      "Train Epoch: 20 [80/2566 (3%)]\tLoss: 0.755881\n",
      "Train Epoch: 20 [120/2566 (5%)]\tLoss: 0.588447\n",
      "Train Epoch: 20 [160/2566 (6%)]\tLoss: 0.651714\n",
      "Train Epoch: 20 [200/2566 (8%)]\tLoss: 0.720746\n",
      "Train Epoch: 20 [240/2566 (9%)]\tLoss: 0.299997\n",
      "Train Epoch: 20 [280/2566 (11%)]\tLoss: 0.525100\n",
      "Train Epoch: 20 [320/2566 (12%)]\tLoss: 0.677639\n",
      "Train Epoch: 20 [360/2566 (14%)]\tLoss: 0.541729\n",
      "Train Epoch: 20 [400/2566 (16%)]\tLoss: 0.648405\n",
      "Train Epoch: 20 [440/2566 (17%)]\tLoss: 0.676475\n",
      "Train Epoch: 20 [480/2566 (19%)]\tLoss: 1.942535\n",
      "Train Epoch: 20 [520/2566 (20%)]\tLoss: 0.872430\n",
      "Train Epoch: 20 [560/2566 (22%)]\tLoss: 0.720398\n",
      "Train Epoch: 20 [600/2566 (23%)]\tLoss: 0.527559\n",
      "Train Epoch: 20 [640/2566 (25%)]\tLoss: 1.024763\n",
      "Train Epoch: 20 [680/2566 (26%)]\tLoss: 0.977045\n",
      "Train Epoch: 20 [720/2566 (28%)]\tLoss: 0.814948\n",
      "Train Epoch: 20 [760/2566 (30%)]\tLoss: 1.048082\n",
      "Train Epoch: 20 [800/2566 (31%)]\tLoss: 0.998349\n",
      "Train Epoch: 20 [840/2566 (33%)]\tLoss: 0.424812\n",
      "Train Epoch: 20 [880/2566 (34%)]\tLoss: 0.673447\n",
      "Train Epoch: 20 [920/2566 (36%)]\tLoss: 0.504177\n",
      "Train Epoch: 20 [960/2566 (37%)]\tLoss: 0.702350\n",
      "Train Epoch: 20 [1000/2566 (39%)]\tLoss: 0.789071\n",
      "Train Epoch: 20 [1040/2566 (40%)]\tLoss: 0.483094\n",
      "Train Epoch: 20 [1080/2566 (42%)]\tLoss: 0.565991\n",
      "Train Epoch: 20 [1120/2566 (44%)]\tLoss: 0.905177\n",
      "Train Epoch: 20 [1160/2566 (45%)]\tLoss: 0.961172\n",
      "Train Epoch: 20 [1200/2566 (47%)]\tLoss: 0.792945\n",
      "Train Epoch: 20 [1240/2566 (48%)]\tLoss: 0.199137\n",
      "Train Epoch: 20 [1280/2566 (50%)]\tLoss: 1.125372\n",
      "Train Epoch: 20 [1320/2566 (51%)]\tLoss: 0.556516\n",
      "Train Epoch: 20 [1360/2566 (53%)]\tLoss: 0.528374\n",
      "Train Epoch: 20 [1400/2566 (55%)]\tLoss: 0.969941\n",
      "Train Epoch: 20 [1440/2566 (56%)]\tLoss: 0.593417\n",
      "Train Epoch: 20 [1480/2566 (58%)]\tLoss: 0.837885\n",
      "Train Epoch: 20 [1520/2566 (59%)]\tLoss: 0.988129\n",
      "Train Epoch: 20 [1560/2566 (61%)]\tLoss: 0.666870\n",
      "Train Epoch: 20 [1600/2566 (62%)]\tLoss: 0.748556\n",
      "Train Epoch: 20 [1640/2566 (64%)]\tLoss: 0.676927\n",
      "Train Epoch: 20 [1680/2566 (65%)]\tLoss: 0.784818\n",
      "Train Epoch: 20 [1720/2566 (67%)]\tLoss: 0.731546\n",
      "Train Epoch: 20 [1760/2566 (69%)]\tLoss: 0.674229\n",
      "Train Epoch: 20 [1800/2566 (70%)]\tLoss: 1.164786\n",
      "Train Epoch: 20 [1840/2566 (72%)]\tLoss: 0.502555\n",
      "Train Epoch: 20 [1880/2566 (73%)]\tLoss: 0.875137\n",
      "Train Epoch: 20 [1920/2566 (75%)]\tLoss: 0.452995\n",
      "Train Epoch: 20 [1960/2566 (76%)]\tLoss: 0.610160\n",
      "Train Epoch: 20 [2000/2566 (78%)]\tLoss: 1.007238\n",
      "Train Epoch: 20 [2040/2566 (79%)]\tLoss: 1.304057\n",
      "Train Epoch: 20 [2080/2566 (81%)]\tLoss: 0.638710\n",
      "Train Epoch: 20 [2120/2566 (83%)]\tLoss: 0.499291\n",
      "Train Epoch: 20 [2160/2566 (84%)]\tLoss: 0.560341\n",
      "Train Epoch: 20 [2200/2566 (86%)]\tLoss: 0.679720\n",
      "Train Epoch: 20 [2240/2566 (87%)]\tLoss: 0.557888\n",
      "Train Epoch: 20 [2280/2566 (89%)]\tLoss: 2.344541\n",
      "Train Epoch: 20 [2320/2566 (90%)]\tLoss: 0.873702\n",
      "Train Epoch: 20 [2360/2566 (92%)]\tLoss: 0.451110\n",
      "Train Epoch: 20 [2400/2566 (93%)]\tLoss: 0.264207\n",
      "Train Epoch: 20 [2440/2566 (95%)]\tLoss: 0.243417\n",
      "Train Epoch: 20 [2480/2566 (97%)]\tLoss: 0.535709\n",
      "Train Epoch: 20 [2520/2566 (98%)]\tLoss: 0.647977\n",
      "Train Epoch: 20 [2560/2566 (100%)]\tLoss: 0.856901\n",
      "epoch:20,loss:0.7205201613011761\n",
      "Train set: Average loss: 0.6369, Accuracy: 1922/2566 (75%)\n",
      "Val set: Average loss: 0.6655, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 21 [40/2566 (2%)]\tLoss: 0.404440\n",
      "Train Epoch: 21 [80/2566 (3%)]\tLoss: 0.765232\n",
      "Train Epoch: 21 [120/2566 (5%)]\tLoss: 0.396293\n",
      "Train Epoch: 21 [160/2566 (6%)]\tLoss: 0.956984\n",
      "Train Epoch: 21 [200/2566 (8%)]\tLoss: 0.610902\n",
      "Train Epoch: 21 [240/2566 (9%)]\tLoss: 0.258360\n",
      "Train Epoch: 21 [280/2566 (11%)]\tLoss: 0.521932\n",
      "Train Epoch: 21 [320/2566 (12%)]\tLoss: 0.483698\n",
      "Train Epoch: 21 [360/2566 (14%)]\tLoss: 0.854454\n",
      "Train Epoch: 21 [400/2566 (16%)]\tLoss: 0.999334\n",
      "Train Epoch: 21 [440/2566 (17%)]\tLoss: 0.819094\n",
      "Train Epoch: 21 [480/2566 (19%)]\tLoss: 0.688626\n",
      "Train Epoch: 21 [520/2566 (20%)]\tLoss: 0.250016\n",
      "Train Epoch: 21 [560/2566 (22%)]\tLoss: 0.765704\n",
      "Train Epoch: 21 [600/2566 (23%)]\tLoss: 0.501136\n",
      "Train Epoch: 21 [640/2566 (25%)]\tLoss: 0.528554\n",
      "Train Epoch: 21 [680/2566 (26%)]\tLoss: 0.531854\n",
      "Train Epoch: 21 [720/2566 (28%)]\tLoss: 1.007653\n",
      "Train Epoch: 21 [760/2566 (30%)]\tLoss: 0.738340\n",
      "Train Epoch: 21 [800/2566 (31%)]\tLoss: 0.390896\n",
      "Train Epoch: 21 [840/2566 (33%)]\tLoss: 0.758287\n",
      "Train Epoch: 21 [880/2566 (34%)]\tLoss: 0.693073\n",
      "Train Epoch: 21 [920/2566 (36%)]\tLoss: 0.422883\n",
      "Train Epoch: 21 [960/2566 (37%)]\tLoss: 0.485932\n",
      "Train Epoch: 21 [1000/2566 (39%)]\tLoss: 0.413845\n",
      "Train Epoch: 21 [1040/2566 (40%)]\tLoss: 0.610388\n",
      "Train Epoch: 21 [1080/2566 (42%)]\tLoss: 0.729362\n",
      "Train Epoch: 21 [1120/2566 (44%)]\tLoss: 0.963530\n",
      "Train Epoch: 21 [1160/2566 (45%)]\tLoss: 0.553018\n",
      "Train Epoch: 21 [1200/2566 (47%)]\tLoss: 0.881140\n",
      "Train Epoch: 21 [1240/2566 (48%)]\tLoss: 1.043911\n",
      "Train Epoch: 21 [1280/2566 (50%)]\tLoss: 0.714625\n",
      "Train Epoch: 21 [1320/2566 (51%)]\tLoss: 0.942612\n",
      "Train Epoch: 21 [1360/2566 (53%)]\tLoss: 0.913858\n",
      "Train Epoch: 21 [1400/2566 (55%)]\tLoss: 0.693681\n",
      "Train Epoch: 21 [1440/2566 (56%)]\tLoss: 0.572954\n",
      "Train Epoch: 21 [1480/2566 (58%)]\tLoss: 0.724932\n",
      "Train Epoch: 21 [1520/2566 (59%)]\tLoss: 0.812659\n",
      "Train Epoch: 21 [1560/2566 (61%)]\tLoss: 0.437289\n",
      "Train Epoch: 21 [1600/2566 (62%)]\tLoss: 0.642519\n",
      "Train Epoch: 21 [1640/2566 (64%)]\tLoss: 0.784869\n",
      "Train Epoch: 21 [1680/2566 (65%)]\tLoss: 0.684479\n",
      "Train Epoch: 21 [1720/2566 (67%)]\tLoss: 1.057132\n",
      "Train Epoch: 21 [1760/2566 (69%)]\tLoss: 1.140283\n",
      "Train Epoch: 21 [1800/2566 (70%)]\tLoss: 0.486559\n",
      "Train Epoch: 21 [1840/2566 (72%)]\tLoss: 0.633184\n",
      "Train Epoch: 21 [1880/2566 (73%)]\tLoss: 0.986720\n",
      "Train Epoch: 21 [1920/2566 (75%)]\tLoss: 0.317518\n",
      "Train Epoch: 21 [1960/2566 (76%)]\tLoss: 0.524548\n",
      "Train Epoch: 21 [2000/2566 (78%)]\tLoss: 0.393817\n",
      "Train Epoch: 21 [2040/2566 (79%)]\tLoss: 0.597103\n",
      "Train Epoch: 21 [2080/2566 (81%)]\tLoss: 0.582900\n",
      "Train Epoch: 21 [2120/2566 (83%)]\tLoss: 0.934238\n",
      "Train Epoch: 21 [2160/2566 (84%)]\tLoss: 0.909764\n",
      "Train Epoch: 21 [2200/2566 (86%)]\tLoss: 1.276201\n",
      "Train Epoch: 21 [2240/2566 (87%)]\tLoss: 0.492806\n",
      "Train Epoch: 21 [2280/2566 (89%)]\tLoss: 1.183271\n",
      "Train Epoch: 21 [2320/2566 (90%)]\tLoss: 0.604829\n",
      "Train Epoch: 21 [2360/2566 (92%)]\tLoss: 0.858540\n",
      "Train Epoch: 21 [2400/2566 (93%)]\tLoss: 0.678911\n",
      "Train Epoch: 21 [2440/2566 (95%)]\tLoss: 0.384252\n",
      "Train Epoch: 21 [2480/2566 (97%)]\tLoss: 0.946161\n",
      "Train Epoch: 21 [2520/2566 (98%)]\tLoss: 0.757577\n",
      "Train Epoch: 21 [2560/2566 (100%)]\tLoss: 0.772134\n",
      "epoch:21,loss:0.7234150899162174\n",
      "Train set: Average loss: 0.6342, Accuracy: 1914/2566 (75%)\n",
      "Val set: Average loss: 0.6614, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 22 [40/2566 (2%)]\tLoss: 0.565008\n",
      "Train Epoch: 22 [80/2566 (3%)]\tLoss: 0.487416\n",
      "Train Epoch: 22 [120/2566 (5%)]\tLoss: 0.738614\n",
      "Train Epoch: 22 [160/2566 (6%)]\tLoss: 0.299258\n",
      "Train Epoch: 22 [200/2566 (8%)]\tLoss: 0.923149\n",
      "Train Epoch: 22 [240/2566 (9%)]\tLoss: 0.412909\n",
      "Train Epoch: 22 [280/2566 (11%)]\tLoss: 0.739697\n",
      "Train Epoch: 22 [320/2566 (12%)]\tLoss: 0.852308\n",
      "Train Epoch: 22 [360/2566 (14%)]\tLoss: 0.433184\n",
      "Train Epoch: 22 [400/2566 (16%)]\tLoss: 0.601515\n",
      "Train Epoch: 22 [440/2566 (17%)]\tLoss: 0.373733\n",
      "Train Epoch: 22 [480/2566 (19%)]\tLoss: 0.438624\n",
      "Train Epoch: 22 [520/2566 (20%)]\tLoss: 0.610386\n",
      "Train Epoch: 22 [560/2566 (22%)]\tLoss: 0.790176\n",
      "Train Epoch: 22 [600/2566 (23%)]\tLoss: 0.823248\n",
      "Train Epoch: 22 [640/2566 (25%)]\tLoss: 0.600296\n",
      "Train Epoch: 22 [680/2566 (26%)]\tLoss: 0.989020\n",
      "Train Epoch: 22 [720/2566 (28%)]\tLoss: 0.693250\n",
      "Train Epoch: 22 [760/2566 (30%)]\tLoss: 0.583962\n",
      "Train Epoch: 22 [800/2566 (31%)]\tLoss: 0.855839\n",
      "Train Epoch: 22 [840/2566 (33%)]\tLoss: 0.604953\n",
      "Train Epoch: 22 [880/2566 (34%)]\tLoss: 0.778206\n",
      "Train Epoch: 22 [920/2566 (36%)]\tLoss: 0.424192\n",
      "Train Epoch: 22 [960/2566 (37%)]\tLoss: 1.046032\n",
      "Train Epoch: 22 [1000/2566 (39%)]\tLoss: 0.541443\n",
      "Train Epoch: 22 [1040/2566 (40%)]\tLoss: 0.536940\n",
      "Train Epoch: 22 [1080/2566 (42%)]\tLoss: 0.869570\n",
      "Train Epoch: 22 [1120/2566 (44%)]\tLoss: 0.715339\n",
      "Train Epoch: 22 [1160/2566 (45%)]\tLoss: 0.262248\n",
      "Train Epoch: 22 [1200/2566 (47%)]\tLoss: 0.671114\n",
      "Train Epoch: 22 [1240/2566 (48%)]\tLoss: 0.433827\n",
      "Train Epoch: 22 [1280/2566 (50%)]\tLoss: 0.706264\n",
      "Train Epoch: 22 [1320/2566 (51%)]\tLoss: 0.973290\n",
      "Train Epoch: 22 [1360/2566 (53%)]\tLoss: 0.974010\n",
      "Train Epoch: 22 [1400/2566 (55%)]\tLoss: 0.852589\n",
      "Train Epoch: 22 [1440/2566 (56%)]\tLoss: 1.013018\n",
      "Train Epoch: 22 [1480/2566 (58%)]\tLoss: 0.199004\n",
      "Train Epoch: 22 [1520/2566 (59%)]\tLoss: 0.991793\n",
      "Train Epoch: 22 [1560/2566 (61%)]\tLoss: 0.981575\n",
      "Train Epoch: 22 [1600/2566 (62%)]\tLoss: 0.649830\n",
      "Train Epoch: 22 [1640/2566 (64%)]\tLoss: 0.987112\n",
      "Train Epoch: 22 [1680/2566 (65%)]\tLoss: 0.291265\n",
      "Train Epoch: 22 [1720/2566 (67%)]\tLoss: 0.375250\n",
      "Train Epoch: 22 [1760/2566 (69%)]\tLoss: 0.923532\n",
      "Train Epoch: 22 [1800/2566 (70%)]\tLoss: 0.852767\n",
      "Train Epoch: 22 [1840/2566 (72%)]\tLoss: 0.579419\n",
      "Train Epoch: 22 [1880/2566 (73%)]\tLoss: 0.767259\n",
      "Train Epoch: 22 [1920/2566 (75%)]\tLoss: 0.352478\n",
      "Train Epoch: 22 [1960/2566 (76%)]\tLoss: 0.579592\n",
      "Train Epoch: 22 [2000/2566 (78%)]\tLoss: 0.453002\n",
      "Train Epoch: 22 [2040/2566 (79%)]\tLoss: 1.311983\n",
      "Train Epoch: 22 [2080/2566 (81%)]\tLoss: 0.870564\n",
      "Train Epoch: 22 [2120/2566 (83%)]\tLoss: 0.336569\n",
      "Train Epoch: 22 [2160/2566 (84%)]\tLoss: 0.593987\n",
      "Train Epoch: 22 [2200/2566 (86%)]\tLoss: 0.415981\n",
      "Train Epoch: 22 [2240/2566 (87%)]\tLoss: 0.608108\n",
      "Train Epoch: 22 [2280/2566 (89%)]\tLoss: 0.660268\n",
      "Train Epoch: 22 [2320/2566 (90%)]\tLoss: 0.393679\n",
      "Train Epoch: 22 [2360/2566 (92%)]\tLoss: 0.779980\n",
      "Train Epoch: 22 [2400/2566 (93%)]\tLoss: 0.231928\n",
      "Train Epoch: 22 [2440/2566 (95%)]\tLoss: 0.518278\n",
      "Train Epoch: 22 [2480/2566 (97%)]\tLoss: 0.636717\n",
      "Train Epoch: 22 [2520/2566 (98%)]\tLoss: 0.858108\n",
      "Train Epoch: 22 [2560/2566 (100%)]\tLoss: 0.416775\n",
      "epoch:22,loss:0.6996332394928204\n",
      "Train set: Average loss: 0.6321, Accuracy: 1917/2566 (75%)\n",
      "Val set: Average loss: 0.6648, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 23 [40/2566 (2%)]\tLoss: 0.800700\n",
      "Train Epoch: 23 [80/2566 (3%)]\tLoss: 0.890257\n",
      "Train Epoch: 23 [120/2566 (5%)]\tLoss: 0.871038\n",
      "Train Epoch: 23 [160/2566 (6%)]\tLoss: 1.015792\n",
      "Train Epoch: 23 [200/2566 (8%)]\tLoss: 0.579936\n",
      "Train Epoch: 23 [240/2566 (9%)]\tLoss: 0.589399\n",
      "Train Epoch: 23 [280/2566 (11%)]\tLoss: 0.238413\n",
      "Train Epoch: 23 [320/2566 (12%)]\tLoss: 0.864881\n",
      "Train Epoch: 23 [360/2566 (14%)]\tLoss: 0.805313\n",
      "Train Epoch: 23 [400/2566 (16%)]\tLoss: 0.378115\n",
      "Train Epoch: 23 [440/2566 (17%)]\tLoss: 0.523694\n",
      "Train Epoch: 23 [480/2566 (19%)]\tLoss: 0.432048\n",
      "Train Epoch: 23 [520/2566 (20%)]\tLoss: 0.312979\n",
      "Train Epoch: 23 [560/2566 (22%)]\tLoss: 0.816194\n",
      "Train Epoch: 23 [600/2566 (23%)]\tLoss: 1.260918\n",
      "Train Epoch: 23 [640/2566 (25%)]\tLoss: 1.308842\n",
      "Train Epoch: 23 [680/2566 (26%)]\tLoss: 0.272071\n",
      "Train Epoch: 23 [720/2566 (28%)]\tLoss: 0.803452\n",
      "Train Epoch: 23 [760/2566 (30%)]\tLoss: 0.732993\n",
      "Train Epoch: 23 [800/2566 (31%)]\tLoss: 0.475681\n",
      "Train Epoch: 23 [840/2566 (33%)]\tLoss: 0.523687\n",
      "Train Epoch: 23 [880/2566 (34%)]\tLoss: 0.850479\n",
      "Train Epoch: 23 [920/2566 (36%)]\tLoss: 0.791545\n",
      "Train Epoch: 23 [960/2566 (37%)]\tLoss: 0.918160\n",
      "Train Epoch: 23 [1000/2566 (39%)]\tLoss: 0.676914\n",
      "Train Epoch: 23 [1040/2566 (40%)]\tLoss: 0.554228\n",
      "Train Epoch: 23 [1080/2566 (42%)]\tLoss: 0.398397\n",
      "Train Epoch: 23 [1120/2566 (44%)]\tLoss: 0.398636\n",
      "Train Epoch: 23 [1160/2566 (45%)]\tLoss: 0.624049\n",
      "Train Epoch: 23 [1200/2566 (47%)]\tLoss: 0.430217\n",
      "Train Epoch: 23 [1240/2566 (48%)]\tLoss: 0.374762\n",
      "Train Epoch: 23 [1280/2566 (50%)]\tLoss: 0.354734\n",
      "Train Epoch: 23 [1320/2566 (51%)]\tLoss: 0.624164\n",
      "Train Epoch: 23 [1360/2566 (53%)]\tLoss: 0.351436\n",
      "Train Epoch: 23 [1400/2566 (55%)]\tLoss: 0.690761\n",
      "Train Epoch: 23 [1440/2566 (56%)]\tLoss: 1.048320\n",
      "Train Epoch: 23 [1480/2566 (58%)]\tLoss: 0.327231\n",
      "Train Epoch: 23 [1520/2566 (59%)]\tLoss: 0.484772\n",
      "Train Epoch: 23 [1560/2566 (61%)]\tLoss: 0.518782\n",
      "Train Epoch: 23 [1600/2566 (62%)]\tLoss: 0.423863\n",
      "Train Epoch: 23 [1640/2566 (64%)]\tLoss: 1.213909\n",
      "Train Epoch: 23 [1680/2566 (65%)]\tLoss: 0.644721\n",
      "Train Epoch: 23 [1720/2566 (67%)]\tLoss: 0.521476\n",
      "Train Epoch: 23 [1760/2566 (69%)]\tLoss: 0.619921\n",
      "Train Epoch: 23 [1800/2566 (70%)]\tLoss: 0.788893\n",
      "Train Epoch: 23 [1840/2566 (72%)]\tLoss: 1.009832\n",
      "Train Epoch: 23 [1880/2566 (73%)]\tLoss: 1.137597\n",
      "Train Epoch: 23 [1920/2566 (75%)]\tLoss: 0.768950\n",
      "Train Epoch: 23 [1960/2566 (76%)]\tLoss: 0.767636\n",
      "Train Epoch: 23 [2000/2566 (78%)]\tLoss: 2.153234\n",
      "Train Epoch: 23 [2040/2566 (79%)]\tLoss: 0.600968\n",
      "Train Epoch: 23 [2080/2566 (81%)]\tLoss: 0.863504\n",
      "Train Epoch: 23 [2120/2566 (83%)]\tLoss: 0.675076\n",
      "Train Epoch: 23 [2160/2566 (84%)]\tLoss: 1.053872\n",
      "Train Epoch: 23 [2200/2566 (86%)]\tLoss: 0.611319\n",
      "Train Epoch: 23 [2240/2566 (87%)]\tLoss: 0.577008\n",
      "Train Epoch: 23 [2280/2566 (89%)]\tLoss: 0.551801\n",
      "Train Epoch: 23 [2320/2566 (90%)]\tLoss: 0.742646\n",
      "Train Epoch: 23 [2360/2566 (92%)]\tLoss: 0.841406\n",
      "Train Epoch: 23 [2400/2566 (93%)]\tLoss: 0.765249\n",
      "Train Epoch: 23 [2440/2566 (95%)]\tLoss: 0.910632\n",
      "Train Epoch: 23 [2480/2566 (97%)]\tLoss: 0.837203\n",
      "Train Epoch: 23 [2520/2566 (98%)]\tLoss: 0.722728\n",
      "Train Epoch: 23 [2560/2566 (100%)]\tLoss: 0.249089\n",
      "epoch:23,loss:0.7025472048287079\n",
      "Train set: Average loss: 0.6282, Accuracy: 1926/2566 (75%)\n",
      "Val set: Average loss: 0.6562, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 24 [40/2566 (2%)]\tLoss: 0.561736\n",
      "Train Epoch: 24 [80/2566 (3%)]\tLoss: 0.725100\n",
      "Train Epoch: 24 [120/2566 (5%)]\tLoss: 0.171940\n",
      "Train Epoch: 24 [160/2566 (6%)]\tLoss: 0.638376\n",
      "Train Epoch: 24 [200/2566 (8%)]\tLoss: 0.459755\n",
      "Train Epoch: 24 [240/2566 (9%)]\tLoss: 0.483088\n",
      "Train Epoch: 24 [280/2566 (11%)]\tLoss: 0.834357\n",
      "Train Epoch: 24 [320/2566 (12%)]\tLoss: 0.710381\n",
      "Train Epoch: 24 [360/2566 (14%)]\tLoss: 0.688163\n",
      "Train Epoch: 24 [400/2566 (16%)]\tLoss: 1.163946\n",
      "Train Epoch: 24 [440/2566 (17%)]\tLoss: 0.702280\n",
      "Train Epoch: 24 [480/2566 (19%)]\tLoss: 0.553478\n",
      "Train Epoch: 24 [520/2566 (20%)]\tLoss: 0.706258\n",
      "Train Epoch: 24 [560/2566 (22%)]\tLoss: 0.553549\n",
      "Train Epoch: 24 [600/2566 (23%)]\tLoss: 0.168300\n",
      "Train Epoch: 24 [640/2566 (25%)]\tLoss: 0.865247\n",
      "Train Epoch: 24 [680/2566 (26%)]\tLoss: 1.168303\n",
      "Train Epoch: 24 [720/2566 (28%)]\tLoss: 0.533545\n",
      "Train Epoch: 24 [760/2566 (30%)]\tLoss: 0.780231\n",
      "Train Epoch: 24 [800/2566 (31%)]\tLoss: 0.669004\n",
      "Train Epoch: 24 [840/2566 (33%)]\tLoss: 0.723927\n",
      "Train Epoch: 24 [880/2566 (34%)]\tLoss: 0.619836\n",
      "Train Epoch: 24 [920/2566 (36%)]\tLoss: 0.799470\n",
      "Train Epoch: 24 [960/2566 (37%)]\tLoss: 0.465339\n",
      "Train Epoch: 24 [1000/2566 (39%)]\tLoss: 0.392585\n",
      "Train Epoch: 24 [1040/2566 (40%)]\tLoss: 0.758927\n",
      "Train Epoch: 24 [1080/2566 (42%)]\tLoss: 0.223415\n",
      "Train Epoch: 24 [1120/2566 (44%)]\tLoss: 0.587427\n",
      "Train Epoch: 24 [1160/2566 (45%)]\tLoss: 0.354326\n",
      "Train Epoch: 24 [1200/2566 (47%)]\tLoss: 0.850899\n",
      "Train Epoch: 24 [1240/2566 (48%)]\tLoss: 0.390960\n",
      "Train Epoch: 24 [1280/2566 (50%)]\tLoss: 0.851269\n",
      "Train Epoch: 24 [1320/2566 (51%)]\tLoss: 0.704083\n",
      "Train Epoch: 24 [1360/2566 (53%)]\tLoss: 0.432619\n",
      "Train Epoch: 24 [1400/2566 (55%)]\tLoss: 1.280214\n",
      "Train Epoch: 24 [1440/2566 (56%)]\tLoss: 0.425582\n",
      "Train Epoch: 24 [1480/2566 (58%)]\tLoss: 0.949455\n",
      "Train Epoch: 24 [1520/2566 (59%)]\tLoss: 1.017725\n",
      "Train Epoch: 24 [1560/2566 (61%)]\tLoss: 0.923871\n",
      "Train Epoch: 24 [1600/2566 (62%)]\tLoss: 0.790877\n",
      "Train Epoch: 24 [1640/2566 (64%)]\tLoss: 0.476761\n",
      "Train Epoch: 24 [1680/2566 (65%)]\tLoss: 0.388671\n",
      "Train Epoch: 24 [1720/2566 (67%)]\tLoss: 0.865522\n",
      "Train Epoch: 24 [1760/2566 (69%)]\tLoss: 0.927753\n",
      "Train Epoch: 24 [1800/2566 (70%)]\tLoss: 0.337065\n",
      "Train Epoch: 24 [1840/2566 (72%)]\tLoss: 0.628890\n",
      "Train Epoch: 24 [1880/2566 (73%)]\tLoss: 0.351968\n",
      "Train Epoch: 24 [1920/2566 (75%)]\tLoss: 0.651226\n",
      "Train Epoch: 24 [1960/2566 (76%)]\tLoss: 0.770770\n",
      "Train Epoch: 24 [2000/2566 (78%)]\tLoss: 0.694701\n",
      "Train Epoch: 24 [2040/2566 (79%)]\tLoss: 1.545285\n",
      "Train Epoch: 24 [2080/2566 (81%)]\tLoss: 0.603746\n",
      "Train Epoch: 24 [2120/2566 (83%)]\tLoss: 0.672831\n",
      "Train Epoch: 24 [2160/2566 (84%)]\tLoss: 0.709966\n",
      "Train Epoch: 24 [2200/2566 (86%)]\tLoss: 0.317978\n",
      "Train Epoch: 24 [2240/2566 (87%)]\tLoss: 0.541850\n",
      "Train Epoch: 24 [2280/2566 (89%)]\tLoss: 1.090679\n",
      "Train Epoch: 24 [2320/2566 (90%)]\tLoss: 0.465056\n",
      "Train Epoch: 24 [2360/2566 (92%)]\tLoss: 0.465626\n",
      "Train Epoch: 24 [2400/2566 (93%)]\tLoss: 1.133022\n",
      "Train Epoch: 24 [2440/2566 (95%)]\tLoss: 0.339434\n",
      "Train Epoch: 24 [2480/2566 (97%)]\tLoss: 0.796839\n",
      "Train Epoch: 24 [2520/2566 (98%)]\tLoss: 0.848394\n",
      "Train Epoch: 24 [2560/2566 (100%)]\tLoss: 0.497159\n",
      "epoch:24,loss:0.7105897497443766\n",
      "Train set: Average loss: 0.6223, Accuracy: 1923/2566 (75%)\n",
      "Val set: Average loss: 0.6574, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 25 [40/2566 (2%)]\tLoss: 0.825042\n",
      "Train Epoch: 25 [80/2566 (3%)]\tLoss: 0.417045\n",
      "Train Epoch: 25 [120/2566 (5%)]\tLoss: 0.928847\n",
      "Train Epoch: 25 [160/2566 (6%)]\tLoss: 0.165966\n",
      "Train Epoch: 25 [200/2566 (8%)]\tLoss: 0.224612\n",
      "Train Epoch: 25 [240/2566 (9%)]\tLoss: 1.439081\n",
      "Train Epoch: 25 [280/2566 (11%)]\tLoss: 1.018872\n",
      "Train Epoch: 25 [320/2566 (12%)]\tLoss: 0.518040\n",
      "Train Epoch: 25 [360/2566 (14%)]\tLoss: 0.638523\n",
      "Train Epoch: 25 [400/2566 (16%)]\tLoss: 0.546023\n",
      "Train Epoch: 25 [440/2566 (17%)]\tLoss: 0.821440\n",
      "Train Epoch: 25 [480/2566 (19%)]\tLoss: 0.702058\n",
      "Train Epoch: 25 [520/2566 (20%)]\tLoss: 0.297216\n",
      "Train Epoch: 25 [560/2566 (22%)]\tLoss: 0.549371\n",
      "Train Epoch: 25 [600/2566 (23%)]\tLoss: 0.731255\n",
      "Train Epoch: 25 [640/2566 (25%)]\tLoss: 0.554736\n",
      "Train Epoch: 25 [680/2566 (26%)]\tLoss: 0.761982\n",
      "Train Epoch: 25 [720/2566 (28%)]\tLoss: 0.402559\n",
      "Train Epoch: 25 [760/2566 (30%)]\tLoss: 0.265314\n",
      "Train Epoch: 25 [800/2566 (31%)]\tLoss: 0.663903\n",
      "Train Epoch: 25 [840/2566 (33%)]\tLoss: 0.710594\n",
      "Train Epoch: 25 [880/2566 (34%)]\tLoss: 0.639446\n",
      "Train Epoch: 25 [920/2566 (36%)]\tLoss: 0.835836\n",
      "Train Epoch: 25 [960/2566 (37%)]\tLoss: 0.388503\n",
      "Train Epoch: 25 [1000/2566 (39%)]\tLoss: 0.331347\n",
      "Train Epoch: 25 [1040/2566 (40%)]\tLoss: 0.220991\n",
      "Train Epoch: 25 [1080/2566 (42%)]\tLoss: 0.726651\n",
      "Train Epoch: 25 [1120/2566 (44%)]\tLoss: 0.677651\n",
      "Train Epoch: 25 [1160/2566 (45%)]\tLoss: 0.726780\n",
      "Train Epoch: 25 [1200/2566 (47%)]\tLoss: 0.742086\n",
      "Train Epoch: 25 [1240/2566 (48%)]\tLoss: 0.335680\n",
      "Train Epoch: 25 [1280/2566 (50%)]\tLoss: 0.824003\n",
      "Train Epoch: 25 [1320/2566 (51%)]\tLoss: 0.974086\n",
      "Train Epoch: 25 [1360/2566 (53%)]\tLoss: 0.246520\n",
      "Train Epoch: 25 [1400/2566 (55%)]\tLoss: 0.613570\n",
      "Train Epoch: 25 [1440/2566 (56%)]\tLoss: 0.587235\n",
      "Train Epoch: 25 [1480/2566 (58%)]\tLoss: 0.895843\n",
      "Train Epoch: 25 [1520/2566 (59%)]\tLoss: 1.759112\n",
      "Train Epoch: 25 [1560/2566 (61%)]\tLoss: 0.379480\n",
      "Train Epoch: 25 [1600/2566 (62%)]\tLoss: 0.462074\n",
      "Train Epoch: 25 [1640/2566 (64%)]\tLoss: 0.762531\n",
      "Train Epoch: 25 [1680/2566 (65%)]\tLoss: 1.375531\n",
      "Train Epoch: 25 [1720/2566 (67%)]\tLoss: 0.540657\n",
      "Train Epoch: 25 [1760/2566 (69%)]\tLoss: 0.500810\n",
      "Train Epoch: 25 [1800/2566 (70%)]\tLoss: 1.180126\n",
      "Train Epoch: 25 [1840/2566 (72%)]\tLoss: 0.984766\n",
      "Train Epoch: 25 [1880/2566 (73%)]\tLoss: 1.000535\n",
      "Train Epoch: 25 [1920/2566 (75%)]\tLoss: 0.233418\n",
      "Train Epoch: 25 [1960/2566 (76%)]\tLoss: 0.437294\n",
      "Train Epoch: 25 [2000/2566 (78%)]\tLoss: 0.370693\n",
      "Train Epoch: 25 [2040/2566 (79%)]\tLoss: 0.701406\n",
      "Train Epoch: 25 [2080/2566 (81%)]\tLoss: 1.100638\n",
      "Train Epoch: 25 [2120/2566 (83%)]\tLoss: 0.231201\n",
      "Train Epoch: 25 [2160/2566 (84%)]\tLoss: 0.214583\n",
      "Train Epoch: 25 [2200/2566 (86%)]\tLoss: 0.748145\n",
      "Train Epoch: 25 [2240/2566 (87%)]\tLoss: 0.739897\n",
      "Train Epoch: 25 [2280/2566 (89%)]\tLoss: 0.202376\n",
      "Train Epoch: 25 [2320/2566 (90%)]\tLoss: 0.661379\n",
      "Train Epoch: 25 [2360/2566 (92%)]\tLoss: 0.740031\n",
      "Train Epoch: 25 [2400/2566 (93%)]\tLoss: 0.892201\n",
      "Train Epoch: 25 [2440/2566 (95%)]\tLoss: 2.507833\n",
      "Train Epoch: 25 [2480/2566 (97%)]\tLoss: 0.716675\n",
      "Train Epoch: 25 [2520/2566 (98%)]\tLoss: 0.663386\n",
      "Train Epoch: 25 [2560/2566 (100%)]\tLoss: 0.629119\n",
      "epoch:25,loss:0.6972381906624524\n",
      "Train set: Average loss: 0.6039, Accuracy: 1928/2566 (75%)\n",
      "Val set: Average loss: 0.6433, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 26 [40/2566 (2%)]\tLoss: 0.992370\n",
      "Train Epoch: 26 [80/2566 (3%)]\tLoss: 0.405995\n",
      "Train Epoch: 26 [120/2566 (5%)]\tLoss: 0.874672\n",
      "Train Epoch: 26 [160/2566 (6%)]\tLoss: 1.026415\n",
      "Train Epoch: 26 [200/2566 (8%)]\tLoss: 0.619994\n",
      "Train Epoch: 26 [240/2566 (9%)]\tLoss: 1.012474\n",
      "Train Epoch: 26 [280/2566 (11%)]\tLoss: 0.339027\n",
      "Train Epoch: 26 [320/2566 (12%)]\tLoss: 1.252076\n",
      "Train Epoch: 26 [360/2566 (14%)]\tLoss: 0.347971\n",
      "Train Epoch: 26 [400/2566 (16%)]\tLoss: 0.496850\n",
      "Train Epoch: 26 [440/2566 (17%)]\tLoss: 0.226198\n",
      "Train Epoch: 26 [480/2566 (19%)]\tLoss: 0.234398\n",
      "Train Epoch: 26 [520/2566 (20%)]\tLoss: 1.219939\n",
      "Train Epoch: 26 [560/2566 (22%)]\tLoss: 0.221749\n",
      "Train Epoch: 26 [600/2566 (23%)]\tLoss: 0.339887\n",
      "Train Epoch: 26 [640/2566 (25%)]\tLoss: 0.519787\n",
      "Train Epoch: 26 [680/2566 (26%)]\tLoss: 0.530416\n",
      "Train Epoch: 26 [720/2566 (28%)]\tLoss: 0.422737\n",
      "Train Epoch: 26 [760/2566 (30%)]\tLoss: 1.159002\n",
      "Train Epoch: 26 [800/2566 (31%)]\tLoss: 1.084422\n",
      "Train Epoch: 26 [840/2566 (33%)]\tLoss: 0.636170\n",
      "Train Epoch: 26 [880/2566 (34%)]\tLoss: 0.804225\n",
      "Train Epoch: 26 [920/2566 (36%)]\tLoss: 0.777753\n",
      "Train Epoch: 26 [960/2566 (37%)]\tLoss: 0.478376\n",
      "Train Epoch: 26 [1000/2566 (39%)]\tLoss: 0.624061\n",
      "Train Epoch: 26 [1040/2566 (40%)]\tLoss: 0.273716\n",
      "Train Epoch: 26 [1080/2566 (42%)]\tLoss: 0.293219\n",
      "Train Epoch: 26 [1120/2566 (44%)]\tLoss: 0.627609\n",
      "Train Epoch: 26 [1160/2566 (45%)]\tLoss: 1.168935\n",
      "Train Epoch: 26 [1200/2566 (47%)]\tLoss: 0.329405\n",
      "Train Epoch: 26 [1240/2566 (48%)]\tLoss: 0.739962\n",
      "Train Epoch: 26 [1280/2566 (50%)]\tLoss: 0.639059\n",
      "Train Epoch: 26 [1320/2566 (51%)]\tLoss: 0.598708\n",
      "Train Epoch: 26 [1360/2566 (53%)]\tLoss: 1.148139\n",
      "Train Epoch: 26 [1400/2566 (55%)]\tLoss: 0.232710\n",
      "Train Epoch: 26 [1440/2566 (56%)]\tLoss: 0.619454\n",
      "Train Epoch: 26 [1480/2566 (58%)]\tLoss: 1.132661\n",
      "Train Epoch: 26 [1520/2566 (59%)]\tLoss: 0.877682\n",
      "Train Epoch: 26 [1560/2566 (61%)]\tLoss: 0.635469\n",
      "Train Epoch: 26 [1600/2566 (62%)]\tLoss: 0.204337\n",
      "Train Epoch: 26 [1640/2566 (64%)]\tLoss: 0.501159\n",
      "Train Epoch: 26 [1680/2566 (65%)]\tLoss: 1.519025\n",
      "Train Epoch: 26 [1720/2566 (67%)]\tLoss: 0.365185\n",
      "Train Epoch: 26 [1760/2566 (69%)]\tLoss: 0.313849\n",
      "Train Epoch: 26 [1800/2566 (70%)]\tLoss: 0.404839\n",
      "Train Epoch: 26 [1840/2566 (72%)]\tLoss: 0.409972\n",
      "Train Epoch: 26 [1880/2566 (73%)]\tLoss: 0.485189\n",
      "Train Epoch: 26 [1920/2566 (75%)]\tLoss: 0.541845\n",
      "Train Epoch: 26 [1960/2566 (76%)]\tLoss: 1.373559\n",
      "Train Epoch: 26 [2000/2566 (78%)]\tLoss: 0.924913\n",
      "Train Epoch: 26 [2040/2566 (79%)]\tLoss: 0.816061\n",
      "Train Epoch: 26 [2080/2566 (81%)]\tLoss: 0.209817\n",
      "Train Epoch: 26 [2120/2566 (83%)]\tLoss: 0.985577\n",
      "Train Epoch: 26 [2160/2566 (84%)]\tLoss: 0.173692\n",
      "Train Epoch: 26 [2200/2566 (86%)]\tLoss: 0.725795\n",
      "Train Epoch: 26 [2240/2566 (87%)]\tLoss: 0.901894\n",
      "Train Epoch: 26 [2280/2566 (89%)]\tLoss: 0.388107\n",
      "Train Epoch: 26 [2320/2566 (90%)]\tLoss: 0.513013\n",
      "Train Epoch: 26 [2360/2566 (92%)]\tLoss: 0.526442\n",
      "Train Epoch: 26 [2400/2566 (93%)]\tLoss: 0.370350\n",
      "Train Epoch: 26 [2440/2566 (95%)]\tLoss: 0.413556\n",
      "Train Epoch: 26 [2480/2566 (97%)]\tLoss: 0.549308\n",
      "Train Epoch: 26 [2520/2566 (98%)]\tLoss: 0.498353\n",
      "Train Epoch: 26 [2560/2566 (100%)]\tLoss: 0.426432\n",
      "epoch:26,loss:0.6842419474481423\n",
      "Train set: Average loss: 0.6064, Accuracy: 1926/2566 (75%)\n",
      "Val set: Average loss: 0.6390, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 27 [40/2566 (2%)]\tLoss: 0.247397\n",
      "Train Epoch: 27 [80/2566 (3%)]\tLoss: 0.318125\n",
      "Train Epoch: 27 [120/2566 (5%)]\tLoss: 0.551231\n",
      "Train Epoch: 27 [160/2566 (6%)]\tLoss: 0.696469\n",
      "Train Epoch: 27 [200/2566 (8%)]\tLoss: 0.633677\n",
      "Train Epoch: 27 [240/2566 (9%)]\tLoss: 0.702946\n",
      "Train Epoch: 27 [280/2566 (11%)]\tLoss: 0.529465\n",
      "Train Epoch: 27 [320/2566 (12%)]\tLoss: 1.045987\n",
      "Train Epoch: 27 [360/2566 (14%)]\tLoss: 0.719403\n",
      "Train Epoch: 27 [400/2566 (16%)]\tLoss: 0.531184\n",
      "Train Epoch: 27 [440/2566 (17%)]\tLoss: 0.499098\n",
      "Train Epoch: 27 [480/2566 (19%)]\tLoss: 0.734061\n",
      "Train Epoch: 27 [520/2566 (20%)]\tLoss: 0.896781\n",
      "Train Epoch: 27 [560/2566 (22%)]\tLoss: 0.887503\n",
      "Train Epoch: 27 [600/2566 (23%)]\tLoss: 0.971543\n",
      "Train Epoch: 27 [640/2566 (25%)]\tLoss: 0.769953\n",
      "Train Epoch: 27 [680/2566 (26%)]\tLoss: 0.716531\n",
      "Train Epoch: 27 [720/2566 (28%)]\tLoss: 1.136051\n",
      "Train Epoch: 27 [760/2566 (30%)]\tLoss: 0.770263\n",
      "Train Epoch: 27 [800/2566 (31%)]\tLoss: 0.971366\n",
      "Train Epoch: 27 [840/2566 (33%)]\tLoss: 0.405510\n",
      "Train Epoch: 27 [880/2566 (34%)]\tLoss: 0.271525\n",
      "Train Epoch: 27 [920/2566 (36%)]\tLoss: 0.541921\n",
      "Train Epoch: 27 [960/2566 (37%)]\tLoss: 0.529489\n",
      "Train Epoch: 27 [1000/2566 (39%)]\tLoss: 1.419868\n",
      "Train Epoch: 27 [1040/2566 (40%)]\tLoss: 0.170470\n",
      "Train Epoch: 27 [1080/2566 (42%)]\tLoss: 1.143971\n",
      "Train Epoch: 27 [1120/2566 (44%)]\tLoss: 0.923322\n",
      "Train Epoch: 27 [1160/2566 (45%)]\tLoss: 0.477730\n",
      "Train Epoch: 27 [1200/2566 (47%)]\tLoss: 1.124222\n",
      "Train Epoch: 27 [1240/2566 (48%)]\tLoss: 0.704826\n",
      "Train Epoch: 27 [1280/2566 (50%)]\tLoss: 0.491159\n",
      "Train Epoch: 27 [1320/2566 (51%)]\tLoss: 0.709382\n",
      "Train Epoch: 27 [1360/2566 (53%)]\tLoss: 0.751626\n",
      "Train Epoch: 27 [1400/2566 (55%)]\tLoss: 0.162781\n",
      "Train Epoch: 27 [1440/2566 (56%)]\tLoss: 0.201908\n",
      "Train Epoch: 27 [1480/2566 (58%)]\tLoss: 0.976242\n",
      "Train Epoch: 27 [1520/2566 (59%)]\tLoss: 1.030028\n",
      "Train Epoch: 27 [1560/2566 (61%)]\tLoss: 0.895064\n",
      "Train Epoch: 27 [1600/2566 (62%)]\tLoss: 0.623522\n",
      "Train Epoch: 27 [1640/2566 (64%)]\tLoss: 1.195086\n",
      "Train Epoch: 27 [1680/2566 (65%)]\tLoss: 0.516175\n",
      "Train Epoch: 27 [1720/2566 (67%)]\tLoss: 0.733926\n",
      "Train Epoch: 27 [1760/2566 (69%)]\tLoss: 0.357880\n",
      "Train Epoch: 27 [1800/2566 (70%)]\tLoss: 0.510922\n",
      "Train Epoch: 27 [1840/2566 (72%)]\tLoss: 0.971423\n",
      "Train Epoch: 27 [1880/2566 (73%)]\tLoss: 0.376768\n",
      "Train Epoch: 27 [1920/2566 (75%)]\tLoss: 0.593603\n",
      "Train Epoch: 27 [1960/2566 (76%)]\tLoss: 0.624439\n",
      "Train Epoch: 27 [2000/2566 (78%)]\tLoss: 1.025019\n",
      "Train Epoch: 27 [2040/2566 (79%)]\tLoss: 0.613651\n",
      "Train Epoch: 27 [2080/2566 (81%)]\tLoss: 0.222022\n",
      "Train Epoch: 27 [2120/2566 (83%)]\tLoss: 0.613501\n",
      "Train Epoch: 27 [2160/2566 (84%)]\tLoss: 0.816098\n",
      "Train Epoch: 27 [2200/2566 (86%)]\tLoss: 0.632510\n",
      "Train Epoch: 27 [2240/2566 (87%)]\tLoss: 0.293062\n",
      "Train Epoch: 27 [2280/2566 (89%)]\tLoss: 0.771998\n",
      "Train Epoch: 27 [2320/2566 (90%)]\tLoss: 0.259655\n",
      "Train Epoch: 27 [2360/2566 (92%)]\tLoss: 1.005383\n",
      "Train Epoch: 27 [2400/2566 (93%)]\tLoss: 0.446285\n",
      "Train Epoch: 27 [2440/2566 (95%)]\tLoss: 0.838543\n",
      "Train Epoch: 27 [2480/2566 (97%)]\tLoss: 0.661978\n",
      "Train Epoch: 27 [2520/2566 (98%)]\tLoss: 0.643039\n",
      "Train Epoch: 27 [2560/2566 (100%)]\tLoss: 0.488772\n",
      "epoch:27,loss:0.6699697236034358\n",
      "Train set: Average loss: 0.5958, Accuracy: 1933/2566 (75%)\n",
      "Val set: Average loss: 0.6380, Accuracy: 247/327 (76%)\n",
      "Train Epoch: 28 [40/2566 (2%)]\tLoss: 0.869547\n",
      "Train Epoch: 28 [80/2566 (3%)]\tLoss: 0.282760\n",
      "Train Epoch: 28 [120/2566 (5%)]\tLoss: 2.538651\n",
      "Train Epoch: 28 [160/2566 (6%)]\tLoss: 0.655585\n",
      "Train Epoch: 28 [200/2566 (8%)]\tLoss: 0.851179\n",
      "Train Epoch: 28 [240/2566 (9%)]\tLoss: 0.804542\n",
      "Train Epoch: 28 [280/2566 (11%)]\tLoss: 0.682929\n",
      "Train Epoch: 28 [320/2566 (12%)]\tLoss: 0.334641\n",
      "Train Epoch: 28 [360/2566 (14%)]\tLoss: 0.330267\n",
      "Train Epoch: 28 [400/2566 (16%)]\tLoss: 0.780547\n",
      "Train Epoch: 28 [440/2566 (17%)]\tLoss: 0.611233\n",
      "Train Epoch: 28 [480/2566 (19%)]\tLoss: 0.969419\n",
      "Train Epoch: 28 [520/2566 (20%)]\tLoss: 0.508921\n",
      "Train Epoch: 28 [560/2566 (22%)]\tLoss: 0.453351\n",
      "Train Epoch: 28 [600/2566 (23%)]\tLoss: 0.618809\n",
      "Train Epoch: 28 [640/2566 (25%)]\tLoss: 0.325742\n",
      "Train Epoch: 28 [680/2566 (26%)]\tLoss: 0.418525\n",
      "Train Epoch: 28 [720/2566 (28%)]\tLoss: 0.413228\n",
      "Train Epoch: 28 [760/2566 (30%)]\tLoss: 0.721215\n",
      "Train Epoch: 28 [800/2566 (31%)]\tLoss: 0.751907\n",
      "Train Epoch: 28 [840/2566 (33%)]\tLoss: 0.362150\n",
      "Train Epoch: 28 [880/2566 (34%)]\tLoss: 0.503888\n",
      "Train Epoch: 28 [920/2566 (36%)]\tLoss: 0.771576\n",
      "Train Epoch: 28 [960/2566 (37%)]\tLoss: 0.598296\n",
      "Train Epoch: 28 [1000/2566 (39%)]\tLoss: 0.585552\n",
      "Train Epoch: 28 [1040/2566 (40%)]\tLoss: 0.674349\n",
      "Train Epoch: 28 [1080/2566 (42%)]\tLoss: 1.171116\n",
      "Train Epoch: 28 [1120/2566 (44%)]\tLoss: 0.341108\n",
      "Train Epoch: 28 [1160/2566 (45%)]\tLoss: 1.059552\n",
      "Train Epoch: 28 [1200/2566 (47%)]\tLoss: 0.445111\n",
      "Train Epoch: 28 [1240/2566 (48%)]\tLoss: 0.945301\n",
      "Train Epoch: 28 [1280/2566 (50%)]\tLoss: 0.806506\n",
      "Train Epoch: 28 [1320/2566 (51%)]\tLoss: 0.444567\n",
      "Train Epoch: 28 [1360/2566 (53%)]\tLoss: 0.725792\n",
      "Train Epoch: 28 [1400/2566 (55%)]\tLoss: 0.813856\n",
      "Train Epoch: 28 [1440/2566 (56%)]\tLoss: 0.682115\n",
      "Train Epoch: 28 [1480/2566 (58%)]\tLoss: 0.615473\n",
      "Train Epoch: 28 [1520/2566 (59%)]\tLoss: 0.608492\n",
      "Train Epoch: 28 [1560/2566 (61%)]\tLoss: 0.976245\n",
      "Train Epoch: 28 [1600/2566 (62%)]\tLoss: 0.683913\n",
      "Train Epoch: 28 [1640/2566 (64%)]\tLoss: 0.679961\n",
      "Train Epoch: 28 [1680/2566 (65%)]\tLoss: 0.555110\n",
      "Train Epoch: 28 [1720/2566 (67%)]\tLoss: 0.857313\n",
      "Train Epoch: 28 [1760/2566 (69%)]\tLoss: 0.543344\n",
      "Train Epoch: 28 [1800/2566 (70%)]\tLoss: 0.653622\n",
      "Train Epoch: 28 [1840/2566 (72%)]\tLoss: 0.349252\n",
      "Train Epoch: 28 [1880/2566 (73%)]\tLoss: 0.680960\n",
      "Train Epoch: 28 [1920/2566 (75%)]\tLoss: 0.403893\n",
      "Train Epoch: 28 [1960/2566 (76%)]\tLoss: 0.304930\n",
      "Train Epoch: 28 [2000/2566 (78%)]\tLoss: 0.530120\n",
      "Train Epoch: 28 [2040/2566 (79%)]\tLoss: 0.297669\n",
      "Train Epoch: 28 [2080/2566 (81%)]\tLoss: 0.921440\n",
      "Train Epoch: 28 [2120/2566 (83%)]\tLoss: 0.317825\n",
      "Train Epoch: 28 [2160/2566 (84%)]\tLoss: 0.534481\n",
      "Train Epoch: 28 [2200/2566 (86%)]\tLoss: 0.849451\n",
      "Train Epoch: 28 [2240/2566 (87%)]\tLoss: 0.842095\n",
      "Train Epoch: 28 [2280/2566 (89%)]\tLoss: 0.664162\n",
      "Train Epoch: 28 [2320/2566 (90%)]\tLoss: 0.574646\n",
      "Train Epoch: 28 [2360/2566 (92%)]\tLoss: 0.763887\n",
      "Train Epoch: 28 [2400/2566 (93%)]\tLoss: 0.632061\n",
      "Train Epoch: 28 [2440/2566 (95%)]\tLoss: 0.662920\n",
      "Train Epoch: 28 [2480/2566 (97%)]\tLoss: 0.437951\n",
      "Train Epoch: 28 [2520/2566 (98%)]\tLoss: 0.382603\n",
      "Train Epoch: 28 [2560/2566 (100%)]\tLoss: 0.978264\n",
      "epoch:28,loss:0.6665477130179093\n",
      "Train set: Average loss: 0.5879, Accuracy: 1932/2566 (75%)\n",
      "Val set: Average loss: 0.6326, Accuracy: 247/327 (76%)\n",
      "Train Epoch: 29 [40/2566 (2%)]\tLoss: 0.504312\n",
      "Train Epoch: 29 [80/2566 (3%)]\tLoss: 0.331616\n",
      "Train Epoch: 29 [120/2566 (5%)]\tLoss: 0.525149\n",
      "Train Epoch: 29 [160/2566 (6%)]\tLoss: 0.469664\n",
      "Train Epoch: 29 [200/2566 (8%)]\tLoss: 0.663538\n",
      "Train Epoch: 29 [240/2566 (9%)]\tLoss: 0.222967\n",
      "Train Epoch: 29 [280/2566 (11%)]\tLoss: 0.933443\n",
      "Train Epoch: 29 [320/2566 (12%)]\tLoss: 0.491203\n",
      "Train Epoch: 29 [360/2566 (14%)]\tLoss: 0.970944\n",
      "Train Epoch: 29 [400/2566 (16%)]\tLoss: 0.741742\n",
      "Train Epoch: 29 [440/2566 (17%)]\tLoss: 0.404259\n",
      "Train Epoch: 29 [480/2566 (19%)]\tLoss: 0.815679\n",
      "Train Epoch: 29 [520/2566 (20%)]\tLoss: 0.342894\n",
      "Train Epoch: 29 [560/2566 (22%)]\tLoss: 0.794680\n",
      "Train Epoch: 29 [600/2566 (23%)]\tLoss: 0.155225\n",
      "Train Epoch: 29 [640/2566 (25%)]\tLoss: 0.391253\n",
      "Train Epoch: 29 [680/2566 (26%)]\tLoss: 0.573969\n",
      "Train Epoch: 29 [720/2566 (28%)]\tLoss: 0.789890\n",
      "Train Epoch: 29 [760/2566 (30%)]\tLoss: 0.871858\n",
      "Train Epoch: 29 [800/2566 (31%)]\tLoss: 0.992322\n",
      "Train Epoch: 29 [840/2566 (33%)]\tLoss: 0.722600\n",
      "Train Epoch: 29 [880/2566 (34%)]\tLoss: 0.572972\n",
      "Train Epoch: 29 [920/2566 (36%)]\tLoss: 0.539211\n",
      "Train Epoch: 29 [960/2566 (37%)]\tLoss: 1.073334\n",
      "Train Epoch: 29 [1000/2566 (39%)]\tLoss: 0.554167\n",
      "Train Epoch: 29 [1040/2566 (40%)]\tLoss: 0.451514\n",
      "Train Epoch: 29 [1080/2566 (42%)]\tLoss: 0.780359\n",
      "Train Epoch: 29 [1120/2566 (44%)]\tLoss: 0.792181\n",
      "Train Epoch: 29 [1160/2566 (45%)]\tLoss: 0.521406\n",
      "Train Epoch: 29 [1200/2566 (47%)]\tLoss: 0.427810\n",
      "Train Epoch: 29 [1240/2566 (48%)]\tLoss: 0.556538\n",
      "Train Epoch: 29 [1280/2566 (50%)]\tLoss: 1.133154\n",
      "Train Epoch: 29 [1320/2566 (51%)]\tLoss: 0.514149\n",
      "Train Epoch: 29 [1360/2566 (53%)]\tLoss: 1.065553\n",
      "Train Epoch: 29 [1400/2566 (55%)]\tLoss: 0.376100\n",
      "Train Epoch: 29 [1440/2566 (56%)]\tLoss: 0.544332\n",
      "Train Epoch: 29 [1480/2566 (58%)]\tLoss: 1.230047\n",
      "Train Epoch: 29 [1520/2566 (59%)]\tLoss: 0.781004\n",
      "Train Epoch: 29 [1560/2566 (61%)]\tLoss: 0.683658\n",
      "Train Epoch: 29 [1600/2566 (62%)]\tLoss: 0.487131\n",
      "Train Epoch: 29 [1640/2566 (64%)]\tLoss: 0.611401\n",
      "Train Epoch: 29 [1680/2566 (65%)]\tLoss: 0.502315\n",
      "Train Epoch: 29 [1720/2566 (67%)]\tLoss: 0.346932\n",
      "Train Epoch: 29 [1760/2566 (69%)]\tLoss: 0.344817\n",
      "Train Epoch: 29 [1800/2566 (70%)]\tLoss: 0.582770\n",
      "Train Epoch: 29 [1840/2566 (72%)]\tLoss: 0.354489\n",
      "Train Epoch: 29 [1880/2566 (73%)]\tLoss: 0.889479\n",
      "Train Epoch: 29 [1920/2566 (75%)]\tLoss: 0.911061\n",
      "Train Epoch: 29 [1960/2566 (76%)]\tLoss: 0.477903\n",
      "Train Epoch: 29 [2000/2566 (78%)]\tLoss: 0.911336\n",
      "Train Epoch: 29 [2040/2566 (79%)]\tLoss: 1.000157\n",
      "Train Epoch: 29 [2080/2566 (81%)]\tLoss: 0.703575\n",
      "Train Epoch: 29 [2120/2566 (83%)]\tLoss: 1.034344\n",
      "Train Epoch: 29 [2160/2566 (84%)]\tLoss: 0.515474\n",
      "Train Epoch: 29 [2200/2566 (86%)]\tLoss: 0.644895\n",
      "Train Epoch: 29 [2240/2566 (87%)]\tLoss: 0.717949\n",
      "Train Epoch: 29 [2280/2566 (89%)]\tLoss: 0.559111\n",
      "Train Epoch: 29 [2320/2566 (90%)]\tLoss: 0.702935\n",
      "Train Epoch: 29 [2360/2566 (92%)]\tLoss: 0.910296\n",
      "Train Epoch: 29 [2400/2566 (93%)]\tLoss: 0.420745\n",
      "Train Epoch: 29 [2440/2566 (95%)]\tLoss: 0.622437\n",
      "Train Epoch: 29 [2480/2566 (97%)]\tLoss: 0.793047\n",
      "Train Epoch: 29 [2520/2566 (98%)]\tLoss: 0.391973\n",
      "Train Epoch: 29 [2560/2566 (100%)]\tLoss: 0.819180\n",
      "epoch:29,loss:0.6545387722342928\n",
      "Train set: Average loss: 0.5789, Accuracy: 1935/2566 (75%)\n",
      "Val set: Average loss: 0.6328, Accuracy: 247/327 (76%)\n",
      "Train Epoch: 30 [40/2566 (2%)]\tLoss: 0.416236\n",
      "Train Epoch: 30 [80/2566 (3%)]\tLoss: 0.500119\n",
      "Train Epoch: 30 [120/2566 (5%)]\tLoss: 0.643062\n",
      "Train Epoch: 30 [160/2566 (6%)]\tLoss: 0.773482\n",
      "Train Epoch: 30 [200/2566 (8%)]\tLoss: 0.555160\n",
      "Train Epoch: 30 [240/2566 (9%)]\tLoss: 1.195916\n",
      "Train Epoch: 30 [280/2566 (11%)]\tLoss: 0.446154\n",
      "Train Epoch: 30 [320/2566 (12%)]\tLoss: 1.271518\n",
      "Train Epoch: 30 [360/2566 (14%)]\tLoss: 1.125797\n",
      "Train Epoch: 30 [400/2566 (16%)]\tLoss: 0.311819\n",
      "Train Epoch: 30 [440/2566 (17%)]\tLoss: 0.837327\n",
      "Train Epoch: 30 [480/2566 (19%)]\tLoss: 0.765251\n",
      "Train Epoch: 30 [520/2566 (20%)]\tLoss: 0.946827\n",
      "Train Epoch: 30 [560/2566 (22%)]\tLoss: 0.539554\n",
      "Train Epoch: 30 [600/2566 (23%)]\tLoss: 0.416628\n",
      "Train Epoch: 30 [640/2566 (25%)]\tLoss: 0.190559\n",
      "Train Epoch: 30 [680/2566 (26%)]\tLoss: 0.676128\n",
      "Train Epoch: 30 [720/2566 (28%)]\tLoss: 0.908070\n",
      "Train Epoch: 30 [760/2566 (30%)]\tLoss: 0.718702\n",
      "Train Epoch: 30 [800/2566 (31%)]\tLoss: 0.787182\n",
      "Train Epoch: 30 [840/2566 (33%)]\tLoss: 0.523884\n",
      "Train Epoch: 30 [880/2566 (34%)]\tLoss: 0.618918\n",
      "Train Epoch: 30 [920/2566 (36%)]\tLoss: 0.359885\n",
      "Train Epoch: 30 [960/2566 (37%)]\tLoss: 1.231979\n",
      "Train Epoch: 30 [1000/2566 (39%)]\tLoss: 0.385269\n",
      "Train Epoch: 30 [1040/2566 (40%)]\tLoss: 1.000956\n",
      "Train Epoch: 30 [1080/2566 (42%)]\tLoss: 2.204272\n",
      "Train Epoch: 30 [1120/2566 (44%)]\tLoss: 0.939143\n",
      "Train Epoch: 30 [1160/2566 (45%)]\tLoss: 0.229694\n",
      "Train Epoch: 30 [1200/2566 (47%)]\tLoss: 0.532087\n",
      "Train Epoch: 30 [1240/2566 (48%)]\tLoss: 0.553274\n",
      "Train Epoch: 30 [1280/2566 (50%)]\tLoss: 0.945844\n",
      "Train Epoch: 30 [1320/2566 (51%)]\tLoss: 0.221560\n",
      "Train Epoch: 30 [1360/2566 (53%)]\tLoss: 0.455109\n",
      "Train Epoch: 30 [1400/2566 (55%)]\tLoss: 0.512797\n",
      "Train Epoch: 30 [1440/2566 (56%)]\tLoss: 0.574178\n",
      "Train Epoch: 30 [1480/2566 (58%)]\tLoss: 0.786623\n",
      "Train Epoch: 30 [1520/2566 (59%)]\tLoss: 3.140621\n",
      "Train Epoch: 30 [1560/2566 (61%)]\tLoss: 0.544260\n",
      "Train Epoch: 30 [1600/2566 (62%)]\tLoss: 0.822680\n",
      "Train Epoch: 30 [1640/2566 (64%)]\tLoss: 0.377957\n",
      "Train Epoch: 30 [1680/2566 (65%)]\tLoss: 0.984851\n",
      "Train Epoch: 30 [1720/2566 (67%)]\tLoss: 0.423699\n",
      "Train Epoch: 30 [1760/2566 (69%)]\tLoss: 0.641295\n",
      "Train Epoch: 30 [1800/2566 (70%)]\tLoss: 0.642373\n",
      "Train Epoch: 30 [1840/2566 (72%)]\tLoss: 0.307268\n",
      "Train Epoch: 30 [1880/2566 (73%)]\tLoss: 1.019919\n",
      "Train Epoch: 30 [1920/2566 (75%)]\tLoss: 1.139946\n",
      "Train Epoch: 30 [1960/2566 (76%)]\tLoss: 0.409966\n",
      "Train Epoch: 30 [2000/2566 (78%)]\tLoss: 0.888077\n",
      "Train Epoch: 30 [2040/2566 (79%)]\tLoss: 0.306583\n",
      "Train Epoch: 30 [2080/2566 (81%)]\tLoss: 0.815852\n",
      "Train Epoch: 30 [2120/2566 (83%)]\tLoss: 0.514922\n",
      "Train Epoch: 30 [2160/2566 (84%)]\tLoss: 0.519327\n",
      "Train Epoch: 30 [2200/2566 (86%)]\tLoss: 0.203678\n",
      "Train Epoch: 30 [2240/2566 (87%)]\tLoss: 0.725535\n",
      "Train Epoch: 30 [2280/2566 (89%)]\tLoss: 0.592374\n",
      "Train Epoch: 30 [2320/2566 (90%)]\tLoss: 0.222453\n",
      "Train Epoch: 30 [2360/2566 (92%)]\tLoss: 0.859138\n",
      "Train Epoch: 30 [2400/2566 (93%)]\tLoss: 0.535412\n",
      "Train Epoch: 30 [2440/2566 (95%)]\tLoss: 0.524968\n",
      "Train Epoch: 30 [2480/2566 (97%)]\tLoss: 0.939863\n",
      "Train Epoch: 30 [2520/2566 (98%)]\tLoss: 0.851865\n",
      "Train Epoch: 30 [2560/2566 (100%)]\tLoss: 1.398546\n",
      "epoch:30,loss:0.6692440668556178\n",
      "Train set: Average loss: 0.5811, Accuracy: 1934/2566 (75%)\n",
      "Val set: Average loss: 0.6299, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 31 [40/2566 (2%)]\tLoss: 0.470585\n",
      "Train Epoch: 31 [80/2566 (3%)]\tLoss: 0.666673\n",
      "Train Epoch: 31 [120/2566 (5%)]\tLoss: 1.034019\n",
      "Train Epoch: 31 [160/2566 (6%)]\tLoss: 0.586634\n",
      "Train Epoch: 31 [200/2566 (8%)]\tLoss: 0.699984\n",
      "Train Epoch: 31 [240/2566 (9%)]\tLoss: 0.257999\n",
      "Train Epoch: 31 [280/2566 (11%)]\tLoss: 1.600888\n",
      "Train Epoch: 31 [320/2566 (12%)]\tLoss: 1.036457\n",
      "Train Epoch: 31 [360/2566 (14%)]\tLoss: 0.561557\n",
      "Train Epoch: 31 [400/2566 (16%)]\tLoss: 0.458825\n",
      "Train Epoch: 31 [440/2566 (17%)]\tLoss: 0.211765\n",
      "Train Epoch: 31 [480/2566 (19%)]\tLoss: 0.389686\n",
      "Train Epoch: 31 [520/2566 (20%)]\tLoss: 0.387079\n",
      "Train Epoch: 31 [560/2566 (22%)]\tLoss: 0.559764\n",
      "Train Epoch: 31 [600/2566 (23%)]\tLoss: 0.683169\n",
      "Train Epoch: 31 [640/2566 (25%)]\tLoss: 0.229515\n",
      "Train Epoch: 31 [680/2566 (26%)]\tLoss: 0.575536\n",
      "Train Epoch: 31 [720/2566 (28%)]\tLoss: 0.694120\n",
      "Train Epoch: 31 [760/2566 (30%)]\tLoss: 0.421189\n",
      "Train Epoch: 31 [800/2566 (31%)]\tLoss: 0.553457\n",
      "Train Epoch: 31 [840/2566 (33%)]\tLoss: 0.562511\n",
      "Train Epoch: 31 [880/2566 (34%)]\tLoss: 0.806558\n",
      "Train Epoch: 31 [920/2566 (36%)]\tLoss: 0.813815\n",
      "Train Epoch: 31 [960/2566 (37%)]\tLoss: 0.480085\n",
      "Train Epoch: 31 [1000/2566 (39%)]\tLoss: 0.641363\n",
      "Train Epoch: 31 [1040/2566 (40%)]\tLoss: 0.360893\n",
      "Train Epoch: 31 [1080/2566 (42%)]\tLoss: 0.911448\n",
      "Train Epoch: 31 [1120/2566 (44%)]\tLoss: 0.529361\n",
      "Train Epoch: 31 [1160/2566 (45%)]\tLoss: 0.559457\n",
      "Train Epoch: 31 [1200/2566 (47%)]\tLoss: 0.583864\n",
      "Train Epoch: 31 [1240/2566 (48%)]\tLoss: 0.313777\n",
      "Train Epoch: 31 [1280/2566 (50%)]\tLoss: 0.371101\n",
      "Train Epoch: 31 [1320/2566 (51%)]\tLoss: 0.576487\n",
      "Train Epoch: 31 [1360/2566 (53%)]\tLoss: 1.212938\n",
      "Train Epoch: 31 [1400/2566 (55%)]\tLoss: 0.306495\n",
      "Train Epoch: 31 [1440/2566 (56%)]\tLoss: 0.449072\n",
      "Train Epoch: 31 [1480/2566 (58%)]\tLoss: 0.144903\n",
      "Train Epoch: 31 [1520/2566 (59%)]\tLoss: 0.828246\n",
      "Train Epoch: 31 [1560/2566 (61%)]\tLoss: 0.331281\n",
      "Train Epoch: 31 [1600/2566 (62%)]\tLoss: 0.484593\n",
      "Train Epoch: 31 [1640/2566 (64%)]\tLoss: 0.906283\n",
      "Train Epoch: 31 [1680/2566 (65%)]\tLoss: 0.648513\n",
      "Train Epoch: 31 [1720/2566 (67%)]\tLoss: 1.343495\n",
      "Train Epoch: 31 [1760/2566 (69%)]\tLoss: 0.201302\n",
      "Train Epoch: 31 [1800/2566 (70%)]\tLoss: 0.584920\n",
      "Train Epoch: 31 [1840/2566 (72%)]\tLoss: 0.575379\n",
      "Train Epoch: 31 [1880/2566 (73%)]\tLoss: 1.104048\n",
      "Train Epoch: 31 [1920/2566 (75%)]\tLoss: 0.498977\n",
      "Train Epoch: 31 [1960/2566 (76%)]\tLoss: 0.634058\n",
      "Train Epoch: 31 [2000/2566 (78%)]\tLoss: 0.606766\n",
      "Train Epoch: 31 [2040/2566 (79%)]\tLoss: 0.323867\n",
      "Train Epoch: 31 [2080/2566 (81%)]\tLoss: 0.654009\n",
      "Train Epoch: 31 [2120/2566 (83%)]\tLoss: 0.477523\n",
      "Train Epoch: 31 [2160/2566 (84%)]\tLoss: 0.476423\n",
      "Train Epoch: 31 [2200/2566 (86%)]\tLoss: 1.047204\n",
      "Train Epoch: 31 [2240/2566 (87%)]\tLoss: 0.836538\n",
      "Train Epoch: 31 [2280/2566 (89%)]\tLoss: 1.099991\n",
      "Train Epoch: 31 [2320/2566 (90%)]\tLoss: 0.830459\n",
      "Train Epoch: 31 [2360/2566 (92%)]\tLoss: 0.828988\n",
      "Train Epoch: 31 [2400/2566 (93%)]\tLoss: 0.617031\n",
      "Train Epoch: 31 [2440/2566 (95%)]\tLoss: 0.799394\n",
      "Train Epoch: 31 [2480/2566 (97%)]\tLoss: 0.657520\n",
      "Train Epoch: 31 [2520/2566 (98%)]\tLoss: 1.319288\n",
      "Train Epoch: 31 [2560/2566 (100%)]\tLoss: 1.026611\n",
      "epoch:31,loss:0.6535446626189342\n",
      "Train set: Average loss: 0.5772, Accuracy: 1932/2566 (75%)\n",
      "Val set: Average loss: 0.6277, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 32 [40/2566 (2%)]\tLoss: 0.206593\n",
      "Train Epoch: 32 [80/2566 (3%)]\tLoss: 0.383556\n",
      "Train Epoch: 32 [120/2566 (5%)]\tLoss: 0.674222\n",
      "Train Epoch: 32 [160/2566 (6%)]\tLoss: 0.223949\n",
      "Train Epoch: 32 [200/2566 (8%)]\tLoss: 0.222111\n",
      "Train Epoch: 32 [240/2566 (9%)]\tLoss: 0.657166\n",
      "Train Epoch: 32 [280/2566 (11%)]\tLoss: 1.149670\n",
      "Train Epoch: 32 [320/2566 (12%)]\tLoss: 0.728097\n",
      "Train Epoch: 32 [360/2566 (14%)]\tLoss: 0.492557\n",
      "Train Epoch: 32 [400/2566 (16%)]\tLoss: 0.536087\n",
      "Train Epoch: 32 [440/2566 (17%)]\tLoss: 0.475078\n",
      "Train Epoch: 32 [480/2566 (19%)]\tLoss: 0.512659\n",
      "Train Epoch: 32 [520/2566 (20%)]\tLoss: 0.500360\n",
      "Train Epoch: 32 [560/2566 (22%)]\tLoss: 0.587552\n",
      "Train Epoch: 32 [600/2566 (23%)]\tLoss: 0.559301\n",
      "Train Epoch: 32 [640/2566 (25%)]\tLoss: 0.663988\n",
      "Train Epoch: 32 [680/2566 (26%)]\tLoss: 0.947663\n",
      "Train Epoch: 32 [720/2566 (28%)]\tLoss: 0.689036\n",
      "Train Epoch: 32 [760/2566 (30%)]\tLoss: 0.538185\n",
      "Train Epoch: 32 [800/2566 (31%)]\tLoss: 0.503934\n",
      "Train Epoch: 32 [840/2566 (33%)]\tLoss: 0.303765\n",
      "Train Epoch: 32 [880/2566 (34%)]\tLoss: 0.464590\n",
      "Train Epoch: 32 [920/2566 (36%)]\tLoss: 0.404007\n",
      "Train Epoch: 32 [960/2566 (37%)]\tLoss: 0.733429\n",
      "Train Epoch: 32 [1000/2566 (39%)]\tLoss: 0.553994\n",
      "Train Epoch: 32 [1040/2566 (40%)]\tLoss: 0.519278\n",
      "Train Epoch: 32 [1080/2566 (42%)]\tLoss: 0.518516\n",
      "Train Epoch: 32 [1120/2566 (44%)]\tLoss: 0.868995\n",
      "Train Epoch: 32 [1160/2566 (45%)]\tLoss: 0.192395\n",
      "Train Epoch: 32 [1200/2566 (47%)]\tLoss: 1.344539\n",
      "Train Epoch: 32 [1240/2566 (48%)]\tLoss: 0.556006\n",
      "Train Epoch: 32 [1280/2566 (50%)]\tLoss: 0.741583\n",
      "Train Epoch: 32 [1320/2566 (51%)]\tLoss: 0.816035\n",
      "Train Epoch: 32 [1360/2566 (53%)]\tLoss: 0.667184\n",
      "Train Epoch: 32 [1400/2566 (55%)]\tLoss: 0.841941\n",
      "Train Epoch: 32 [1440/2566 (56%)]\tLoss: 0.546973\n",
      "Train Epoch: 32 [1480/2566 (58%)]\tLoss: 0.324345\n",
      "Train Epoch: 32 [1520/2566 (59%)]\tLoss: 0.364650\n",
      "Train Epoch: 32 [1560/2566 (61%)]\tLoss: 0.616412\n",
      "Train Epoch: 32 [1600/2566 (62%)]\tLoss: 0.831091\n",
      "Train Epoch: 32 [1640/2566 (64%)]\tLoss: 1.074064\n",
      "Train Epoch: 32 [1680/2566 (65%)]\tLoss: 0.442058\n",
      "Train Epoch: 32 [1720/2566 (67%)]\tLoss: 0.682325\n",
      "Train Epoch: 32 [1760/2566 (69%)]\tLoss: 0.532362\n",
      "Train Epoch: 32 [1800/2566 (70%)]\tLoss: 0.569301\n",
      "Train Epoch: 32 [1840/2566 (72%)]\tLoss: 0.577717\n",
      "Train Epoch: 32 [1880/2566 (73%)]\tLoss: 0.512508\n",
      "Train Epoch: 32 [1920/2566 (75%)]\tLoss: 0.534782\n",
      "Train Epoch: 32 [1960/2566 (76%)]\tLoss: 0.660493\n",
      "Train Epoch: 32 [2000/2566 (78%)]\tLoss: 0.678419\n",
      "Train Epoch: 32 [2040/2566 (79%)]\tLoss: 0.566686\n",
      "Train Epoch: 32 [2080/2566 (81%)]\tLoss: 0.418211\n",
      "Train Epoch: 32 [2120/2566 (83%)]\tLoss: 0.680616\n",
      "Train Epoch: 32 [2160/2566 (84%)]\tLoss: 0.853719\n",
      "Train Epoch: 32 [2200/2566 (86%)]\tLoss: 0.950217\n",
      "Train Epoch: 32 [2240/2566 (87%)]\tLoss: 0.364072\n",
      "Train Epoch: 32 [2280/2566 (89%)]\tLoss: 0.828612\n",
      "Train Epoch: 32 [2320/2566 (90%)]\tLoss: 0.540388\n",
      "Train Epoch: 32 [2360/2566 (92%)]\tLoss: 1.077419\n",
      "Train Epoch: 32 [2400/2566 (93%)]\tLoss: 0.451054\n",
      "Train Epoch: 32 [2440/2566 (95%)]\tLoss: 0.586728\n",
      "Train Epoch: 32 [2480/2566 (97%)]\tLoss: 0.558930\n",
      "Train Epoch: 32 [2520/2566 (98%)]\tLoss: 1.015649\n",
      "Train Epoch: 32 [2560/2566 (100%)]\tLoss: 0.756666\n",
      "epoch:32,loss:0.6360436617585358\n",
      "Train set: Average loss: 0.5663, Accuracy: 1936/2566 (75%)\n",
      "Val set: Average loss: 0.6165, Accuracy: 248/327 (76%)\n",
      "Train Epoch: 33 [40/2566 (2%)]\tLoss: 0.736492\n",
      "Train Epoch: 33 [80/2566 (3%)]\tLoss: 0.803221\n",
      "Train Epoch: 33 [120/2566 (5%)]\tLoss: 0.477451\n",
      "Train Epoch: 33 [160/2566 (6%)]\tLoss: 0.207256\n",
      "Train Epoch: 33 [200/2566 (8%)]\tLoss: 0.570499\n",
      "Train Epoch: 33 [240/2566 (9%)]\tLoss: 0.865622\n",
      "Train Epoch: 33 [280/2566 (11%)]\tLoss: 0.673557\n",
      "Train Epoch: 33 [320/2566 (12%)]\tLoss: 0.671865\n",
      "Train Epoch: 33 [360/2566 (14%)]\tLoss: 0.694307\n",
      "Train Epoch: 33 [400/2566 (16%)]\tLoss: 0.778012\n",
      "Train Epoch: 33 [440/2566 (17%)]\tLoss: 0.515556\n",
      "Train Epoch: 33 [480/2566 (19%)]\tLoss: 0.286135\n",
      "Train Epoch: 33 [520/2566 (20%)]\tLoss: 0.753190\n",
      "Train Epoch: 33 [560/2566 (22%)]\tLoss: 0.305936\n",
      "Train Epoch: 33 [600/2566 (23%)]\tLoss: 1.360100\n",
      "Train Epoch: 33 [640/2566 (25%)]\tLoss: 0.472733\n",
      "Train Epoch: 33 [680/2566 (26%)]\tLoss: 0.641500\n",
      "Train Epoch: 33 [720/2566 (28%)]\tLoss: 0.317121\n",
      "Train Epoch: 33 [760/2566 (30%)]\tLoss: 0.616726\n",
      "Train Epoch: 33 [800/2566 (31%)]\tLoss: 0.349714\n",
      "Train Epoch: 33 [840/2566 (33%)]\tLoss: 0.467485\n",
      "Train Epoch: 33 [880/2566 (34%)]\tLoss: 0.258583\n",
      "Train Epoch: 33 [920/2566 (36%)]\tLoss: 0.312205\n",
      "Train Epoch: 33 [960/2566 (37%)]\tLoss: 0.530714\n",
      "Train Epoch: 33 [1000/2566 (39%)]\tLoss: 0.556167\n",
      "Train Epoch: 33 [1040/2566 (40%)]\tLoss: 1.409496\n",
      "Train Epoch: 33 [1080/2566 (42%)]\tLoss: 0.646958\n",
      "Train Epoch: 33 [1120/2566 (44%)]\tLoss: 0.419117\n",
      "Train Epoch: 33 [1160/2566 (45%)]\tLoss: 0.503617\n",
      "Train Epoch: 33 [1200/2566 (47%)]\tLoss: 0.590539\n",
      "Train Epoch: 33 [1240/2566 (48%)]\tLoss: 0.557653\n",
      "Train Epoch: 33 [1280/2566 (50%)]\tLoss: 0.507033\n",
      "Train Epoch: 33 [1320/2566 (51%)]\tLoss: 1.121067\n",
      "Train Epoch: 33 [1360/2566 (53%)]\tLoss: 0.652023\n",
      "Train Epoch: 33 [1400/2566 (55%)]\tLoss: 0.577942\n",
      "Train Epoch: 33 [1440/2566 (56%)]\tLoss: 0.620816\n",
      "Train Epoch: 33 [1480/2566 (58%)]\tLoss: 0.352850\n",
      "Train Epoch: 33 [1520/2566 (59%)]\tLoss: 0.642370\n",
      "Train Epoch: 33 [1560/2566 (61%)]\tLoss: 0.298215\n",
      "Train Epoch: 33 [1600/2566 (62%)]\tLoss: 0.972724\n",
      "Train Epoch: 33 [1640/2566 (64%)]\tLoss: 0.954290\n",
      "Train Epoch: 33 [1680/2566 (65%)]\tLoss: 1.841519\n",
      "Train Epoch: 33 [1720/2566 (67%)]\tLoss: 0.530387\n",
      "Train Epoch: 33 [1760/2566 (69%)]\tLoss: 0.197292\n",
      "Train Epoch: 33 [1800/2566 (70%)]\tLoss: 0.622131\n",
      "Train Epoch: 33 [1840/2566 (72%)]\tLoss: 0.733109\n",
      "Train Epoch: 33 [1880/2566 (73%)]\tLoss: 0.687784\n",
      "Train Epoch: 33 [1920/2566 (75%)]\tLoss: 0.339451\n",
      "Train Epoch: 33 [1960/2566 (76%)]\tLoss: 0.299297\n",
      "Train Epoch: 33 [2000/2566 (78%)]\tLoss: 0.856879\n",
      "Train Epoch: 33 [2040/2566 (79%)]\tLoss: 0.653909\n",
      "Train Epoch: 33 [2080/2566 (81%)]\tLoss: 0.839227\n",
      "Train Epoch: 33 [2120/2566 (83%)]\tLoss: 0.621760\n",
      "Train Epoch: 33 [2160/2566 (84%)]\tLoss: 0.704053\n",
      "Train Epoch: 33 [2200/2566 (86%)]\tLoss: 0.326443\n",
      "Train Epoch: 33 [2240/2566 (87%)]\tLoss: 0.399656\n",
      "Train Epoch: 33 [2280/2566 (89%)]\tLoss: 0.429715\n",
      "Train Epoch: 33 [2320/2566 (90%)]\tLoss: 0.744361\n",
      "Train Epoch: 33 [2360/2566 (92%)]\tLoss: 0.680072\n",
      "Train Epoch: 33 [2400/2566 (93%)]\tLoss: 0.787669\n",
      "Train Epoch: 33 [2440/2566 (95%)]\tLoss: 0.571292\n",
      "Train Epoch: 33 [2480/2566 (97%)]\tLoss: 0.629777\n",
      "Train Epoch: 33 [2520/2566 (98%)]\tLoss: 0.821258\n",
      "Train Epoch: 33 [2560/2566 (100%)]\tLoss: 0.308498\n",
      "epoch:33,loss:0.6251011622657657\n",
      "Train set: Average loss: 0.5615, Accuracy: 1938/2566 (76%)\n",
      "Val set: Average loss: 0.6167, Accuracy: 247/327 (76%)\n",
      "Train Epoch: 34 [40/2566 (2%)]\tLoss: 0.515790\n",
      "Train Epoch: 34 [80/2566 (3%)]\tLoss: 0.208538\n",
      "Train Epoch: 34 [120/2566 (5%)]\tLoss: 1.268619\n",
      "Train Epoch: 34 [160/2566 (6%)]\tLoss: 0.330383\n",
      "Train Epoch: 34 [200/2566 (8%)]\tLoss: 0.340642\n",
      "Train Epoch: 34 [240/2566 (9%)]\tLoss: 1.083800\n",
      "Train Epoch: 34 [280/2566 (11%)]\tLoss: 0.298046\n",
      "Train Epoch: 34 [320/2566 (12%)]\tLoss: 0.702380\n",
      "Train Epoch: 34 [360/2566 (14%)]\tLoss: 0.782508\n",
      "Train Epoch: 34 [400/2566 (16%)]\tLoss: 0.726008\n",
      "Train Epoch: 34 [440/2566 (17%)]\tLoss: 0.705819\n",
      "Train Epoch: 34 [480/2566 (19%)]\tLoss: 0.654805\n",
      "Train Epoch: 34 [520/2566 (20%)]\tLoss: 0.288229\n",
      "Train Epoch: 34 [560/2566 (22%)]\tLoss: 1.133298\n",
      "Train Epoch: 34 [600/2566 (23%)]\tLoss: 1.310595\n",
      "Train Epoch: 34 [640/2566 (25%)]\tLoss: 0.688597\n",
      "Train Epoch: 34 [680/2566 (26%)]\tLoss: 0.681159\n",
      "Train Epoch: 34 [720/2566 (28%)]\tLoss: 1.239694\n",
      "Train Epoch: 34 [760/2566 (30%)]\tLoss: 0.445799\n",
      "Train Epoch: 34 [800/2566 (31%)]\tLoss: 0.722439\n",
      "Train Epoch: 34 [840/2566 (33%)]\tLoss: 0.511601\n",
      "Train Epoch: 34 [880/2566 (34%)]\tLoss: 0.697447\n",
      "Train Epoch: 34 [920/2566 (36%)]\tLoss: 0.526611\n",
      "Train Epoch: 34 [960/2566 (37%)]\tLoss: 0.480838\n",
      "Train Epoch: 34 [1000/2566 (39%)]\tLoss: 0.524030\n",
      "Train Epoch: 34 [1040/2566 (40%)]\tLoss: 0.403111\n",
      "Train Epoch: 34 [1080/2566 (42%)]\tLoss: 0.407568\n",
      "Train Epoch: 34 [1120/2566 (44%)]\tLoss: 1.021323\n",
      "Train Epoch: 34 [1160/2566 (45%)]\tLoss: 0.504749\n",
      "Train Epoch: 34 [1200/2566 (47%)]\tLoss: 0.573030\n",
      "Train Epoch: 34 [1240/2566 (48%)]\tLoss: 0.444079\n",
      "Train Epoch: 34 [1280/2566 (50%)]\tLoss: 0.604200\n",
      "Train Epoch: 34 [1320/2566 (51%)]\tLoss: 0.298318\n",
      "Train Epoch: 34 [1360/2566 (53%)]\tLoss: 0.892299\n",
      "Train Epoch: 34 [1400/2566 (55%)]\tLoss: 0.157279\n",
      "Train Epoch: 34 [1440/2566 (56%)]\tLoss: 0.425588\n",
      "Train Epoch: 34 [1480/2566 (58%)]\tLoss: 0.635739\n",
      "Train Epoch: 34 [1520/2566 (59%)]\tLoss: 0.565408\n",
      "Train Epoch: 34 [1560/2566 (61%)]\tLoss: 0.600575\n",
      "Train Epoch: 34 [1600/2566 (62%)]\tLoss: 0.668792\n",
      "Train Epoch: 34 [1640/2566 (64%)]\tLoss: 0.167009\n",
      "Train Epoch: 34 [1680/2566 (65%)]\tLoss: 0.619616\n",
      "Train Epoch: 34 [1720/2566 (67%)]\tLoss: 0.300635\n",
      "Train Epoch: 34 [1760/2566 (69%)]\tLoss: 0.673403\n",
      "Train Epoch: 34 [1800/2566 (70%)]\tLoss: 0.528932\n",
      "Train Epoch: 34 [1840/2566 (72%)]\tLoss: 0.680943\n",
      "Train Epoch: 34 [1880/2566 (73%)]\tLoss: 0.420784\n",
      "Train Epoch: 34 [1920/2566 (75%)]\tLoss: 0.834944\n",
      "Train Epoch: 34 [1960/2566 (76%)]\tLoss: 0.750432\n",
      "Train Epoch: 34 [2000/2566 (78%)]\tLoss: 0.564046\n",
      "Train Epoch: 34 [2040/2566 (79%)]\tLoss: 0.543218\n",
      "Train Epoch: 34 [2080/2566 (81%)]\tLoss: 0.556245\n",
      "Train Epoch: 34 [2120/2566 (83%)]\tLoss: 0.718467\n",
      "Train Epoch: 34 [2160/2566 (84%)]\tLoss: 0.498640\n",
      "Train Epoch: 34 [2200/2566 (86%)]\tLoss: 0.163763\n",
      "Train Epoch: 34 [2240/2566 (87%)]\tLoss: 0.849745\n",
      "Train Epoch: 34 [2280/2566 (89%)]\tLoss: 0.293685\n",
      "Train Epoch: 34 [2320/2566 (90%)]\tLoss: 0.686423\n",
      "Train Epoch: 34 [2360/2566 (92%)]\tLoss: 0.627790\n",
      "Train Epoch: 34 [2400/2566 (93%)]\tLoss: 0.476848\n",
      "Train Epoch: 34 [2440/2566 (95%)]\tLoss: 0.151327\n",
      "Train Epoch: 34 [2480/2566 (97%)]\tLoss: 0.327272\n",
      "Train Epoch: 34 [2520/2566 (98%)]\tLoss: 0.469484\n",
      "Train Epoch: 34 [2560/2566 (100%)]\tLoss: 0.713332\n",
      "epoch:34,loss:0.6269602860756381\n",
      "Train set: Average loss: 0.5634, Accuracy: 1937/2566 (75%)\n",
      "Val set: Average loss: 0.6187, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 35 [40/2566 (2%)]\tLoss: 0.439386\n",
      "Train Epoch: 35 [80/2566 (3%)]\tLoss: 0.247559\n",
      "Train Epoch: 35 [120/2566 (5%)]\tLoss: 0.694247\n",
      "Train Epoch: 35 [160/2566 (6%)]\tLoss: 0.687000\n",
      "Train Epoch: 35 [200/2566 (8%)]\tLoss: 0.908285\n",
      "Train Epoch: 35 [240/2566 (9%)]\tLoss: 0.488339\n",
      "Train Epoch: 35 [280/2566 (11%)]\tLoss: 0.701252\n",
      "Train Epoch: 35 [320/2566 (12%)]\tLoss: 1.171203\n",
      "Train Epoch: 35 [360/2566 (14%)]\tLoss: 0.539637\n",
      "Train Epoch: 35 [400/2566 (16%)]\tLoss: 0.619898\n",
      "Train Epoch: 35 [440/2566 (17%)]\tLoss: 0.459819\n",
      "Train Epoch: 35 [480/2566 (19%)]\tLoss: 1.041879\n",
      "Train Epoch: 35 [520/2566 (20%)]\tLoss: 0.752291\n",
      "Train Epoch: 35 [560/2566 (22%)]\tLoss: 0.754168\n",
      "Train Epoch: 35 [600/2566 (23%)]\tLoss: 0.683929\n",
      "Train Epoch: 35 [640/2566 (25%)]\tLoss: 0.732134\n",
      "Train Epoch: 35 [680/2566 (26%)]\tLoss: 0.879757\n",
      "Train Epoch: 35 [720/2566 (28%)]\tLoss: 0.969212\n",
      "Train Epoch: 35 [760/2566 (30%)]\tLoss: 0.478020\n",
      "Train Epoch: 35 [800/2566 (31%)]\tLoss: 0.772844\n",
      "Train Epoch: 35 [840/2566 (33%)]\tLoss: 0.880852\n",
      "Train Epoch: 35 [880/2566 (34%)]\tLoss: 1.038269\n",
      "Train Epoch: 35 [920/2566 (36%)]\tLoss: 0.676431\n",
      "Train Epoch: 35 [960/2566 (37%)]\tLoss: 0.345412\n",
      "Train Epoch: 35 [1000/2566 (39%)]\tLoss: 0.311061\n",
      "Train Epoch: 35 [1040/2566 (40%)]\tLoss: 0.571522\n",
      "Train Epoch: 35 [1080/2566 (42%)]\tLoss: 0.546209\n",
      "Train Epoch: 35 [1120/2566 (44%)]\tLoss: 0.195878\n",
      "Train Epoch: 35 [1160/2566 (45%)]\tLoss: 1.021784\n",
      "Train Epoch: 35 [1200/2566 (47%)]\tLoss: 0.352362\n",
      "Train Epoch: 35 [1240/2566 (48%)]\tLoss: 0.395915\n",
      "Train Epoch: 35 [1280/2566 (50%)]\tLoss: 0.440621\n",
      "Train Epoch: 35 [1320/2566 (51%)]\tLoss: 0.625947\n",
      "Train Epoch: 35 [1360/2566 (53%)]\tLoss: 0.818231\n",
      "Train Epoch: 35 [1400/2566 (55%)]\tLoss: 0.930868\n",
      "Train Epoch: 35 [1440/2566 (56%)]\tLoss: 0.519778\n",
      "Train Epoch: 35 [1480/2566 (58%)]\tLoss: 0.563961\n",
      "Train Epoch: 35 [1520/2566 (59%)]\tLoss: 0.528663\n",
      "Train Epoch: 35 [1560/2566 (61%)]\tLoss: 0.740271\n",
      "Train Epoch: 35 [1600/2566 (62%)]\tLoss: 0.394584\n",
      "Train Epoch: 35 [1640/2566 (64%)]\tLoss: 0.760110\n",
      "Train Epoch: 35 [1680/2566 (65%)]\tLoss: 0.310488\n",
      "Train Epoch: 35 [1720/2566 (67%)]\tLoss: 1.040679\n",
      "Train Epoch: 35 [1760/2566 (69%)]\tLoss: 0.151123\n",
      "Train Epoch: 35 [1800/2566 (70%)]\tLoss: 0.958288\n",
      "Train Epoch: 35 [1840/2566 (72%)]\tLoss: 0.808630\n",
      "Train Epoch: 35 [1880/2566 (73%)]\tLoss: 0.602569\n",
      "Train Epoch: 35 [1920/2566 (75%)]\tLoss: 0.321275\n",
      "Train Epoch: 35 [1960/2566 (76%)]\tLoss: 0.356142\n",
      "Train Epoch: 35 [2000/2566 (78%)]\tLoss: 0.205051\n",
      "Train Epoch: 35 [2040/2566 (79%)]\tLoss: 0.504654\n",
      "Train Epoch: 35 [2080/2566 (81%)]\tLoss: 0.929693\n",
      "Train Epoch: 35 [2120/2566 (83%)]\tLoss: 0.381471\n",
      "Train Epoch: 35 [2160/2566 (84%)]\tLoss: 0.305162\n",
      "Train Epoch: 35 [2200/2566 (86%)]\tLoss: 0.769607\n",
      "Train Epoch: 35 [2240/2566 (87%)]\tLoss: 0.754009\n",
      "Train Epoch: 35 [2280/2566 (89%)]\tLoss: 0.257493\n",
      "Train Epoch: 35 [2320/2566 (90%)]\tLoss: 0.420618\n",
      "Train Epoch: 35 [2360/2566 (92%)]\tLoss: 0.800747\n",
      "Train Epoch: 35 [2400/2566 (93%)]\tLoss: 0.650037\n",
      "Train Epoch: 35 [2440/2566 (95%)]\tLoss: 0.850270\n",
      "Train Epoch: 35 [2480/2566 (97%)]\tLoss: 0.777108\n",
      "Train Epoch: 35 [2520/2566 (98%)]\tLoss: 0.296546\n",
      "Train Epoch: 35 [2560/2566 (100%)]\tLoss: 0.599390\n",
      "epoch:35,loss:0.6228654235137214\n",
      "Train set: Average loss: 0.5520, Accuracy: 1940/2566 (76%)\n",
      "Val set: Average loss: 0.6133, Accuracy: 247/327 (76%)\n",
      "Train Epoch: 36 [40/2566 (2%)]\tLoss: 0.298497\n",
      "Train Epoch: 36 [80/2566 (3%)]\tLoss: 0.144928\n",
      "Train Epoch: 36 [120/2566 (5%)]\tLoss: 0.640220\n",
      "Train Epoch: 36 [160/2566 (6%)]\tLoss: 0.871071\n",
      "Train Epoch: 36 [200/2566 (8%)]\tLoss: 0.643084\n",
      "Train Epoch: 36 [240/2566 (9%)]\tLoss: 0.949183\n",
      "Train Epoch: 36 [280/2566 (11%)]\tLoss: 0.616236\n",
      "Train Epoch: 36 [320/2566 (12%)]\tLoss: 0.404891\n",
      "Train Epoch: 36 [360/2566 (14%)]\tLoss: 1.022345\n",
      "Train Epoch: 36 [400/2566 (16%)]\tLoss: 0.758887\n",
      "Train Epoch: 36 [440/2566 (17%)]\tLoss: 0.463474\n",
      "Train Epoch: 36 [480/2566 (19%)]\tLoss: 0.346738\n",
      "Train Epoch: 36 [520/2566 (20%)]\tLoss: 0.524901\n",
      "Train Epoch: 36 [560/2566 (22%)]\tLoss: 0.867829\n",
      "Train Epoch: 36 [600/2566 (23%)]\tLoss: 0.798143\n",
      "Train Epoch: 36 [640/2566 (25%)]\tLoss: 0.629162\n",
      "Train Epoch: 36 [680/2566 (26%)]\tLoss: 0.275530\n",
      "Train Epoch: 36 [720/2566 (28%)]\tLoss: 0.713294\n",
      "Train Epoch: 36 [760/2566 (30%)]\tLoss: 0.569415\n",
      "Train Epoch: 36 [800/2566 (31%)]\tLoss: 0.399278\n",
      "Train Epoch: 36 [840/2566 (33%)]\tLoss: 0.832874\n",
      "Train Epoch: 36 [880/2566 (34%)]\tLoss: 0.200345\n",
      "Train Epoch: 36 [920/2566 (36%)]\tLoss: 0.308987\n",
      "Train Epoch: 36 [960/2566 (37%)]\tLoss: 0.529290\n",
      "Train Epoch: 36 [1000/2566 (39%)]\tLoss: 0.569267\n",
      "Train Epoch: 36 [1040/2566 (40%)]\tLoss: 0.753541\n",
      "Train Epoch: 36 [1080/2566 (42%)]\tLoss: 0.472820\n",
      "Train Epoch: 36 [1120/2566 (44%)]\tLoss: 1.232970\n",
      "Train Epoch: 36 [1160/2566 (45%)]\tLoss: 0.217131\n",
      "Train Epoch: 36 [1200/2566 (47%)]\tLoss: 1.285703\n",
      "Train Epoch: 36 [1240/2566 (48%)]\tLoss: 0.463133\n",
      "Train Epoch: 36 [1280/2566 (50%)]\tLoss: 0.172184\n",
      "Train Epoch: 36 [1320/2566 (51%)]\tLoss: 0.335348\n",
      "Train Epoch: 36 [1360/2566 (53%)]\tLoss: 0.725311\n",
      "Train Epoch: 36 [1400/2566 (55%)]\tLoss: 0.603192\n",
      "Train Epoch: 36 [1440/2566 (56%)]\tLoss: 0.840753\n",
      "Train Epoch: 36 [1480/2566 (58%)]\tLoss: 0.809044\n",
      "Train Epoch: 36 [1520/2566 (59%)]\tLoss: 0.468487\n",
      "Train Epoch: 36 [1560/2566 (61%)]\tLoss: 0.376287\n",
      "Train Epoch: 36 [1600/2566 (62%)]\tLoss: 0.335064\n",
      "Train Epoch: 36 [1640/2566 (64%)]\tLoss: 0.629162\n",
      "Train Epoch: 36 [1680/2566 (65%)]\tLoss: 0.521428\n",
      "Train Epoch: 36 [1720/2566 (67%)]\tLoss: 0.331218\n",
      "Train Epoch: 36 [1760/2566 (69%)]\tLoss: 0.793606\n",
      "Train Epoch: 36 [1800/2566 (70%)]\tLoss: 0.658042\n",
      "Train Epoch: 36 [1840/2566 (72%)]\tLoss: 0.962490\n",
      "Train Epoch: 36 [1880/2566 (73%)]\tLoss: 0.985633\n",
      "Train Epoch: 36 [1920/2566 (75%)]\tLoss: 0.533290\n",
      "Train Epoch: 36 [1960/2566 (76%)]\tLoss: 0.473243\n",
      "Train Epoch: 36 [2000/2566 (78%)]\tLoss: 0.518717\n",
      "Train Epoch: 36 [2040/2566 (79%)]\tLoss: 0.402749\n",
      "Train Epoch: 36 [2080/2566 (81%)]\tLoss: 0.326793\n",
      "Train Epoch: 36 [2120/2566 (83%)]\tLoss: 0.276722\n",
      "Train Epoch: 36 [2160/2566 (84%)]\tLoss: 0.481573\n",
      "Train Epoch: 36 [2200/2566 (86%)]\tLoss: 0.915840\n",
      "Train Epoch: 36 [2240/2566 (87%)]\tLoss: 0.123612\n",
      "Train Epoch: 36 [2280/2566 (89%)]\tLoss: 0.298065\n",
      "Train Epoch: 36 [2320/2566 (90%)]\tLoss: 1.014208\n",
      "Train Epoch: 36 [2360/2566 (92%)]\tLoss: 0.894211\n",
      "Train Epoch: 36 [2400/2566 (93%)]\tLoss: 0.572766\n",
      "Train Epoch: 36 [2440/2566 (95%)]\tLoss: 0.536250\n",
      "Train Epoch: 36 [2480/2566 (97%)]\tLoss: 0.999304\n",
      "Train Epoch: 36 [2520/2566 (98%)]\tLoss: 0.506969\n",
      "Train Epoch: 36 [2560/2566 (100%)]\tLoss: 0.479985\n",
      "epoch:36,loss:0.6074552257948576\n",
      "Train set: Average loss: 0.5542, Accuracy: 1938/2566 (76%)\n",
      "Val set: Average loss: 0.6195, Accuracy: 246/327 (75%)\n",
      "Train Epoch: 37 [40/2566 (2%)]\tLoss: 0.306108\n",
      "Train Epoch: 37 [80/2566 (3%)]\tLoss: 0.459399\n",
      "Train Epoch: 37 [120/2566 (5%)]\tLoss: 0.683416\n",
      "Train Epoch: 37 [160/2566 (6%)]\tLoss: 0.498606\n",
      "Train Epoch: 37 [200/2566 (8%)]\tLoss: 0.697107\n",
      "Train Epoch: 37 [240/2566 (9%)]\tLoss: 0.579615\n",
      "Train Epoch: 37 [280/2566 (11%)]\tLoss: 0.546547\n",
      "Train Epoch: 37 [320/2566 (12%)]\tLoss: 0.784034\n",
      "Train Epoch: 37 [360/2566 (14%)]\tLoss: 0.522580\n",
      "Train Epoch: 37 [400/2566 (16%)]\tLoss: 0.303272\n",
      "Train Epoch: 37 [440/2566 (17%)]\tLoss: 0.354127\n",
      "Train Epoch: 37 [480/2566 (19%)]\tLoss: 0.543517\n",
      "Train Epoch: 37 [520/2566 (20%)]\tLoss: 0.486978\n",
      "Train Epoch: 37 [560/2566 (22%)]\tLoss: 0.134529\n",
      "Train Epoch: 37 [600/2566 (23%)]\tLoss: 0.272578\n",
      "Train Epoch: 37 [640/2566 (25%)]\tLoss: 0.312052\n",
      "Train Epoch: 37 [680/2566 (26%)]\tLoss: 0.428636\n",
      "Train Epoch: 37 [720/2566 (28%)]\tLoss: 0.951603\n",
      "Train Epoch: 37 [760/2566 (30%)]\tLoss: 1.472116\n",
      "Train Epoch: 37 [800/2566 (31%)]\tLoss: 0.208655\n",
      "Train Epoch: 37 [840/2566 (33%)]\tLoss: 1.244943\n",
      "Train Epoch: 37 [880/2566 (34%)]\tLoss: 0.449470\n",
      "Train Epoch: 37 [920/2566 (36%)]\tLoss: 0.646720\n",
      "Train Epoch: 37 [960/2566 (37%)]\tLoss: 0.559239\n",
      "Train Epoch: 37 [1000/2566 (39%)]\tLoss: 0.439998\n",
      "Train Epoch: 37 [1040/2566 (40%)]\tLoss: 0.833689\n",
      "Train Epoch: 37 [1080/2566 (42%)]\tLoss: 0.882051\n",
      "Train Epoch: 37 [1120/2566 (44%)]\tLoss: 0.356198\n",
      "Train Epoch: 37 [1160/2566 (45%)]\tLoss: 0.807954\n",
      "Train Epoch: 37 [1200/2566 (47%)]\tLoss: 0.172799\n",
      "Train Epoch: 37 [1240/2566 (48%)]\tLoss: 1.533894\n",
      "Train Epoch: 37 [1280/2566 (50%)]\tLoss: 0.258631\n",
      "Train Epoch: 37 [1320/2566 (51%)]\tLoss: 0.503176\n",
      "Train Epoch: 37 [1360/2566 (53%)]\tLoss: 0.324618\n",
      "Train Epoch: 37 [1400/2566 (55%)]\tLoss: 0.447678\n",
      "Train Epoch: 37 [1440/2566 (56%)]\tLoss: 0.587538\n",
      "Train Epoch: 37 [1480/2566 (58%)]\tLoss: 0.647128\n",
      "Train Epoch: 37 [1520/2566 (59%)]\tLoss: 0.400187\n",
      "Train Epoch: 37 [1560/2566 (61%)]\tLoss: 0.356001\n",
      "Train Epoch: 37 [1600/2566 (62%)]\tLoss: 0.998513\n",
      "Train Epoch: 37 [1640/2566 (64%)]\tLoss: 0.875189\n",
      "Train Epoch: 37 [1680/2566 (65%)]\tLoss: 0.264432\n",
      "Train Epoch: 37 [1720/2566 (67%)]\tLoss: 0.802020\n",
      "Train Epoch: 37 [1760/2566 (69%)]\tLoss: 0.840405\n",
      "Train Epoch: 37 [1800/2566 (70%)]\tLoss: 0.528857\n",
      "Train Epoch: 37 [1840/2566 (72%)]\tLoss: 0.574701\n",
      "Train Epoch: 37 [1880/2566 (73%)]\tLoss: 0.980919\n",
      "Train Epoch: 37 [1920/2566 (75%)]\tLoss: 1.040177\n",
      "Train Epoch: 37 [1960/2566 (76%)]\tLoss: 1.013091\n",
      "Train Epoch: 37 [2000/2566 (78%)]\tLoss: 0.653429\n",
      "Train Epoch: 37 [2040/2566 (79%)]\tLoss: 0.738696\n",
      "Train Epoch: 37 [2080/2566 (81%)]\tLoss: 0.902543\n",
      "Train Epoch: 37 [2120/2566 (83%)]\tLoss: 0.425396\n",
      "Train Epoch: 37 [2160/2566 (84%)]\tLoss: 0.700367\n",
      "Train Epoch: 37 [2200/2566 (86%)]\tLoss: 0.281111\n",
      "Train Epoch: 37 [2240/2566 (87%)]\tLoss: 0.734027\n",
      "Train Epoch: 37 [2280/2566 (89%)]\tLoss: 0.917556\n",
      "Train Epoch: 37 [2320/2566 (90%)]\tLoss: 0.461862\n",
      "Train Epoch: 37 [2360/2566 (92%)]\tLoss: 0.695439\n",
      "Train Epoch: 37 [2400/2566 (93%)]\tLoss: 2.824091\n",
      "Train Epoch: 37 [2440/2566 (95%)]\tLoss: 0.673377\n",
      "Train Epoch: 37 [2480/2566 (97%)]\tLoss: 0.807469\n",
      "Train Epoch: 37 [2520/2566 (98%)]\tLoss: 0.275396\n",
      "Train Epoch: 37 [2560/2566 (100%)]\tLoss: 0.783286\n",
      "epoch:37,loss:0.6166396237375952\n",
      "Train set: Average loss: 0.5458, Accuracy: 1958/2566 (76%)\n",
      "Val set: Average loss: 0.6135, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 38 [40/2566 (2%)]\tLoss: 0.506390\n",
      "Train Epoch: 38 [80/2566 (3%)]\tLoss: 1.164446\n",
      "Train Epoch: 38 [120/2566 (5%)]\tLoss: 0.654567\n",
      "Train Epoch: 38 [160/2566 (6%)]\tLoss: 0.289060\n",
      "Train Epoch: 38 [200/2566 (8%)]\tLoss: 0.432513\n",
      "Train Epoch: 38 [240/2566 (9%)]\tLoss: 0.320948\n",
      "Train Epoch: 38 [280/2566 (11%)]\tLoss: 0.808470\n",
      "Train Epoch: 38 [320/2566 (12%)]\tLoss: 1.893406\n",
      "Train Epoch: 38 [360/2566 (14%)]\tLoss: 0.365590\n",
      "Train Epoch: 38 [400/2566 (16%)]\tLoss: 0.599379\n",
      "Train Epoch: 38 [440/2566 (17%)]\tLoss: 0.571096\n",
      "Train Epoch: 38 [480/2566 (19%)]\tLoss: 0.334775\n",
      "Train Epoch: 38 [520/2566 (20%)]\tLoss: 0.742723\n",
      "Train Epoch: 38 [560/2566 (22%)]\tLoss: 0.265976\n",
      "Train Epoch: 38 [600/2566 (23%)]\tLoss: 0.373838\n",
      "Train Epoch: 38 [640/2566 (25%)]\tLoss: 1.129478\n",
      "Train Epoch: 38 [680/2566 (26%)]\tLoss: 0.729038\n",
      "Train Epoch: 38 [720/2566 (28%)]\tLoss: 0.901349\n",
      "Train Epoch: 38 [760/2566 (30%)]\tLoss: 0.539500\n",
      "Train Epoch: 38 [800/2566 (31%)]\tLoss: 1.562184\n",
      "Train Epoch: 38 [840/2566 (33%)]\tLoss: 0.518414\n",
      "Train Epoch: 38 [880/2566 (34%)]\tLoss: 0.683173\n",
      "Train Epoch: 38 [920/2566 (36%)]\tLoss: 0.685411\n",
      "Train Epoch: 38 [960/2566 (37%)]\tLoss: 0.534930\n",
      "Train Epoch: 38 [1000/2566 (39%)]\tLoss: 0.543149\n",
      "Train Epoch: 38 [1040/2566 (40%)]\tLoss: 0.339643\n",
      "Train Epoch: 38 [1080/2566 (42%)]\tLoss: 0.579251\n",
      "Train Epoch: 38 [1120/2566 (44%)]\tLoss: 0.435629\n",
      "Train Epoch: 38 [1160/2566 (45%)]\tLoss: 0.797998\n",
      "Train Epoch: 38 [1200/2566 (47%)]\tLoss: 0.636726\n",
      "Train Epoch: 38 [1240/2566 (48%)]\tLoss: 0.712781\n",
      "Train Epoch: 38 [1280/2566 (50%)]\tLoss: 0.712142\n",
      "Train Epoch: 38 [1320/2566 (51%)]\tLoss: 0.574240\n",
      "Train Epoch: 38 [1360/2566 (53%)]\tLoss: 0.469032\n",
      "Train Epoch: 38 [1400/2566 (55%)]\tLoss: 0.622543\n",
      "Train Epoch: 38 [1440/2566 (56%)]\tLoss: 0.708957\n",
      "Train Epoch: 38 [1480/2566 (58%)]\tLoss: 0.262002\n",
      "Train Epoch: 38 [1520/2566 (59%)]\tLoss: 0.764062\n",
      "Train Epoch: 38 [1560/2566 (61%)]\tLoss: 0.767093\n",
      "Train Epoch: 38 [1600/2566 (62%)]\tLoss: 0.507526\n",
      "Train Epoch: 38 [1640/2566 (64%)]\tLoss: 0.857137\n",
      "Train Epoch: 38 [1680/2566 (65%)]\tLoss: 0.729032\n",
      "Train Epoch: 38 [1720/2566 (67%)]\tLoss: 0.340707\n",
      "Train Epoch: 38 [1760/2566 (69%)]\tLoss: 0.486989\n",
      "Train Epoch: 38 [1800/2566 (70%)]\tLoss: 0.779445\n",
      "Train Epoch: 38 [1840/2566 (72%)]\tLoss: 0.633503\n",
      "Train Epoch: 38 [1880/2566 (73%)]\tLoss: 0.861231\n",
      "Train Epoch: 38 [1920/2566 (75%)]\tLoss: 0.774839\n",
      "Train Epoch: 38 [1960/2566 (76%)]\tLoss: 0.454347\n",
      "Train Epoch: 38 [2000/2566 (78%)]\tLoss: 0.519020\n",
      "Train Epoch: 38 [2040/2566 (79%)]\tLoss: 0.362996\n",
      "Train Epoch: 38 [2080/2566 (81%)]\tLoss: 0.653271\n",
      "Train Epoch: 38 [2120/2566 (83%)]\tLoss: 1.017911\n",
      "Train Epoch: 38 [2160/2566 (84%)]\tLoss: 0.544251\n",
      "Train Epoch: 38 [2200/2566 (86%)]\tLoss: 0.613026\n",
      "Train Epoch: 38 [2240/2566 (87%)]\tLoss: 0.736529\n",
      "Train Epoch: 38 [2280/2566 (89%)]\tLoss: 0.721495\n",
      "Train Epoch: 38 [2320/2566 (90%)]\tLoss: 0.446673\n",
      "Train Epoch: 38 [2360/2566 (92%)]\tLoss: 0.544066\n",
      "Train Epoch: 38 [2400/2566 (93%)]\tLoss: 1.105024\n",
      "Train Epoch: 38 [2440/2566 (95%)]\tLoss: 0.394189\n",
      "Train Epoch: 38 [2480/2566 (97%)]\tLoss: 0.686212\n",
      "Train Epoch: 38 [2520/2566 (98%)]\tLoss: 0.747956\n",
      "Train Epoch: 38 [2560/2566 (100%)]\tLoss: 0.796575\n",
      "epoch:38,loss:0.6133281129914281\n",
      "Train set: Average loss: 0.5342, Accuracy: 1965/2566 (77%)\n",
      "Val set: Average loss: 0.6018, Accuracy: 247/327 (76%)\n",
      "Train Epoch: 39 [40/2566 (2%)]\tLoss: 0.162856\n",
      "Train Epoch: 39 [80/2566 (3%)]\tLoss: 0.439116\n",
      "Train Epoch: 39 [120/2566 (5%)]\tLoss: 0.520440\n",
      "Train Epoch: 39 [160/2566 (6%)]\tLoss: 0.345515\n",
      "Train Epoch: 39 [200/2566 (8%)]\tLoss: 0.864739\n",
      "Train Epoch: 39 [240/2566 (9%)]\tLoss: 0.654328\n",
      "Train Epoch: 39 [280/2566 (11%)]\tLoss: 0.479028\n",
      "Train Epoch: 39 [320/2566 (12%)]\tLoss: 0.577632\n",
      "Train Epoch: 39 [360/2566 (14%)]\tLoss: 0.707616\n",
      "Train Epoch: 39 [400/2566 (16%)]\tLoss: 0.179285\n",
      "Train Epoch: 39 [440/2566 (17%)]\tLoss: 0.335873\n",
      "Train Epoch: 39 [480/2566 (19%)]\tLoss: 0.318823\n",
      "Train Epoch: 39 [520/2566 (20%)]\tLoss: 0.322726\n",
      "Train Epoch: 39 [560/2566 (22%)]\tLoss: 0.608627\n",
      "Train Epoch: 39 [600/2566 (23%)]\tLoss: 0.266111\n",
      "Train Epoch: 39 [640/2566 (25%)]\tLoss: 0.440572\n",
      "Train Epoch: 39 [680/2566 (26%)]\tLoss: 0.479255\n",
      "Train Epoch: 39 [720/2566 (28%)]\tLoss: 0.248875\n",
      "Train Epoch: 39 [760/2566 (30%)]\tLoss: 0.139127\n",
      "Train Epoch: 39 [800/2566 (31%)]\tLoss: 0.475472\n",
      "Train Epoch: 39 [840/2566 (33%)]\tLoss: 0.542267\n",
      "Train Epoch: 39 [880/2566 (34%)]\tLoss: 0.564933\n",
      "Train Epoch: 39 [920/2566 (36%)]\tLoss: 0.185786\n",
      "Train Epoch: 39 [960/2566 (37%)]\tLoss: 0.895757\n",
      "Train Epoch: 39 [1000/2566 (39%)]\tLoss: 0.745055\n",
      "Train Epoch: 39 [1040/2566 (40%)]\tLoss: 0.474412\n",
      "Train Epoch: 39 [1080/2566 (42%)]\tLoss: 0.558748\n",
      "Train Epoch: 39 [1120/2566 (44%)]\tLoss: 0.569100\n",
      "Train Epoch: 39 [1160/2566 (45%)]\tLoss: 0.110704\n",
      "Train Epoch: 39 [1200/2566 (47%)]\tLoss: 1.044808\n",
      "Train Epoch: 39 [1240/2566 (48%)]\tLoss: 0.261235\n",
      "Train Epoch: 39 [1280/2566 (50%)]\tLoss: 0.248615\n",
      "Train Epoch: 39 [1320/2566 (51%)]\tLoss: 0.491526\n",
      "Train Epoch: 39 [1360/2566 (53%)]\tLoss: 0.350624\n",
      "Train Epoch: 39 [1400/2566 (55%)]\tLoss: 3.280306\n",
      "Train Epoch: 39 [1440/2566 (56%)]\tLoss: 0.660938\n",
      "Train Epoch: 39 [1480/2566 (58%)]\tLoss: 0.203777\n",
      "Train Epoch: 39 [1520/2566 (59%)]\tLoss: 0.545991\n",
      "Train Epoch: 39 [1560/2566 (61%)]\tLoss: 0.177456\n",
      "Train Epoch: 39 [1600/2566 (62%)]\tLoss: 0.528249\n",
      "Train Epoch: 39 [1640/2566 (64%)]\tLoss: 0.471244\n",
      "Train Epoch: 39 [1680/2566 (65%)]\tLoss: 0.911297\n",
      "Train Epoch: 39 [1720/2566 (67%)]\tLoss: 0.231732\n",
      "Train Epoch: 39 [1760/2566 (69%)]\tLoss: 0.895862\n",
      "Train Epoch: 39 [1800/2566 (70%)]\tLoss: 0.909781\n",
      "Train Epoch: 39 [1840/2566 (72%)]\tLoss: 0.270836\n",
      "Train Epoch: 39 [1880/2566 (73%)]\tLoss: 0.674197\n",
      "Train Epoch: 39 [1920/2566 (75%)]\tLoss: 0.568348\n",
      "Train Epoch: 39 [1960/2566 (76%)]\tLoss: 0.863655\n",
      "Train Epoch: 39 [2000/2566 (78%)]\tLoss: 0.481818\n",
      "Train Epoch: 39 [2040/2566 (79%)]\tLoss: 0.450007\n",
      "Train Epoch: 39 [2080/2566 (81%)]\tLoss: 0.565738\n",
      "Train Epoch: 39 [2120/2566 (83%)]\tLoss: 0.858601\n",
      "Train Epoch: 39 [2160/2566 (84%)]\tLoss: 1.224639\n",
      "Train Epoch: 39 [2200/2566 (86%)]\tLoss: 0.984538\n",
      "Train Epoch: 39 [2240/2566 (87%)]\tLoss: 0.503008\n",
      "Train Epoch: 39 [2280/2566 (89%)]\tLoss: 0.490642\n",
      "Train Epoch: 39 [2320/2566 (90%)]\tLoss: 0.873199\n",
      "Train Epoch: 39 [2360/2566 (92%)]\tLoss: 0.473262\n",
      "Train Epoch: 39 [2400/2566 (93%)]\tLoss: 0.479035\n",
      "Train Epoch: 39 [2440/2566 (95%)]\tLoss: 0.367902\n",
      "Train Epoch: 39 [2480/2566 (97%)]\tLoss: 0.675066\n",
      "Train Epoch: 39 [2520/2566 (98%)]\tLoss: 0.539677\n",
      "Train Epoch: 39 [2560/2566 (100%)]\tLoss: 0.399417\n",
      "epoch:39,loss:0.5992086675493888\n",
      "Train set: Average loss: 0.5320, Accuracy: 1977/2566 (77%)\n",
      "Val set: Average loss: 0.6024, Accuracy: 247/327 (76%)\n",
      "Train Epoch: 40 [40/2566 (2%)]\tLoss: 0.788424\n",
      "Train Epoch: 40 [80/2566 (3%)]\tLoss: 0.330278\n",
      "Train Epoch: 40 [120/2566 (5%)]\tLoss: 0.498852\n",
      "Train Epoch: 40 [160/2566 (6%)]\tLoss: 0.488635\n",
      "Train Epoch: 40 [200/2566 (8%)]\tLoss: 0.733066\n",
      "Train Epoch: 40 [240/2566 (9%)]\tLoss: 0.760306\n",
      "Train Epoch: 40 [280/2566 (11%)]\tLoss: 0.363579\n",
      "Train Epoch: 40 [320/2566 (12%)]\tLoss: 0.467270\n",
      "Train Epoch: 40 [360/2566 (14%)]\tLoss: 1.082805\n",
      "Train Epoch: 40 [400/2566 (16%)]\tLoss: 0.389098\n",
      "Train Epoch: 40 [440/2566 (17%)]\tLoss: 0.775255\n",
      "Train Epoch: 40 [480/2566 (19%)]\tLoss: 0.634333\n",
      "Train Epoch: 40 [520/2566 (20%)]\tLoss: 0.176185\n",
      "Train Epoch: 40 [560/2566 (22%)]\tLoss: 0.546813\n",
      "Train Epoch: 40 [600/2566 (23%)]\tLoss: 0.669912\n",
      "Train Epoch: 40 [640/2566 (25%)]\tLoss: 0.373579\n",
      "Train Epoch: 40 [680/2566 (26%)]\tLoss: 0.723687\n",
      "Train Epoch: 40 [720/2566 (28%)]\tLoss: 0.573900\n",
      "Train Epoch: 40 [760/2566 (30%)]\tLoss: 0.822950\n",
      "Train Epoch: 40 [800/2566 (31%)]\tLoss: 0.517000\n",
      "Train Epoch: 40 [840/2566 (33%)]\tLoss: 0.326667\n",
      "Train Epoch: 40 [880/2566 (34%)]\tLoss: 0.330114\n",
      "Train Epoch: 40 [920/2566 (36%)]\tLoss: 0.876968\n",
      "Train Epoch: 40 [960/2566 (37%)]\tLoss: 0.952989\n",
      "Train Epoch: 40 [1000/2566 (39%)]\tLoss: 0.278156\n",
      "Train Epoch: 40 [1040/2566 (40%)]\tLoss: 0.978221\n",
      "Train Epoch: 40 [1080/2566 (42%)]\tLoss: 0.677703\n",
      "Train Epoch: 40 [1120/2566 (44%)]\tLoss: 0.407042\n",
      "Train Epoch: 40 [1160/2566 (45%)]\tLoss: 0.584235\n",
      "Train Epoch: 40 [1200/2566 (47%)]\tLoss: 0.624080\n",
      "Train Epoch: 40 [1240/2566 (48%)]\tLoss: 0.668239\n",
      "Train Epoch: 40 [1280/2566 (50%)]\tLoss: 0.369247\n",
      "Train Epoch: 40 [1320/2566 (51%)]\tLoss: 0.685195\n",
      "Train Epoch: 40 [1360/2566 (53%)]\tLoss: 0.736037\n",
      "Train Epoch: 40 [1400/2566 (55%)]\tLoss: 0.736968\n",
      "Train Epoch: 40 [1440/2566 (56%)]\tLoss: 0.373812\n",
      "Train Epoch: 40 [1480/2566 (58%)]\tLoss: 0.605541\n",
      "Train Epoch: 40 [1520/2566 (59%)]\tLoss: 0.521788\n",
      "Train Epoch: 40 [1560/2566 (61%)]\tLoss: 0.311710\n",
      "Train Epoch: 40 [1600/2566 (62%)]\tLoss: 0.725553\n",
      "Train Epoch: 40 [1640/2566 (64%)]\tLoss: 0.535942\n",
      "Train Epoch: 40 [1680/2566 (65%)]\tLoss: 0.843024\n",
      "Train Epoch: 40 [1720/2566 (67%)]\tLoss: 0.433068\n",
      "Train Epoch: 40 [1760/2566 (69%)]\tLoss: 0.962524\n",
      "Train Epoch: 40 [1800/2566 (70%)]\tLoss: 0.958289\n",
      "Train Epoch: 40 [1840/2566 (72%)]\tLoss: 0.366833\n",
      "Train Epoch: 40 [1880/2566 (73%)]\tLoss: 0.681027\n",
      "Train Epoch: 40 [1920/2566 (75%)]\tLoss: 0.796267\n",
      "Train Epoch: 40 [1960/2566 (76%)]\tLoss: 0.681022\n",
      "Train Epoch: 40 [2000/2566 (78%)]\tLoss: 0.389476\n",
      "Train Epoch: 40 [2040/2566 (79%)]\tLoss: 0.782081\n",
      "Train Epoch: 40 [2080/2566 (81%)]\tLoss: 0.560459\n",
      "Train Epoch: 40 [2120/2566 (83%)]\tLoss: 0.582746\n",
      "Train Epoch: 40 [2160/2566 (84%)]\tLoss: 0.231999\n",
      "Train Epoch: 40 [2200/2566 (86%)]\tLoss: 0.898421\n",
      "Train Epoch: 40 [2240/2566 (87%)]\tLoss: 0.195409\n",
      "Train Epoch: 40 [2280/2566 (89%)]\tLoss: 0.306990\n",
      "Train Epoch: 40 [2320/2566 (90%)]\tLoss: 0.784125\n",
      "Train Epoch: 40 [2360/2566 (92%)]\tLoss: 0.320895\n",
      "Train Epoch: 40 [2400/2566 (93%)]\tLoss: 0.526428\n",
      "Train Epoch: 40 [2440/2566 (95%)]\tLoss: 0.527218\n",
      "Train Epoch: 40 [2480/2566 (97%)]\tLoss: 0.369370\n",
      "Train Epoch: 40 [2520/2566 (98%)]\tLoss: 0.549496\n",
      "Train Epoch: 40 [2560/2566 (100%)]\tLoss: 0.610380\n",
      "epoch:40,loss:0.5902899257676252\n",
      "Train set: Average loss: 0.5265, Accuracy: 1997/2566 (78%)\n",
      "Val set: Average loss: 0.6042, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 41 [40/2566 (2%)]\tLoss: 0.420245\n",
      "Train Epoch: 41 [80/2566 (3%)]\tLoss: 0.445921\n",
      "Train Epoch: 41 [120/2566 (5%)]\tLoss: 0.554091\n",
      "Train Epoch: 41 [160/2566 (6%)]\tLoss: 0.625767\n",
      "Train Epoch: 41 [200/2566 (8%)]\tLoss: 0.832399\n",
      "Train Epoch: 41 [240/2566 (9%)]\tLoss: 0.653526\n",
      "Train Epoch: 41 [280/2566 (11%)]\tLoss: 0.726962\n",
      "Train Epoch: 41 [320/2566 (12%)]\tLoss: 0.265306\n",
      "Train Epoch: 41 [360/2566 (14%)]\tLoss: 0.438323\n",
      "Train Epoch: 41 [400/2566 (16%)]\tLoss: 1.506762\n",
      "Train Epoch: 41 [440/2566 (17%)]\tLoss: 0.465880\n",
      "Train Epoch: 41 [480/2566 (19%)]\tLoss: 0.671952\n",
      "Train Epoch: 41 [520/2566 (20%)]\tLoss: 0.260733\n",
      "Train Epoch: 41 [560/2566 (22%)]\tLoss: 0.749139\n",
      "Train Epoch: 41 [600/2566 (23%)]\tLoss: 0.540832\n",
      "Train Epoch: 41 [640/2566 (25%)]\tLoss: 0.581389\n",
      "Train Epoch: 41 [680/2566 (26%)]\tLoss: 0.739628\n",
      "Train Epoch: 41 [720/2566 (28%)]\tLoss: 0.204243\n",
      "Train Epoch: 41 [760/2566 (30%)]\tLoss: 0.712127\n",
      "Train Epoch: 41 [800/2566 (31%)]\tLoss: 0.620269\n",
      "Train Epoch: 41 [840/2566 (33%)]\tLoss: 1.177833\n",
      "Train Epoch: 41 [880/2566 (34%)]\tLoss: 1.598266\n",
      "Train Epoch: 41 [920/2566 (36%)]\tLoss: 0.182855\n",
      "Train Epoch: 41 [960/2566 (37%)]\tLoss: 0.310491\n",
      "Train Epoch: 41 [1000/2566 (39%)]\tLoss: 0.446743\n",
      "Train Epoch: 41 [1040/2566 (40%)]\tLoss: 0.570899\n",
      "Train Epoch: 41 [1080/2566 (42%)]\tLoss: 0.530239\n",
      "Train Epoch: 41 [1120/2566 (44%)]\tLoss: 0.300445\n",
      "Train Epoch: 41 [1160/2566 (45%)]\tLoss: 0.556326\n",
      "Train Epoch: 41 [1200/2566 (47%)]\tLoss: 1.130848\n",
      "Train Epoch: 41 [1240/2566 (48%)]\tLoss: 0.902856\n",
      "Train Epoch: 41 [1280/2566 (50%)]\tLoss: 0.869921\n",
      "Train Epoch: 41 [1320/2566 (51%)]\tLoss: 0.713838\n",
      "Train Epoch: 41 [1360/2566 (53%)]\tLoss: 0.502651\n",
      "Train Epoch: 41 [1400/2566 (55%)]\tLoss: 0.436923\n",
      "Train Epoch: 41 [1440/2566 (56%)]\tLoss: 0.532938\n",
      "Train Epoch: 41 [1480/2566 (58%)]\tLoss: 0.344459\n",
      "Train Epoch: 41 [1520/2566 (59%)]\tLoss: 0.502232\n",
      "Train Epoch: 41 [1560/2566 (61%)]\tLoss: 0.772252\n",
      "Train Epoch: 41 [1600/2566 (62%)]\tLoss: 0.905551\n",
      "Train Epoch: 41 [1640/2566 (64%)]\tLoss: 1.058572\n",
      "Train Epoch: 41 [1680/2566 (65%)]\tLoss: 0.466472\n",
      "Train Epoch: 41 [1720/2566 (67%)]\tLoss: 1.174854\n",
      "Train Epoch: 41 [1760/2566 (69%)]\tLoss: 0.827934\n",
      "Train Epoch: 41 [1800/2566 (70%)]\tLoss: 0.419403\n",
      "Train Epoch: 41 [1840/2566 (72%)]\tLoss: 0.563396\n",
      "Train Epoch: 41 [1880/2566 (73%)]\tLoss: 0.923689\n",
      "Train Epoch: 41 [1920/2566 (75%)]\tLoss: 0.308933\n",
      "Train Epoch: 41 [1960/2566 (76%)]\tLoss: 0.207596\n",
      "Train Epoch: 41 [2000/2566 (78%)]\tLoss: 0.534573\n",
      "Train Epoch: 41 [2040/2566 (79%)]\tLoss: 0.712955\n",
      "Train Epoch: 41 [2080/2566 (81%)]\tLoss: 0.653026\n",
      "Train Epoch: 41 [2120/2566 (83%)]\tLoss: 0.550445\n",
      "Train Epoch: 41 [2160/2566 (84%)]\tLoss: 0.173784\n",
      "Train Epoch: 41 [2200/2566 (86%)]\tLoss: 0.315139\n",
      "Train Epoch: 41 [2240/2566 (87%)]\tLoss: 0.179153\n",
      "Train Epoch: 41 [2280/2566 (89%)]\tLoss: 0.472323\n",
      "Train Epoch: 41 [2320/2566 (90%)]\tLoss: 0.399293\n",
      "Train Epoch: 41 [2360/2566 (92%)]\tLoss: 0.797855\n",
      "Train Epoch: 41 [2400/2566 (93%)]\tLoss: 0.296430\n",
      "Train Epoch: 41 [2440/2566 (95%)]\tLoss: 0.213416\n",
      "Train Epoch: 41 [2480/2566 (97%)]\tLoss: 0.745081\n",
      "Train Epoch: 41 [2520/2566 (98%)]\tLoss: 0.695815\n",
      "Train Epoch: 41 [2560/2566 (100%)]\tLoss: 0.899422\n",
      "epoch:41,loss:0.5966633083385842\n",
      "Train set: Average loss: 0.5102, Accuracy: 2000/2566 (78%)\n",
      "Val set: Average loss: 0.5935, Accuracy: 245/327 (75%)\n",
      "Train Epoch: 42 [40/2566 (2%)]\tLoss: 0.557241\n",
      "Train Epoch: 42 [80/2566 (3%)]\tLoss: 1.007710\n",
      "Train Epoch: 42 [120/2566 (5%)]\tLoss: 0.667426\n",
      "Train Epoch: 42 [160/2566 (6%)]\tLoss: 0.850229\n",
      "Train Epoch: 42 [200/2566 (8%)]\tLoss: 0.473795\n",
      "Train Epoch: 42 [240/2566 (9%)]\tLoss: 0.722629\n",
      "Train Epoch: 42 [280/2566 (11%)]\tLoss: 0.903797\n",
      "Train Epoch: 42 [320/2566 (12%)]\tLoss: 0.369093\n",
      "Train Epoch: 42 [360/2566 (14%)]\tLoss: 0.950783\n",
      "Train Epoch: 42 [400/2566 (16%)]\tLoss: 0.403418\n",
      "Train Epoch: 42 [440/2566 (17%)]\tLoss: 0.820220\n",
      "Train Epoch: 42 [480/2566 (19%)]\tLoss: 0.524242\n",
      "Train Epoch: 42 [520/2566 (20%)]\tLoss: 0.545493\n",
      "Train Epoch: 42 [560/2566 (22%)]\tLoss: 0.713856\n",
      "Train Epoch: 42 [600/2566 (23%)]\tLoss: 0.447046\n",
      "Train Epoch: 42 [640/2566 (25%)]\tLoss: 0.626517\n",
      "Train Epoch: 42 [680/2566 (26%)]\tLoss: 0.412545\n",
      "Train Epoch: 42 [720/2566 (28%)]\tLoss: 0.582188\n",
      "Train Epoch: 42 [760/2566 (30%)]\tLoss: 0.878863\n",
      "Train Epoch: 42 [800/2566 (31%)]\tLoss: 0.556101\n",
      "Train Epoch: 42 [840/2566 (33%)]\tLoss: 0.499441\n",
      "Train Epoch: 42 [880/2566 (34%)]\tLoss: 0.627776\n",
      "Train Epoch: 42 [920/2566 (36%)]\tLoss: 0.275948\n",
      "Train Epoch: 42 [960/2566 (37%)]\tLoss: 0.337077\n",
      "Train Epoch: 42 [1000/2566 (39%)]\tLoss: 0.773867\n",
      "Train Epoch: 42 [1040/2566 (40%)]\tLoss: 0.219547\n",
      "Train Epoch: 42 [1080/2566 (42%)]\tLoss: 0.154031\n",
      "Train Epoch: 42 [1120/2566 (44%)]\tLoss: 0.269106\n",
      "Train Epoch: 42 [1160/2566 (45%)]\tLoss: 0.406082\n",
      "Train Epoch: 42 [1200/2566 (47%)]\tLoss: 0.528624\n",
      "Train Epoch: 42 [1240/2566 (48%)]\tLoss: 0.594050\n",
      "Train Epoch: 42 [1280/2566 (50%)]\tLoss: 0.159645\n",
      "Train Epoch: 42 [1320/2566 (51%)]\tLoss: 0.505686\n",
      "Train Epoch: 42 [1360/2566 (53%)]\tLoss: 0.985502\n",
      "Train Epoch: 42 [1400/2566 (55%)]\tLoss: 0.503251\n",
      "Train Epoch: 42 [1440/2566 (56%)]\tLoss: 0.874766\n",
      "Train Epoch: 42 [1480/2566 (58%)]\tLoss: 0.512782\n",
      "Train Epoch: 42 [1520/2566 (59%)]\tLoss: 0.251267\n",
      "Train Epoch: 42 [1560/2566 (61%)]\tLoss: 0.269596\n",
      "Train Epoch: 42 [1600/2566 (62%)]\tLoss: 0.844757\n",
      "Train Epoch: 42 [1640/2566 (64%)]\tLoss: 0.399656\n",
      "Train Epoch: 42 [1680/2566 (65%)]\tLoss: 0.436881\n",
      "Train Epoch: 42 [1720/2566 (67%)]\tLoss: 0.239517\n",
      "Train Epoch: 42 [1760/2566 (69%)]\tLoss: 0.665640\n",
      "Train Epoch: 42 [1800/2566 (70%)]\tLoss: 0.557384\n",
      "Train Epoch: 42 [1840/2566 (72%)]\tLoss: 0.859178\n",
      "Train Epoch: 42 [1880/2566 (73%)]\tLoss: 0.721042\n",
      "Train Epoch: 42 [1920/2566 (75%)]\tLoss: 0.594061\n",
      "Train Epoch: 42 [1960/2566 (76%)]\tLoss: 0.767265\n",
      "Train Epoch: 42 [2000/2566 (78%)]\tLoss: 0.519531\n",
      "Train Epoch: 42 [2040/2566 (79%)]\tLoss: 0.590541\n",
      "Train Epoch: 42 [2080/2566 (81%)]\tLoss: 1.001039\n",
      "Train Epoch: 42 [2120/2566 (83%)]\tLoss: 0.432634\n",
      "Train Epoch: 42 [2160/2566 (84%)]\tLoss: 0.569317\n",
      "Train Epoch: 42 [2200/2566 (86%)]\tLoss: 0.847083\n",
      "Train Epoch: 42 [2240/2566 (87%)]\tLoss: 0.434631\n",
      "Train Epoch: 42 [2280/2566 (89%)]\tLoss: 0.681881\n",
      "Train Epoch: 42 [2320/2566 (90%)]\tLoss: 0.635970\n",
      "Train Epoch: 42 [2360/2566 (92%)]\tLoss: 0.425769\n",
      "Train Epoch: 42 [2400/2566 (93%)]\tLoss: 0.707619\n",
      "Train Epoch: 42 [2440/2566 (95%)]\tLoss: 0.350407\n",
      "Train Epoch: 42 [2480/2566 (97%)]\tLoss: 0.653588\n",
      "Train Epoch: 42 [2520/2566 (98%)]\tLoss: 0.484219\n",
      "Train Epoch: 42 [2560/2566 (100%)]\tLoss: 0.564370\n",
      "epoch:42,loss:0.598095729854248\n",
      "Train set: Average loss: 0.5096, Accuracy: 2011/2566 (78%)\n",
      "Val set: Average loss: 0.5921, Accuracy: 248/327 (76%)\n",
      "Train Epoch: 43 [40/2566 (2%)]\tLoss: 0.737376\n",
      "Train Epoch: 43 [80/2566 (3%)]\tLoss: 0.847389\n",
      "Train Epoch: 43 [120/2566 (5%)]\tLoss: 0.433067\n",
      "Train Epoch: 43 [160/2566 (6%)]\tLoss: 0.385589\n",
      "Train Epoch: 43 [200/2566 (8%)]\tLoss: 0.771324\n",
      "Train Epoch: 43 [240/2566 (9%)]\tLoss: 0.880650\n",
      "Train Epoch: 43 [280/2566 (11%)]\tLoss: 0.911976\n",
      "Train Epoch: 43 [320/2566 (12%)]\tLoss: 0.450472\n",
      "Train Epoch: 43 [360/2566 (14%)]\tLoss: 1.148781\n",
      "Train Epoch: 43 [400/2566 (16%)]\tLoss: 0.174210\n",
      "Train Epoch: 43 [440/2566 (17%)]\tLoss: 0.480602\n",
      "Train Epoch: 43 [480/2566 (19%)]\tLoss: 0.272657\n",
      "Train Epoch: 43 [520/2566 (20%)]\tLoss: 0.128489\n",
      "Train Epoch: 43 [560/2566 (22%)]\tLoss: 1.018201\n",
      "Train Epoch: 43 [600/2566 (23%)]\tLoss: 0.574507\n",
      "Train Epoch: 43 [640/2566 (25%)]\tLoss: 0.634846\n",
      "Train Epoch: 43 [680/2566 (26%)]\tLoss: 0.338851\n",
      "Train Epoch: 43 [720/2566 (28%)]\tLoss: 0.146718\n",
      "Train Epoch: 43 [760/2566 (30%)]\tLoss: 0.293026\n",
      "Train Epoch: 43 [800/2566 (31%)]\tLoss: 0.265128\n",
      "Train Epoch: 43 [840/2566 (33%)]\tLoss: 0.301895\n",
      "Train Epoch: 43 [880/2566 (34%)]\tLoss: 0.132906\n",
      "Train Epoch: 43 [920/2566 (36%)]\tLoss: 0.539975\n",
      "Train Epoch: 43 [960/2566 (37%)]\tLoss: 0.307959\n",
      "Train Epoch: 43 [1000/2566 (39%)]\tLoss: 0.587079\n",
      "Train Epoch: 43 [1040/2566 (40%)]\tLoss: 0.209868\n",
      "Train Epoch: 43 [1080/2566 (42%)]\tLoss: 0.289981\n",
      "Train Epoch: 43 [1120/2566 (44%)]\tLoss: 0.280715\n",
      "Train Epoch: 43 [1160/2566 (45%)]\tLoss: 0.727470\n",
      "Train Epoch: 43 [1200/2566 (47%)]\tLoss: 0.342339\n",
      "Train Epoch: 43 [1240/2566 (48%)]\tLoss: 1.059675\n",
      "Train Epoch: 43 [1280/2566 (50%)]\tLoss: 0.113184\n",
      "Train Epoch: 43 [1320/2566 (51%)]\tLoss: 0.567082\n",
      "Train Epoch: 43 [1360/2566 (53%)]\tLoss: 0.334830\n",
      "Train Epoch: 43 [1400/2566 (55%)]\tLoss: 0.314512\n",
      "Train Epoch: 43 [1440/2566 (56%)]\tLoss: 0.343452\n",
      "Train Epoch: 43 [1480/2566 (58%)]\tLoss: 1.662563\n",
      "Train Epoch: 43 [1520/2566 (59%)]\tLoss: 0.291124\n",
      "Train Epoch: 43 [1560/2566 (61%)]\tLoss: 1.719113\n",
      "Train Epoch: 43 [1600/2566 (62%)]\tLoss: 0.246483\n",
      "Train Epoch: 43 [1640/2566 (64%)]\tLoss: 0.577875\n",
      "Train Epoch: 43 [1680/2566 (65%)]\tLoss: 0.225214\n",
      "Train Epoch: 43 [1720/2566 (67%)]\tLoss: 1.512162\n",
      "Train Epoch: 43 [1760/2566 (69%)]\tLoss: 1.008164\n",
      "Train Epoch: 43 [1800/2566 (70%)]\tLoss: 0.164647\n",
      "Train Epoch: 43 [1840/2566 (72%)]\tLoss: 0.918645\n",
      "Train Epoch: 43 [1880/2566 (73%)]\tLoss: 1.146898\n",
      "Train Epoch: 43 [1920/2566 (75%)]\tLoss: 0.403759\n",
      "Train Epoch: 43 [1960/2566 (76%)]\tLoss: 0.671932\n",
      "Train Epoch: 43 [2000/2566 (78%)]\tLoss: 0.823596\n",
      "Train Epoch: 43 [2040/2566 (79%)]\tLoss: 0.349781\n",
      "Train Epoch: 43 [2080/2566 (81%)]\tLoss: 0.791800\n",
      "Train Epoch: 43 [2120/2566 (83%)]\tLoss: 0.930549\n",
      "Train Epoch: 43 [2160/2566 (84%)]\tLoss: 0.221469\n",
      "Train Epoch: 43 [2200/2566 (86%)]\tLoss: 0.722885\n",
      "Train Epoch: 43 [2240/2566 (87%)]\tLoss: 0.500923\n",
      "Train Epoch: 43 [2280/2566 (89%)]\tLoss: 0.780648\n",
      "Train Epoch: 43 [2320/2566 (90%)]\tLoss: 1.513400\n",
      "Train Epoch: 43 [2360/2566 (92%)]\tLoss: 0.381426\n",
      "Train Epoch: 43 [2400/2566 (93%)]\tLoss: 0.415995\n",
      "Train Epoch: 43 [2440/2566 (95%)]\tLoss: 0.610456\n",
      "Train Epoch: 43 [2480/2566 (97%)]\tLoss: 1.006227\n",
      "Train Epoch: 43 [2520/2566 (98%)]\tLoss: 0.372330\n",
      "Train Epoch: 43 [2560/2566 (100%)]\tLoss: 0.434129\n",
      "epoch:43,loss:0.5763865791470091\n",
      "Train set: Average loss: 0.5014, Accuracy: 2020/2566 (79%)\n",
      "Val set: Average loss: 0.5832, Accuracy: 248/327 (76%)\n",
      "Train Epoch: 44 [40/2566 (2%)]\tLoss: 0.384439\n",
      "Train Epoch: 44 [80/2566 (3%)]\tLoss: 0.679506\n",
      "Train Epoch: 44 [120/2566 (5%)]\tLoss: 0.365950\n",
      "Train Epoch: 44 [160/2566 (6%)]\tLoss: 0.451506\n",
      "Train Epoch: 44 [200/2566 (8%)]\tLoss: 0.459961\n",
      "Train Epoch: 44 [240/2566 (9%)]\tLoss: 0.326973\n",
      "Train Epoch: 44 [280/2566 (11%)]\tLoss: 0.768202\n",
      "Train Epoch: 44 [320/2566 (12%)]\tLoss: 0.332381\n",
      "Train Epoch: 44 [360/2566 (14%)]\tLoss: 0.687262\n",
      "Train Epoch: 44 [400/2566 (16%)]\tLoss: 0.422802\n",
      "Train Epoch: 44 [440/2566 (17%)]\tLoss: 0.323282\n",
      "Train Epoch: 44 [480/2566 (19%)]\tLoss: 0.994497\n",
      "Train Epoch: 44 [520/2566 (20%)]\tLoss: 0.853243\n",
      "Train Epoch: 44 [560/2566 (22%)]\tLoss: 0.347832\n",
      "Train Epoch: 44 [600/2566 (23%)]\tLoss: 0.623974\n",
      "Train Epoch: 44 [640/2566 (25%)]\tLoss: 0.713135\n",
      "Train Epoch: 44 [680/2566 (26%)]\tLoss: 0.494356\n",
      "Train Epoch: 44 [720/2566 (28%)]\tLoss: 0.196174\n",
      "Train Epoch: 44 [760/2566 (30%)]\tLoss: 0.749077\n",
      "Train Epoch: 44 [800/2566 (31%)]\tLoss: 0.334454\n",
      "Train Epoch: 44 [840/2566 (33%)]\tLoss: 0.358755\n",
      "Train Epoch: 44 [880/2566 (34%)]\tLoss: 0.212350\n",
      "Train Epoch: 44 [920/2566 (36%)]\tLoss: 0.504579\n",
      "Train Epoch: 44 [960/2566 (37%)]\tLoss: 0.489932\n",
      "Train Epoch: 44 [1000/2566 (39%)]\tLoss: 0.299242\n",
      "Train Epoch: 44 [1040/2566 (40%)]\tLoss: 0.702280\n",
      "Train Epoch: 44 [1080/2566 (42%)]\tLoss: 0.500326\n",
      "Train Epoch: 44 [1120/2566 (44%)]\tLoss: 0.712547\n",
      "Train Epoch: 44 [1160/2566 (45%)]\tLoss: 0.604227\n",
      "Train Epoch: 44 [1200/2566 (47%)]\tLoss: 0.660193\n",
      "Train Epoch: 44 [1240/2566 (48%)]\tLoss: 0.344572\n",
      "Train Epoch: 44 [1280/2566 (50%)]\tLoss: 0.266720\n",
      "Train Epoch: 44 [1320/2566 (51%)]\tLoss: 0.292040\n",
      "Train Epoch: 44 [1360/2566 (53%)]\tLoss: 0.655003\n",
      "Train Epoch: 44 [1400/2566 (55%)]\tLoss: 0.552936\n",
      "Train Epoch: 44 [1440/2566 (56%)]\tLoss: 0.463595\n",
      "Train Epoch: 44 [1480/2566 (58%)]\tLoss: 0.910239\n",
      "Train Epoch: 44 [1520/2566 (59%)]\tLoss: 0.365469\n",
      "Train Epoch: 44 [1560/2566 (61%)]\tLoss: 0.720102\n",
      "Train Epoch: 44 [1600/2566 (62%)]\tLoss: 0.505024\n",
      "Train Epoch: 44 [1640/2566 (64%)]\tLoss: 0.812483\n",
      "Train Epoch: 44 [1680/2566 (65%)]\tLoss: 0.872989\n",
      "Train Epoch: 44 [1720/2566 (67%)]\tLoss: 0.260055\n",
      "Train Epoch: 44 [1760/2566 (69%)]\tLoss: 0.732975\n",
      "Train Epoch: 44 [1800/2566 (70%)]\tLoss: 0.297663\n",
      "Train Epoch: 44 [1840/2566 (72%)]\tLoss: 0.437668\n",
      "Train Epoch: 44 [1880/2566 (73%)]\tLoss: 0.684195\n",
      "Train Epoch: 44 [1920/2566 (75%)]\tLoss: 0.139238\n",
      "Train Epoch: 44 [1960/2566 (76%)]\tLoss: 0.258044\n",
      "Train Epoch: 44 [2000/2566 (78%)]\tLoss: 0.229305\n",
      "Train Epoch: 44 [2040/2566 (79%)]\tLoss: 0.666918\n",
      "Train Epoch: 44 [2080/2566 (81%)]\tLoss: 0.458280\n",
      "Train Epoch: 44 [2120/2566 (83%)]\tLoss: 0.719430\n",
      "Train Epoch: 44 [2160/2566 (84%)]\tLoss: 0.528829\n",
      "Train Epoch: 44 [2200/2566 (86%)]\tLoss: 0.458212\n",
      "Train Epoch: 44 [2240/2566 (87%)]\tLoss: 0.360244\n",
      "Train Epoch: 44 [2280/2566 (89%)]\tLoss: 0.465760\n",
      "Train Epoch: 44 [2320/2566 (90%)]\tLoss: 0.332778\n",
      "Train Epoch: 44 [2360/2566 (92%)]\tLoss: 0.439642\n",
      "Train Epoch: 44 [2400/2566 (93%)]\tLoss: 0.331763\n",
      "Train Epoch: 44 [2440/2566 (95%)]\tLoss: 0.672627\n",
      "Train Epoch: 44 [2480/2566 (97%)]\tLoss: 0.156076\n",
      "Train Epoch: 44 [2520/2566 (98%)]\tLoss: 0.304618\n",
      "Train Epoch: 44 [2560/2566 (100%)]\tLoss: 1.105378\n",
      "epoch:44,loss:0.5742787741054999\n",
      "Train set: Average loss: 0.5071, Accuracy: 2048/2566 (80%)\n",
      "Val set: Average loss: 0.5954, Accuracy: 250/327 (76%)\n",
      "Train Epoch: 45 [40/2566 (2%)]\tLoss: 0.566517\n",
      "Train Epoch: 45 [80/2566 (3%)]\tLoss: 0.552333\n",
      "Train Epoch: 45 [120/2566 (5%)]\tLoss: 0.960668\n",
      "Train Epoch: 45 [160/2566 (6%)]\tLoss: 1.126483\n",
      "Train Epoch: 45 [200/2566 (8%)]\tLoss: 0.720114\n",
      "Train Epoch: 45 [240/2566 (9%)]\tLoss: 0.886149\n",
      "Train Epoch: 45 [280/2566 (11%)]\tLoss: 0.549071\n",
      "Train Epoch: 45 [320/2566 (12%)]\tLoss: 0.383445\n",
      "Train Epoch: 45 [360/2566 (14%)]\tLoss: 0.369434\n",
      "Train Epoch: 45 [400/2566 (16%)]\tLoss: 0.154999\n",
      "Train Epoch: 45 [440/2566 (17%)]\tLoss: 0.167648\n",
      "Train Epoch: 45 [480/2566 (19%)]\tLoss: 0.734333\n",
      "Train Epoch: 45 [520/2566 (20%)]\tLoss: 0.365102\n",
      "Train Epoch: 45 [560/2566 (22%)]\tLoss: 0.313602\n",
      "Train Epoch: 45 [600/2566 (23%)]\tLoss: 0.442368\n",
      "Train Epoch: 45 [640/2566 (25%)]\tLoss: 0.923224\n",
      "Train Epoch: 45 [680/2566 (26%)]\tLoss: 0.433764\n",
      "Train Epoch: 45 [720/2566 (28%)]\tLoss: 0.786640\n",
      "Train Epoch: 45 [760/2566 (30%)]\tLoss: 0.823470\n",
      "Train Epoch: 45 [800/2566 (31%)]\tLoss: 0.789736\n",
      "Train Epoch: 45 [840/2566 (33%)]\tLoss: 0.741837\n",
      "Train Epoch: 45 [880/2566 (34%)]\tLoss: 0.743659\n",
      "Train Epoch: 45 [920/2566 (36%)]\tLoss: 0.466395\n",
      "Train Epoch: 45 [960/2566 (37%)]\tLoss: 1.017296\n",
      "Train Epoch: 45 [1000/2566 (39%)]\tLoss: 0.451966\n",
      "Train Epoch: 45 [1040/2566 (40%)]\tLoss: 0.625455\n",
      "Train Epoch: 45 [1080/2566 (42%)]\tLoss: 0.426871\n",
      "Train Epoch: 45 [1120/2566 (44%)]\tLoss: 0.521181\n",
      "Train Epoch: 45 [1160/2566 (45%)]\tLoss: 0.829575\n",
      "Train Epoch: 45 [1200/2566 (47%)]\tLoss: 0.410712\n",
      "Train Epoch: 45 [1240/2566 (48%)]\tLoss: 0.677414\n",
      "Train Epoch: 45 [1280/2566 (50%)]\tLoss: 0.317919\n",
      "Train Epoch: 45 [1320/2566 (51%)]\tLoss: 0.382639\n",
      "Train Epoch: 45 [1360/2566 (53%)]\tLoss: 0.603948\n",
      "Train Epoch: 45 [1400/2566 (55%)]\tLoss: 0.581863\n",
      "Train Epoch: 45 [1440/2566 (56%)]\tLoss: 0.471701\n",
      "Train Epoch: 45 [1480/2566 (58%)]\tLoss: 0.681228\n",
      "Train Epoch: 45 [1520/2566 (59%)]\tLoss: 0.546748\n",
      "Train Epoch: 45 [1560/2566 (61%)]\tLoss: 1.050821\n",
      "Train Epoch: 45 [1600/2566 (62%)]\tLoss: 0.859833\n",
      "Train Epoch: 45 [1640/2566 (64%)]\tLoss: 0.493092\n",
      "Train Epoch: 45 [1680/2566 (65%)]\tLoss: 0.477588\n",
      "Train Epoch: 45 [1720/2566 (67%)]\tLoss: 0.688090\n",
      "Train Epoch: 45 [1760/2566 (69%)]\tLoss: 0.628086\n",
      "Train Epoch: 45 [1800/2566 (70%)]\tLoss: 0.130827\n",
      "Train Epoch: 45 [1840/2566 (72%)]\tLoss: 0.245517\n",
      "Train Epoch: 45 [1880/2566 (73%)]\tLoss: 0.516956\n",
      "Train Epoch: 45 [1920/2566 (75%)]\tLoss: 1.099238\n",
      "Train Epoch: 45 [1960/2566 (76%)]\tLoss: 0.477906\n",
      "Train Epoch: 45 [2000/2566 (78%)]\tLoss: 0.556377\n",
      "Train Epoch: 45 [2040/2566 (79%)]\tLoss: 0.464825\n",
      "Train Epoch: 45 [2080/2566 (81%)]\tLoss: 0.451463\n",
      "Train Epoch: 45 [2120/2566 (83%)]\tLoss: 0.620776\n",
      "Train Epoch: 45 [2160/2566 (84%)]\tLoss: 0.407373\n",
      "Train Epoch: 45 [2200/2566 (86%)]\tLoss: 0.737631\n",
      "Train Epoch: 45 [2240/2566 (87%)]\tLoss: 0.431109\n",
      "Train Epoch: 45 [2280/2566 (89%)]\tLoss: 0.779485\n",
      "Train Epoch: 45 [2320/2566 (90%)]\tLoss: 0.264978\n",
      "Train Epoch: 45 [2360/2566 (92%)]\tLoss: 0.561070\n",
      "Train Epoch: 45 [2400/2566 (93%)]\tLoss: 0.325521\n",
      "Train Epoch: 45 [2440/2566 (95%)]\tLoss: 0.496302\n",
      "Train Epoch: 45 [2480/2566 (97%)]\tLoss: 0.305649\n",
      "Train Epoch: 45 [2520/2566 (98%)]\tLoss: 0.283286\n",
      "Train Epoch: 45 [2560/2566 (100%)]\tLoss: 0.601124\n",
      "epoch:45,loss:0.5573687300410969\n",
      "Train set: Average loss: 0.4854, Accuracy: 2046/2566 (80%)\n",
      "Val set: Average loss: 0.5823, Accuracy: 251/327 (77%)\n",
      "Train Epoch: 46 [40/2566 (2%)]\tLoss: 0.327403\n",
      "Train Epoch: 46 [80/2566 (3%)]\tLoss: 0.732253\n",
      "Train Epoch: 46 [120/2566 (5%)]\tLoss: 0.531088\n",
      "Train Epoch: 46 [160/2566 (6%)]\tLoss: 0.680214\n",
      "Train Epoch: 46 [200/2566 (8%)]\tLoss: 0.516791\n",
      "Train Epoch: 46 [240/2566 (9%)]\tLoss: 0.535142\n",
      "Train Epoch: 46 [280/2566 (11%)]\tLoss: 0.460564\n",
      "Train Epoch: 46 [320/2566 (12%)]\tLoss: 0.822871\n",
      "Train Epoch: 46 [360/2566 (14%)]\tLoss: 0.505474\n",
      "Train Epoch: 46 [400/2566 (16%)]\tLoss: 0.211766\n",
      "Train Epoch: 46 [440/2566 (17%)]\tLoss: 0.441075\n",
      "Train Epoch: 46 [480/2566 (19%)]\tLoss: 0.358854\n",
      "Train Epoch: 46 [520/2566 (20%)]\tLoss: 0.430733\n",
      "Train Epoch: 46 [560/2566 (22%)]\tLoss: 0.825370\n",
      "Train Epoch: 46 [600/2566 (23%)]\tLoss: 0.671844\n",
      "Train Epoch: 46 [640/2566 (25%)]\tLoss: 0.237654\n",
      "Train Epoch: 46 [680/2566 (26%)]\tLoss: 0.945673\n",
      "Train Epoch: 46 [720/2566 (28%)]\tLoss: 1.161166\n",
      "Train Epoch: 46 [760/2566 (30%)]\tLoss: 0.393774\n",
      "Train Epoch: 46 [800/2566 (31%)]\tLoss: 0.656846\n",
      "Train Epoch: 46 [840/2566 (33%)]\tLoss: 0.721196\n",
      "Train Epoch: 46 [880/2566 (34%)]\tLoss: 0.258167\n",
      "Train Epoch: 46 [920/2566 (36%)]\tLoss: 0.733910\n",
      "Train Epoch: 46 [960/2566 (37%)]\tLoss: 0.512618\n",
      "Train Epoch: 46 [1000/2566 (39%)]\tLoss: 0.356827\n",
      "Train Epoch: 46 [1040/2566 (40%)]\tLoss: 1.355585\n",
      "Train Epoch: 46 [1080/2566 (42%)]\tLoss: 0.764603\n",
      "Train Epoch: 46 [1120/2566 (44%)]\tLoss: 0.326691\n",
      "Train Epoch: 46 [1160/2566 (45%)]\tLoss: 0.551318\n",
      "Train Epoch: 46 [1200/2566 (47%)]\tLoss: 0.135585\n",
      "Train Epoch: 46 [1240/2566 (48%)]\tLoss: 0.308544\n",
      "Train Epoch: 46 [1280/2566 (50%)]\tLoss: 0.114705\n",
      "Train Epoch: 46 [1320/2566 (51%)]\tLoss: 0.417925\n",
      "Train Epoch: 46 [1360/2566 (53%)]\tLoss: 0.258460\n",
      "Train Epoch: 46 [1400/2566 (55%)]\tLoss: 0.614663\n",
      "Train Epoch: 46 [1440/2566 (56%)]\tLoss: 3.125380\n",
      "Train Epoch: 46 [1480/2566 (58%)]\tLoss: 0.784565\n",
      "Train Epoch: 46 [1520/2566 (59%)]\tLoss: 0.617327\n",
      "Train Epoch: 46 [1560/2566 (61%)]\tLoss: 0.455129\n",
      "Train Epoch: 46 [1600/2566 (62%)]\tLoss: 0.474428\n",
      "Train Epoch: 46 [1640/2566 (64%)]\tLoss: 0.408856\n",
      "Train Epoch: 46 [1680/2566 (65%)]\tLoss: 0.352104\n",
      "Train Epoch: 46 [1720/2566 (67%)]\tLoss: 0.729372\n",
      "Train Epoch: 46 [1760/2566 (69%)]\tLoss: 0.628957\n",
      "Train Epoch: 46 [1800/2566 (70%)]\tLoss: 0.535894\n",
      "Train Epoch: 46 [1840/2566 (72%)]\tLoss: 0.392276\n",
      "Train Epoch: 46 [1880/2566 (73%)]\tLoss: 0.639884\n",
      "Train Epoch: 46 [1920/2566 (75%)]\tLoss: 0.517897\n",
      "Train Epoch: 46 [1960/2566 (76%)]\tLoss: 0.267315\n",
      "Train Epoch: 46 [2000/2566 (78%)]\tLoss: 0.216327\n",
      "Train Epoch: 46 [2040/2566 (79%)]\tLoss: 0.444466\n",
      "Train Epoch: 46 [2080/2566 (81%)]\tLoss: 0.649661\n",
      "Train Epoch: 46 [2120/2566 (83%)]\tLoss: 0.458074\n",
      "Train Epoch: 46 [2160/2566 (84%)]\tLoss: 0.267648\n",
      "Train Epoch: 46 [2200/2566 (86%)]\tLoss: 1.001379\n",
      "Train Epoch: 46 [2240/2566 (87%)]\tLoss: 1.049147\n",
      "Train Epoch: 46 [2280/2566 (89%)]\tLoss: 0.580399\n",
      "Train Epoch: 46 [2320/2566 (90%)]\tLoss: 0.372197\n",
      "Train Epoch: 46 [2360/2566 (92%)]\tLoss: 0.253565\n",
      "Train Epoch: 46 [2400/2566 (93%)]\tLoss: 0.262896\n",
      "Train Epoch: 46 [2440/2566 (95%)]\tLoss: 0.610753\n",
      "Train Epoch: 46 [2480/2566 (97%)]\tLoss: 0.672170\n",
      "Train Epoch: 46 [2520/2566 (98%)]\tLoss: 0.748781\n",
      "Train Epoch: 46 [2560/2566 (100%)]\tLoss: 0.857795\n",
      "epoch:46,loss:0.5607842048427026\n",
      "Train set: Average loss: 0.4719, Accuracy: 2060/2566 (80%)\n",
      "Val set: Average loss: 0.5723, Accuracy: 251/327 (77%)\n",
      "Train Epoch: 47 [40/2566 (2%)]\tLoss: 0.311110\n",
      "Train Epoch: 47 [80/2566 (3%)]\tLoss: 0.905714\n",
      "Train Epoch: 47 [120/2566 (5%)]\tLoss: 0.979892\n",
      "Train Epoch: 47 [160/2566 (6%)]\tLoss: 0.302492\n",
      "Train Epoch: 47 [200/2566 (8%)]\tLoss: 0.476963\n",
      "Train Epoch: 47 [240/2566 (9%)]\tLoss: 0.894383\n",
      "Train Epoch: 47 [280/2566 (11%)]\tLoss: 2.700817\n",
      "Train Epoch: 47 [320/2566 (12%)]\tLoss: 0.848121\n",
      "Train Epoch: 47 [360/2566 (14%)]\tLoss: 0.320530\n",
      "Train Epoch: 47 [400/2566 (16%)]\tLoss: 0.785048\n",
      "Train Epoch: 47 [440/2566 (17%)]\tLoss: 0.392377\n",
      "Train Epoch: 47 [480/2566 (19%)]\tLoss: 1.308163\n",
      "Train Epoch: 47 [520/2566 (20%)]\tLoss: 0.198945\n",
      "Train Epoch: 47 [560/2566 (22%)]\tLoss: 0.213904\n",
      "Train Epoch: 47 [600/2566 (23%)]\tLoss: 0.412381\n",
      "Train Epoch: 47 [640/2566 (25%)]\tLoss: 0.231515\n",
      "Train Epoch: 47 [680/2566 (26%)]\tLoss: 0.404457\n",
      "Train Epoch: 47 [720/2566 (28%)]\tLoss: 0.421808\n",
      "Train Epoch: 47 [760/2566 (30%)]\tLoss: 0.435213\n",
      "Train Epoch: 47 [800/2566 (31%)]\tLoss: 0.315108\n",
      "Train Epoch: 47 [840/2566 (33%)]\tLoss: 0.393387\n",
      "Train Epoch: 47 [880/2566 (34%)]\tLoss: 0.313398\n",
      "Train Epoch: 47 [920/2566 (36%)]\tLoss: 0.484187\n",
      "Train Epoch: 47 [960/2566 (37%)]\tLoss: 0.744575\n",
      "Train Epoch: 47 [1000/2566 (39%)]\tLoss: 1.051205\n",
      "Train Epoch: 47 [1040/2566 (40%)]\tLoss: 0.760464\n",
      "Train Epoch: 47 [1080/2566 (42%)]\tLoss: 0.335208\n",
      "Train Epoch: 47 [1120/2566 (44%)]\tLoss: 0.756545\n",
      "Train Epoch: 47 [1160/2566 (45%)]\tLoss: 0.133664\n",
      "Train Epoch: 47 [1200/2566 (47%)]\tLoss: 0.773754\n",
      "Train Epoch: 47 [1240/2566 (48%)]\tLoss: 0.280093\n",
      "Train Epoch: 47 [1280/2566 (50%)]\tLoss: 0.467379\n",
      "Train Epoch: 47 [1320/2566 (51%)]\tLoss: 1.209857\n",
      "Train Epoch: 47 [1360/2566 (53%)]\tLoss: 0.408877\n",
      "Train Epoch: 47 [1400/2566 (55%)]\tLoss: 0.201691\n",
      "Train Epoch: 47 [1440/2566 (56%)]\tLoss: 0.502881\n",
      "Train Epoch: 47 [1480/2566 (58%)]\tLoss: 0.307911\n",
      "Train Epoch: 47 [1520/2566 (59%)]\tLoss: 0.536044\n",
      "Train Epoch: 47 [1560/2566 (61%)]\tLoss: 0.392128\n",
      "Train Epoch: 47 [1600/2566 (62%)]\tLoss: 0.867918\n",
      "Train Epoch: 47 [1640/2566 (64%)]\tLoss: 0.250121\n",
      "Train Epoch: 47 [1680/2566 (65%)]\tLoss: 0.283989\n",
      "Train Epoch: 47 [1720/2566 (67%)]\tLoss: 0.433744\n",
      "Train Epoch: 47 [1760/2566 (69%)]\tLoss: 0.796275\n",
      "Train Epoch: 47 [1800/2566 (70%)]\tLoss: 0.552448\n",
      "Train Epoch: 47 [1840/2566 (72%)]\tLoss: 0.201736\n",
      "Train Epoch: 47 [1880/2566 (73%)]\tLoss: 0.597056\n",
      "Train Epoch: 47 [1920/2566 (75%)]\tLoss: 0.678107\n",
      "Train Epoch: 47 [1960/2566 (76%)]\tLoss: 0.698070\n",
      "Train Epoch: 47 [2000/2566 (78%)]\tLoss: 0.761508\n",
      "Train Epoch: 47 [2040/2566 (79%)]\tLoss: 0.551428\n",
      "Train Epoch: 47 [2080/2566 (81%)]\tLoss: 0.638976\n",
      "Train Epoch: 47 [2120/2566 (83%)]\tLoss: 0.381440\n",
      "Train Epoch: 47 [2160/2566 (84%)]\tLoss: 0.436593\n",
      "Train Epoch: 47 [2200/2566 (86%)]\tLoss: 0.280762\n",
      "Train Epoch: 47 [2240/2566 (87%)]\tLoss: 0.769401\n",
      "Train Epoch: 47 [2280/2566 (89%)]\tLoss: 0.629783\n",
      "Train Epoch: 47 [2320/2566 (90%)]\tLoss: 0.839167\n",
      "Train Epoch: 47 [2360/2566 (92%)]\tLoss: 0.466902\n",
      "Train Epoch: 47 [2400/2566 (93%)]\tLoss: 0.399768\n",
      "Train Epoch: 47 [2440/2566 (95%)]\tLoss: 0.725706\n",
      "Train Epoch: 47 [2480/2566 (97%)]\tLoss: 0.498245\n",
      "Train Epoch: 47 [2520/2566 (98%)]\tLoss: 0.646268\n",
      "Train Epoch: 47 [2560/2566 (100%)]\tLoss: 0.491675\n",
      "epoch:47,loss:0.5661918210834729\n",
      "Train set: Average loss: 0.4714, Accuracy: 2067/2566 (81%)\n",
      "Val set: Average loss: 0.5727, Accuracy: 253/327 (77%)\n",
      "Train Epoch: 48 [40/2566 (2%)]\tLoss: 0.603248\n",
      "Train Epoch: 48 [80/2566 (3%)]\tLoss: 0.730763\n",
      "Train Epoch: 48 [120/2566 (5%)]\tLoss: 0.726230\n",
      "Train Epoch: 48 [160/2566 (6%)]\tLoss: 0.878663\n",
      "Train Epoch: 48 [200/2566 (8%)]\tLoss: 0.410570\n",
      "Train Epoch: 48 [240/2566 (9%)]\tLoss: 0.543303\n",
      "Train Epoch: 48 [280/2566 (11%)]\tLoss: 0.647823\n",
      "Train Epoch: 48 [320/2566 (12%)]\tLoss: 0.868863\n",
      "Train Epoch: 48 [360/2566 (14%)]\tLoss: 0.781550\n",
      "Train Epoch: 48 [400/2566 (16%)]\tLoss: 1.299313\n",
      "Train Epoch: 48 [440/2566 (17%)]\tLoss: 0.858360\n",
      "Train Epoch: 48 [480/2566 (19%)]\tLoss: 0.244643\n",
      "Train Epoch: 48 [520/2566 (20%)]\tLoss: 1.023036\n",
      "Train Epoch: 48 [560/2566 (22%)]\tLoss: 0.455708\n",
      "Train Epoch: 48 [600/2566 (23%)]\tLoss: 0.280268\n",
      "Train Epoch: 48 [640/2566 (25%)]\tLoss: 0.594277\n",
      "Train Epoch: 48 [680/2566 (26%)]\tLoss: 0.153180\n",
      "Train Epoch: 48 [720/2566 (28%)]\tLoss: 0.369769\n",
      "Train Epoch: 48 [760/2566 (30%)]\tLoss: 1.015632\n",
      "Train Epoch: 48 [800/2566 (31%)]\tLoss: 0.291906\n",
      "Train Epoch: 48 [840/2566 (33%)]\tLoss: 0.195058\n",
      "Train Epoch: 48 [880/2566 (34%)]\tLoss: 0.398415\n",
      "Train Epoch: 48 [920/2566 (36%)]\tLoss: 0.292652\n",
      "Train Epoch: 48 [960/2566 (37%)]\tLoss: 0.300832\n",
      "Train Epoch: 48 [1000/2566 (39%)]\tLoss: 0.414862\n",
      "Train Epoch: 48 [1040/2566 (40%)]\tLoss: 0.119856\n",
      "Train Epoch: 48 [1080/2566 (42%)]\tLoss: 0.468966\n",
      "Train Epoch: 48 [1120/2566 (44%)]\tLoss: 0.237726\n",
      "Train Epoch: 48 [1160/2566 (45%)]\tLoss: 0.671787\n",
      "Train Epoch: 48 [1200/2566 (47%)]\tLoss: 0.522097\n",
      "Train Epoch: 48 [1240/2566 (48%)]\tLoss: 0.527277\n",
      "Train Epoch: 48 [1280/2566 (50%)]\tLoss: 0.448893\n",
      "Train Epoch: 48 [1320/2566 (51%)]\tLoss: 0.316935\n",
      "Train Epoch: 48 [1360/2566 (53%)]\tLoss: 0.540970\n",
      "Train Epoch: 48 [1400/2566 (55%)]\tLoss: 0.510821\n",
      "Train Epoch: 48 [1440/2566 (56%)]\tLoss: 0.231274\n",
      "Train Epoch: 48 [1480/2566 (58%)]\tLoss: 0.412654\n",
      "Train Epoch: 48 [1520/2566 (59%)]\tLoss: 0.474298\n",
      "Train Epoch: 48 [1560/2566 (61%)]\tLoss: 0.583206\n",
      "Train Epoch: 48 [1600/2566 (62%)]\tLoss: 0.265837\n",
      "Train Epoch: 48 [1640/2566 (64%)]\tLoss: 0.753905\n",
      "Train Epoch: 48 [1680/2566 (65%)]\tLoss: 0.888050\n",
      "Train Epoch: 48 [1720/2566 (67%)]\tLoss: 0.764450\n",
      "Train Epoch: 48 [1760/2566 (69%)]\tLoss: 0.527598\n",
      "Train Epoch: 48 [1800/2566 (70%)]\tLoss: 0.908033\n",
      "Train Epoch: 48 [1840/2566 (72%)]\tLoss: 0.718838\n",
      "Train Epoch: 48 [1880/2566 (73%)]\tLoss: 0.350136\n",
      "Train Epoch: 48 [1920/2566 (75%)]\tLoss: 0.731460\n",
      "Train Epoch: 48 [1960/2566 (76%)]\tLoss: 0.688323\n",
      "Train Epoch: 48 [2000/2566 (78%)]\tLoss: 0.601742\n",
      "Train Epoch: 48 [2040/2566 (79%)]\tLoss: 0.284612\n",
      "Train Epoch: 48 [2080/2566 (81%)]\tLoss: 0.507592\n",
      "Train Epoch: 48 [2120/2566 (83%)]\tLoss: 0.471094\n",
      "Train Epoch: 48 [2160/2566 (84%)]\tLoss: 0.268739\n",
      "Train Epoch: 48 [2200/2566 (86%)]\tLoss: 1.359443\n",
      "Train Epoch: 48 [2240/2566 (87%)]\tLoss: 0.887754\n",
      "Train Epoch: 48 [2280/2566 (89%)]\tLoss: 0.367051\n",
      "Train Epoch: 48 [2320/2566 (90%)]\tLoss: 0.133385\n",
      "Train Epoch: 48 [2360/2566 (92%)]\tLoss: 0.965026\n",
      "Train Epoch: 48 [2400/2566 (93%)]\tLoss: 0.424980\n",
      "Train Epoch: 48 [2440/2566 (95%)]\tLoss: 0.896941\n",
      "Train Epoch: 48 [2480/2566 (97%)]\tLoss: 1.418158\n",
      "Train Epoch: 48 [2520/2566 (98%)]\tLoss: 0.549172\n",
      "Train Epoch: 48 [2560/2566 (100%)]\tLoss: 0.252278\n",
      "epoch:48,loss:0.5409635429581007\n",
      "Train set: Average loss: 0.4641, Accuracy: 2073/2566 (81%)\n",
      "Val set: Average loss: 0.5781, Accuracy: 255/327 (78%)\n",
      "Train Epoch: 49 [40/2566 (2%)]\tLoss: 0.827349\n",
      "Train Epoch: 49 [80/2566 (3%)]\tLoss: 0.443618\n",
      "Train Epoch: 49 [120/2566 (5%)]\tLoss: 0.658342\n",
      "Train Epoch: 49 [160/2566 (6%)]\tLoss: 0.941998\n",
      "Train Epoch: 49 [200/2566 (8%)]\tLoss: 0.929626\n",
      "Train Epoch: 49 [240/2566 (9%)]\tLoss: 0.320719\n",
      "Train Epoch: 49 [280/2566 (11%)]\tLoss: 0.526226\n",
      "Train Epoch: 49 [320/2566 (12%)]\tLoss: 0.144074\n",
      "Train Epoch: 49 [360/2566 (14%)]\tLoss: 0.407477\n",
      "Train Epoch: 49 [400/2566 (16%)]\tLoss: 0.492087\n",
      "Train Epoch: 49 [440/2566 (17%)]\tLoss: 0.607402\n",
      "Train Epoch: 49 [480/2566 (19%)]\tLoss: 0.839633\n",
      "Train Epoch: 49 [520/2566 (20%)]\tLoss: 0.188765\n",
      "Train Epoch: 49 [560/2566 (22%)]\tLoss: 0.461483\n",
      "Train Epoch: 49 [600/2566 (23%)]\tLoss: 1.052610\n",
      "Train Epoch: 49 [640/2566 (25%)]\tLoss: 0.299991\n",
      "Train Epoch: 49 [680/2566 (26%)]\tLoss: 0.440393\n",
      "Train Epoch: 49 [720/2566 (28%)]\tLoss: 0.317907\n",
      "Train Epoch: 49 [760/2566 (30%)]\tLoss: 3.437903\n",
      "Train Epoch: 49 [800/2566 (31%)]\tLoss: 0.385750\n",
      "Train Epoch: 49 [840/2566 (33%)]\tLoss: 0.617266\n",
      "Train Epoch: 49 [880/2566 (34%)]\tLoss: 0.752685\n",
      "Train Epoch: 49 [920/2566 (36%)]\tLoss: 0.661250\n",
      "Train Epoch: 49 [960/2566 (37%)]\tLoss: 0.121729\n",
      "Train Epoch: 49 [1000/2566 (39%)]\tLoss: 0.514423\n",
      "Train Epoch: 49 [1040/2566 (40%)]\tLoss: 0.845758\n",
      "Train Epoch: 49 [1080/2566 (42%)]\tLoss: 0.331485\n",
      "Train Epoch: 49 [1120/2566 (44%)]\tLoss: 0.274768\n",
      "Train Epoch: 49 [1160/2566 (45%)]\tLoss: 0.372118\n",
      "Train Epoch: 49 [1200/2566 (47%)]\tLoss: 0.770189\n",
      "Train Epoch: 49 [1240/2566 (48%)]\tLoss: 0.538138\n",
      "Train Epoch: 49 [1280/2566 (50%)]\tLoss: 0.516851\n",
      "Train Epoch: 49 [1320/2566 (51%)]\tLoss: 0.351476\n",
      "Train Epoch: 49 [1360/2566 (53%)]\tLoss: 0.122107\n",
      "Train Epoch: 49 [1400/2566 (55%)]\tLoss: 0.099605\n",
      "Train Epoch: 49 [1440/2566 (56%)]\tLoss: 0.846035\n",
      "Train Epoch: 49 [1480/2566 (58%)]\tLoss: 0.700223\n",
      "Train Epoch: 49 [1520/2566 (59%)]\tLoss: 0.665392\n",
      "Train Epoch: 49 [1560/2566 (61%)]\tLoss: 0.406171\n",
      "Train Epoch: 49 [1600/2566 (62%)]\tLoss: 0.394110\n",
      "Train Epoch: 49 [1640/2566 (64%)]\tLoss: 0.889238\n",
      "Train Epoch: 49 [1680/2566 (65%)]\tLoss: 0.877672\n",
      "Train Epoch: 49 [1720/2566 (67%)]\tLoss: 0.646512\n",
      "Train Epoch: 49 [1760/2566 (69%)]\tLoss: 0.281585\n",
      "Train Epoch: 49 [1800/2566 (70%)]\tLoss: 0.672203\n",
      "Train Epoch: 49 [1840/2566 (72%)]\tLoss: 0.807405\n",
      "Train Epoch: 49 [1880/2566 (73%)]\tLoss: 0.603233\n",
      "Train Epoch: 49 [1920/2566 (75%)]\tLoss: 0.473489\n",
      "Train Epoch: 49 [1960/2566 (76%)]\tLoss: 0.734743\n",
      "Train Epoch: 49 [2000/2566 (78%)]\tLoss: 0.277450\n",
      "Train Epoch: 49 [2040/2566 (79%)]\tLoss: 0.656063\n",
      "Train Epoch: 49 [2080/2566 (81%)]\tLoss: 0.942845\n",
      "Train Epoch: 49 [2120/2566 (83%)]\tLoss: 0.625310\n",
      "Train Epoch: 49 [2160/2566 (84%)]\tLoss: 0.494469\n",
      "Train Epoch: 49 [2200/2566 (86%)]\tLoss: 0.814415\n",
      "Train Epoch: 49 [2240/2566 (87%)]\tLoss: 3.442742\n",
      "Train Epoch: 49 [2280/2566 (89%)]\tLoss: 0.268149\n",
      "Train Epoch: 49 [2320/2566 (90%)]\tLoss: 0.343888\n",
      "Train Epoch: 49 [2360/2566 (92%)]\tLoss: 0.285382\n",
      "Train Epoch: 49 [2400/2566 (93%)]\tLoss: 0.308812\n",
      "Train Epoch: 49 [2440/2566 (95%)]\tLoss: 0.585781\n",
      "Train Epoch: 49 [2480/2566 (97%)]\tLoss: 0.611398\n",
      "Train Epoch: 49 [2520/2566 (98%)]\tLoss: 0.425792\n",
      "Train Epoch: 49 [2560/2566 (100%)]\tLoss: 0.654212\n",
      "epoch:49,loss:0.5441787019371986\n",
      "Train set: Average loss: 0.4617, Accuracy: 2089/2566 (81%)\n",
      "Val set: Average loss: 0.5703, Accuracy: 252/327 (77%)\n",
      "Train Epoch: 50 [40/2566 (2%)]\tLoss: 0.256927\n",
      "Train Epoch: 50 [80/2566 (3%)]\tLoss: 0.606386\n",
      "Train Epoch: 50 [120/2566 (5%)]\tLoss: 1.190121\n",
      "Train Epoch: 50 [160/2566 (6%)]\tLoss: 0.509018\n",
      "Train Epoch: 50 [200/2566 (8%)]\tLoss: 0.429467\n",
      "Train Epoch: 50 [240/2566 (9%)]\tLoss: 0.216133\n",
      "Train Epoch: 50 [280/2566 (11%)]\tLoss: 0.600614\n",
      "Train Epoch: 50 [320/2566 (12%)]\tLoss: 0.384413\n",
      "Train Epoch: 50 [360/2566 (14%)]\tLoss: 0.651082\n",
      "Train Epoch: 50 [400/2566 (16%)]\tLoss: 0.494589\n",
      "Train Epoch: 50 [440/2566 (17%)]\tLoss: 0.671054\n",
      "Train Epoch: 50 [480/2566 (19%)]\tLoss: 0.589024\n",
      "Train Epoch: 50 [520/2566 (20%)]\tLoss: 0.605102\n",
      "Train Epoch: 50 [560/2566 (22%)]\tLoss: 0.345563\n",
      "Train Epoch: 50 [600/2566 (23%)]\tLoss: 0.437503\n",
      "Train Epoch: 50 [640/2566 (25%)]\tLoss: 0.290398\n",
      "Train Epoch: 50 [680/2566 (26%)]\tLoss: 0.935057\n",
      "Train Epoch: 50 [720/2566 (28%)]\tLoss: 0.742154\n",
      "Train Epoch: 50 [760/2566 (30%)]\tLoss: 0.614659\n",
      "Train Epoch: 50 [800/2566 (31%)]\tLoss: 0.805665\n",
      "Train Epoch: 50 [840/2566 (33%)]\tLoss: 0.161249\n",
      "Train Epoch: 50 [880/2566 (34%)]\tLoss: 0.596268\n",
      "Train Epoch: 50 [920/2566 (36%)]\tLoss: 0.624649\n",
      "Train Epoch: 50 [960/2566 (37%)]\tLoss: 0.681426\n",
      "Train Epoch: 50 [1000/2566 (39%)]\tLoss: 0.437601\n",
      "Train Epoch: 50 [1040/2566 (40%)]\tLoss: 0.671897\n",
      "Train Epoch: 50 [1080/2566 (42%)]\tLoss: 0.646841\n",
      "Train Epoch: 50 [1120/2566 (44%)]\tLoss: 0.782450\n",
      "Train Epoch: 50 [1160/2566 (45%)]\tLoss: 0.601734\n",
      "Train Epoch: 50 [1200/2566 (47%)]\tLoss: 0.338897\n",
      "Train Epoch: 50 [1240/2566 (48%)]\tLoss: 0.355445\n",
      "Train Epoch: 50 [1280/2566 (50%)]\tLoss: 0.363856\n",
      "Train Epoch: 50 [1320/2566 (51%)]\tLoss: 0.196872\n",
      "Train Epoch: 50 [1360/2566 (53%)]\tLoss: 0.364115\n",
      "Train Epoch: 50 [1400/2566 (55%)]\tLoss: 0.278057\n",
      "Train Epoch: 50 [1440/2566 (56%)]\tLoss: 0.169861\n",
      "Train Epoch: 50 [1480/2566 (58%)]\tLoss: 0.206700\n",
      "Train Epoch: 50 [1520/2566 (59%)]\tLoss: 0.398120\n",
      "Train Epoch: 50 [1560/2566 (61%)]\tLoss: 0.472513\n",
      "Train Epoch: 50 [1600/2566 (62%)]\tLoss: 0.523886\n",
      "Train Epoch: 50 [1640/2566 (64%)]\tLoss: 0.480635\n",
      "Train Epoch: 50 [1680/2566 (65%)]\tLoss: 0.709492\n",
      "Train Epoch: 50 [1720/2566 (67%)]\tLoss: 0.136584\n",
      "Train Epoch: 50 [1760/2566 (69%)]\tLoss: 0.412666\n",
      "Train Epoch: 50 [1800/2566 (70%)]\tLoss: 0.445132\n",
      "Train Epoch: 50 [1840/2566 (72%)]\tLoss: 0.350757\n",
      "Train Epoch: 50 [1880/2566 (73%)]\tLoss: 0.335974\n",
      "Train Epoch: 50 [1920/2566 (75%)]\tLoss: 0.606587\n",
      "Train Epoch: 50 [1960/2566 (76%)]\tLoss: 0.213036\n",
      "Train Epoch: 50 [2000/2566 (78%)]\tLoss: 0.442856\n",
      "Train Epoch: 50 [2040/2566 (79%)]\tLoss: 0.654562\n",
      "Train Epoch: 50 [2080/2566 (81%)]\tLoss: 1.050891\n",
      "Train Epoch: 50 [2120/2566 (83%)]\tLoss: 0.751974\n",
      "Train Epoch: 50 [2160/2566 (84%)]\tLoss: 0.432314\n",
      "Train Epoch: 50 [2200/2566 (86%)]\tLoss: 0.204293\n",
      "Train Epoch: 50 [2240/2566 (87%)]\tLoss: 0.881270\n",
      "Train Epoch: 50 [2280/2566 (89%)]\tLoss: 0.473890\n",
      "Train Epoch: 50 [2320/2566 (90%)]\tLoss: 0.342176\n",
      "Train Epoch: 50 [2360/2566 (92%)]\tLoss: 0.342619\n",
      "Train Epoch: 50 [2400/2566 (93%)]\tLoss: 1.024023\n",
      "Train Epoch: 50 [2440/2566 (95%)]\tLoss: 0.589561\n",
      "Train Epoch: 50 [2480/2566 (97%)]\tLoss: 0.396619\n",
      "Train Epoch: 50 [2520/2566 (98%)]\tLoss: 0.165319\n",
      "Train Epoch: 50 [2560/2566 (100%)]\tLoss: 0.139866\n",
      "epoch:50,loss:0.5306101917431362\n",
      "Train set: Average loss: 0.4504, Accuracy: 2081/2566 (81%)\n",
      "Val set: Average loss: 0.5660, Accuracy: 252/327 (77%)\n",
      "training_time:1664.7261793613434\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    val(model, DEVICE, train_loader, 'train')\n",
    "    val(model, DEVICE, test_loader, 'val')\n",
    "torch.save(model, 'model_last.pth')\n",
    "np.savetxt('logs.txt', logs, fmt='%s')\n",
    "end_time = time()\n",
    "print(f'training_time:{end_time-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d2c2ef7-5190-4440-a58d-190576812005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'logs.txt'\n",
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "\n",
    "for line in lines:\n",
    "    if 'Val set' in line:\n",
    "        line = line.split(',')\n",
    "        val_acc.append(float(line[-1].split('(')[-1].split('%')[0]))\n",
    "        val_loss.append(float(line[0].split(':')[-1]))\n",
    "    elif 'Train set' in line:\n",
    "        line = line.split(',')\n",
    "        train_acc.append(float(line[-1].split('(')[-1].split('%')[0]))\n",
    "        train_loss.append(float(line[0].split(':')[-1]))\n",
    "        \n",
    "x = np.arange(1, len(val_acc)+1)\n",
    "\n",
    "plt.plot(x, train_acc, label='train accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.plot(x, val_acc, label='val accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.title('accuracy curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "#Change the scale range of the vertical axis\n",
    "plt.ylim(0,101)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, train_loss, label='train loss')\n",
    "plt.legend(loc='best')\n",
    "plt.plot(x, val_loss, label='val loss')\n",
    "plt.legend(loc='best')\n",
    "plt.title('loss curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78462ab5-7baa-4b8a-9950-be5e43e56288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率：0.7706422018348624\n",
      "混淆矩阵: \n",
      "[[ 10  20   3   0   0]\n",
      " [  8  80   1   0   0]\n",
      " [  1   1 160   0   0]\n",
      " [  2  22   0   2   0]\n",
      " [  0  16   0   1   0]]\n",
      "每一类的precision、recall和f1-score: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Mild\n",
      "       0.48      0.30      0.37        33\n",
      "      Moderate\n",
      "       0.58      0.90      0.70        89\n",
      "         No_DR\n",
      "       0.98      0.99      0.98       162\n",
      "Proliferate_DR\n",
      "       0.67      0.08      0.14        26\n",
      "        Severe\n",
      "       0.00      0.00      0.00        17\n",
      "\n",
      "       accuracy                           0.77       327\n",
      "      macro avg       0.54      0.45      0.44       327\n",
      "   weighted avg       0.74      0.77      0.73       327\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/root/miniconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test\n",
    "with open('datasets/classes.txt', 'r') as f:\n",
    "    classesname = tuple(f.readlines())\n",
    "model = torch.load('model_last.pth', map_location=DEVICE.type)\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "correct = 0\n",
    "total_num = len(test_loader.dataset)\n",
    "labels = []\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data).to(DEVICE), Variable(target).to(DEVICE)\n",
    "        output = model(data)\n",
    "        _, pred = torch.max(output.data, 1)\n",
    "        labels.append(target.view(-1))\n",
    "        preds.append(pred.view(-1))\n",
    "        correct += torch.sum(pred == target)\n",
    "    correct = correct.data.item()\n",
    "    acc = correct / total_num\n",
    "    print('Accuracy：{}'.format(acc))\n",
    "    labels = torch.cat(labels)\n",
    "    preds = torch.cat(preds)\n",
    "    if 'cuda' in DEVICE.type:\n",
    "        preds = np.array(preds.cpu())\n",
    "        labels = np.array(labels.cpu())\n",
    "    cm = confusion_matrix(labels, preds)\n",
    "     # Print confusion_matrix\n",
    "    print(\"confusion matrix: \")\n",
    "    print(cm)\n",
    "    print(\"For each category:precision、recall和f1-score: \")\n",
    "    print(classification_report(labels, preds, target_names=classesname))\n",
    "    # Draw the confusion matrix\n",
    "    # ConfusionMatrixDisplay Required parameters: confusion_matrix, display_labels\n",
    "    plt.rcParams.update({'font.size': 7})\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classesname)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d9730-1bae-4586-b5e1-5155cddd4bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
